{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# testing.py\n# --------------------------------------------------\n#     reason to return a value from a test).\n#     \"\"\"\n# \n#     def __init__(self, orig_method: Callable) -> None:\n#         self.orig_method = orig_method\n# \n#     def __call__(self, *args: Any, **kwargs: Any) -> None:\n#         result = self.orig_method(*args, **kwargs)\n#         if isinstance(result, Generator) or inspect.iscoroutine(result):\n#             raise TypeError(\n#                 \"Generator and coroutine test methods should be\"\n#                 \" decorated with tornado.testing.gen_test\"\n#             )\n#         elif result is not None:\n#             raise ValueError(\"Return value from test method ignored: %r\" % result)\n# \n#     def __getattr__(self, name: str) -> Any:\n#         \"\"\"Proxy all unknown attributes to the original method.\n# \n#         This is important for some of the decorators in the `unittest`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         # IOLoop.add_callback().\n#         self.io_loop = IOLoop.current()\n#         self._running = True\n#         self._next_timeout = self.io_loop.time()\n#         self._schedule_next()\n# \n#     def stop(self) -> None:\n#         \"\"\"Stops the timer.\"\"\"\n#         self._running = False\n#         if self._timeout is not None:\n#             self.io_loop.remove_timeout(self._timeout)\n#             self._timeout = None\n# \n#     def is_running(self) -> bool:\n#         \"\"\"Returns ``True`` if this `.PeriodicCallback` has been started.\n# \n#         .. versionadded:: 4.1\n#         \"\"\"\n#         return self._running\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. versionchanged:: 4.3\n#        Now accepts any yieldable object, not just\n#        `tornado.concurrent.Future`.\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# log.py\n# --------------------------------------------------\n# def define_logging_options(options: Any = None) -> None:\n#     \"\"\"Add logging-related flags to ``options``.\n# \n#     These options are present automatically on the default options instance;\n#     this method is only necessary if you have created your own `.OptionParser`.\n# \n#     .. versionadded:: 4.2\n#         This function existed in prior versions but was broken and undocumented until 4.2.\n#     \"\"\"\n#     if options is None:\n#         # late import to prevent cycle\n#         import tornado.options\n# \n#         options = tornado.options.options\n#     options.define(\n#         \"logging\",\n#         default=\"info\",\n#         help=(\n#             \"Set the Python log level. If 'none', tornado won't touch the \"\n#             \"logging configuration.\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         .. versionchanged:: 4.3\n#            Returning a non-``None``, non-awaitable value is now an error.\n# \n#         .. versionchanged:: 5.0\n#            If a timeout occurs, the ``func`` coroutine will be cancelled.\n# \n#         \"\"\"\n#         future_cell = [None]  # type: List[Optional[Future]]\n# \n#         def run() -> None:\n#             try:\n#                 result = func()\n#                 if result is not None:\n#                     from tornado.gen import convert_yielded\n# \n#                     result = convert_yielded(result)\n#             except Exception:\n#                 fut = Future()  # type: Future[Any]\n#                 future_cell[0] = fut\n#                 future_set_exc_info(fut, sys.exc_info())\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         func: Callable[..., _T],\n#         *args: Any\n#     ) -> Awaitable[_T]:\n#         \"\"\"Runs a function in a ``concurrent.futures.Executor``. If\n#         ``executor`` is ``None``, the IO loop's default executor will be used.\n# \n#         Use `functools.partial` to pass keyword arguments to ``func``.\n# \n#         .. versionadded:: 5.0\n#         \"\"\"\n#         if executor is None:\n#             if not hasattr(self, \"_executor\"):\n#                 from tornado.process import cpu_count\n# \n#                 self._executor = concurrent.futures.ThreadPoolExecutor(\n#                     max_workers=(cpu_count() * 5)\n#                 )  # type: concurrent.futures.Executor\n#             executor = self._executor\n#         c_future = executor.submit(func, *args)\n#         # Concurrent Futures are not usable with await. Wrap this in a\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def add_callback_from_signal(\n#         self, callback: Callable, *args: Any, **kwargs: Any\n#     ) -> None:\n#         \"\"\"Calls the given callback on the next I/O loop iteration.\n# \n#         Safe for use from a Python signal handler; should not be used\n#         otherwise.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"Calls the given callback on the next IOLoop iteration.\n# \n#         As of Tornado 6.0, this method is equivalent to `add_callback`.\n# \n#         .. versionadded:: 4.0\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         .. versionadded:: 4.1\n# \n#         .. versionchanged:: 4.5\n# \n#            Added ``compression_level`` and ``mem_level``.\n#         \"\"\"\n#         # TODO: Add wbits option.\n#         return None\n# \n#     def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n#         \"\"\"Invoked when a new WebSocket is opened.\n# \n#         The arguments to `open` are extracted from the `tornado.web.URLSpec`\n#         regular expression, just like the arguments to\n#         `tornado.web.RequestHandler.get`.\n# \n#         `open` may be a coroutine. `on_message` will not be called until\n#         `open` has returned.\n# \n#         .. versionchanged:: 5.1\n# --------------------------------------------------\n\ndef is_coroutine_function(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function, i.e. a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n", "metadata": {"task_id": "tornado/id1", "ground_truth": "def is_coroutine_function(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function, i.e. a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n    return getattr(func, \"__tornado_coroutine__\", False)", "fpath_tuple": ["tornado", "gen.py"], "function_name": "is_coroutine_function", "lineno": 0, "context_start_lineno": 0, "_id": 1, "query_window": {"context": "from typing import Any\nfrom tornado import gen\ndef isfunction(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function; a function\n    wrapped with `~.gen.coroutine`.\n    .. versionadded:: 4.5\n    \"\"\"\n    # Check if func is callable and has the attribute 'coroutine' from the gen module\n    return callable(func) and hasattr(func, '_gen_coroutine')", "metadata": {"fpath_tuple": ["tornado", "gen.py"], "line_no": 0, "prediction": "from typing import Any\nfrom tornado import gen\n\ndef isfunction(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function; a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n    # Check if func is callable and has the attribute 'coroutine' from the gen module\n    return callable(func) and hasattr(func, '_gen_coroutine')", "task_id": "tornado/id1", "start_line_no": 0, "end_line_no": 9, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        .. versionadded:: 4.1\n\n        .. versionchanged:: 4.5\n\n           Added ``compression_level`` and ``mem_level``.\n        \"\"\"\n        # TODO: Add wbits option.\n        return None\n\n    def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n        \"\"\"Invoked when a new WebSocket is opened.\n\n        The arguments to `open` are extracted from the `tornado.web.URLSpec`\n        regular expression, just like the arguments to\n        `tornado.web.RequestHandler.get`.\n\n        `open` may be a coroutine. `on_message` will not be called until\n        `open` has returned.\n\n        .. versionchanged:: 5.1", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23255813953488372}, {"context": "        \"\"\"\n        raise NotImplementedError()\n\n    def add_callback_from_signal(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> None:\n        \"\"\"Calls the given callback on the next I/O loop iteration.\n\n        Safe for use from a Python signal handler; should not be used\n        otherwise.\n        \"\"\"\n        raise NotImplementedError()\n\n    def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Calls the given callback on the next IOLoop iteration.\n\n        As of Tornado 6.0, this method is equivalent to `add_callback`.\n\n        .. versionadded:: 4.0\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 650, "start_line_no": 640, "end_line_no": 660, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2222222222222222}, {"context": "        func: Callable[..., _T],\n        *args: Any\n    ) -> Awaitable[_T]:\n        \"\"\"Runs a function in a ``concurrent.futures.Executor``. If\n        ``executor`` is ``None``, the IO loop's default executor will be used.\n\n        Use `functools.partial` to pass keyword arguments to ``func``.\n\n        .. versionadded:: 5.0\n        \"\"\"\n        if executor is None:\n            if not hasattr(self, \"_executor\"):\n                from tornado.process import cpu_count\n\n                self._executor = concurrent.futures.ThreadPoolExecutor(\n                    max_workers=(cpu_count() * 5)\n                )  # type: concurrent.futures.Executor\n            executor = self._executor\n        c_future = executor.submit(func, *args)\n        # Concurrent Futures are not usable with await. Wrap this in a", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 720, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2191780821917808}, {"context": "        .. versionchanged:: 4.3\n           Returning a non-``None``, non-awaitable value is now an error.\n\n        .. versionchanged:: 5.0\n           If a timeout occurs, the ``func`` coroutine will be cancelled.\n\n        \"\"\"\n        future_cell = [None]  # type: List[Optional[Future]]\n\n        def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[0] = fut\n                future_set_exc_info(fut, sys.exc_info())", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21774193548387097}, {"context": "def define_logging_options(options: Any = None) -> None:\n    \"\"\"Add logging-related flags to ``options``.\n\n    These options are present automatically on the default options instance;\n    this method is only necessary if you have created your own `.OptionParser`.\n\n    .. versionadded:: 4.2\n        This function existed in prior versions but was broken and undocumented until 4.2.\n    \"\"\"\n    if options is None:\n        # late import to prevent cycle\n        import tornado.options\n\n        options = tornado.options.options\n    options.define(\n        \"logging\",\n        default=\"info\",\n        help=(\n            \"Set the Python log level. If 'none', tornado won't touch the \"\n            \"logging configuration.\"", "metadata": [{"fpath_tuple": ["tornado", "log.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21705426356589147}, {"context": "    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2169811320754717}, {"context": "        # IOLoop.add_callback().\n        self.io_loop = IOLoop.current()\n        self._running = True\n        self._next_timeout = self.io_loop.time()\n        self._schedule_next()\n\n    def stop(self) -> None:\n        \"\"\"Stops the timer.\"\"\"\n        self._running = False\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n            self._timeout = None\n\n    def is_running(self) -> bool:\n        \"\"\"Returns ``True`` if this `.PeriodicCallback` has been started.\n\n        .. versionadded:: 4.1\n        \"\"\"\n        return self._running\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 890, "start_line_no": 880, "end_line_no": 900, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2037037037037037}, {"context": "    reason to return a value from a test).\n    \"\"\"\n\n    def __init__(self, orig_method: Callable) -> None:\n        self.orig_method = orig_method\n\n    def __call__(self, *args: Any, **kwargs: Any) -> None:\n        result = self.orig_method(*args, **kwargs)\n        if isinstance(result, Generator) or inspect.iscoroutine(result):\n            raise TypeError(\n                \"Generator and coroutine test methods should be\"\n                \" decorated with tornado.testing.gen_test\"\n            )\n        elif result is not None:\n            raise ValueError(\"Return value from test method ignored: %r\" % result)\n\n    def __getattr__(self, name: str) -> Any:\n        \"\"\"Proxy all unknown attributes to the original method.\n\n        This is important for some of the decorators in the `unittest`", "metadata": [{"fpath_tuple": ["tornado", "testing.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2028985507246377}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/websocket_test.py\n# --------------------------------------------------\n# import asyncio\n# import functools\n# import traceback\n# import typing\n# import unittest\n# \n# from tornado.concurrent import Future\n# from tornado import gen\n# from tornado.httpclient import HTTPError, HTTPRequest\n# from tornado.locks import Event\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n# While this module is an important part of Tornado's internal\n# implementation, applications rarely need to interact with it\n# directly.\n# \n# \"\"\"\n# \n# import asyncio\n# from concurrent import futures\n# import functools\n# import sys\n# import types\n# \n# from tornado.log import app_log\n# \n# import typing\n# from typing import Any, Callable, Optional, Tuple, Union\n# \n# _T = typing.TypeVar(\"_T\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# import os\n# import socket\n# import ssl\n# import sys\n# import re\n# \n# from tornado.concurrent import Future, future_set_result_unless_cancelled\n# from tornado import ioloop\n# from tornado.log import gen_log\n# from tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\n# from tornado.util import errno_from_exception\n# \n# import typing\n# from typing import (\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Callable,\n#     Pattern,\n#     Any,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \"\"\"\n# \n# import asyncio\n# import concurrent.futures\n# import datetime\n# import functools\n# import logging\n# import numbers\n# import os\n# import sys\n# import time\n# import math\n# import random\n# \n# from tornado.concurrent import (\n#     Future,\n#     is_future,\n#     chain_future,\n#     future_set_exc_info,\n#     future_add_done_callback,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     ReversibleRuleRouter,\n#     URLSpec,\n#     _RuleList,\n# )\n# from tornado.util import ObjectDict, unicode_type, _websocket_mask\n# \n# url = URLSpec\n# \n# from typing import (\n#     Dict,\n#     Any,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Tuple,\n#     List,\n#     Callable,\n#     Iterable,\n#     Generator,\n#     Type,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n# import numbers\n# import datetime\n# import ssl\n# \n# from tornado.concurrent import Future, future_add_done_callback\n# from tornado.ioloop import IOLoop\n# from tornado.iostream import IOStream\n# from tornado import gen\n# from tornado.netutil import Resolver\n# from tornado.gen import TimeoutError\n# \n# from typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional, Set\n# \n# _INITIAL_CONNECT_TIMEOUT = 0.3\n# \n# \n# class _Connector(object):\n#     \"\"\"A stateless implementation of the \"Happy Eyeballs\" algorithm.\n# \n#     \"Happy Eyeballs\" is documented in RFC6555 as the recommended practice\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# import time\n# import math\n# import random\n# \n# from tornado.concurrent import (\n#     Future,\n#     is_future,\n#     chain_future,\n#     future_set_exc_info,\n#     future_add_done_callback,\n# )\n# from tornado.log import app_log\n# from tornado.util import Configurable, TimeoutError, import_object\n# \n# import typing\n# from typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Dict, List  # noqa: F401\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# import textwrap\n# \n# from tornado.escape import _unicode, native_str\n# from tornado.log import define_logging_options\n# from tornado.util import basestring_type, exec_in\n# \n# from typing import (\n#     Any,\n#     Iterator,\n#     Iterable,\n#     Tuple,\n#     Set,\n#     Dict,\n#     Callable,\n#     List,\n#     TextIO,\n#     Optional,\n# )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# import sys\n# import types\n# \n# from tornado.log import app_log\n# \n# import typing\n# from typing import Any, Callable, Optional, Tuple, Union\n# \n# _T = typing.TypeVar(\"_T\")\n# \n# \n# class ReturnValueIgnoredError(Exception):\n#     # No longer used; was previously used by @return_future\n#     pass\n# \n# \n# Future = asyncio.Future\n# \n# FUTURES = (futures.Future, Future)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n# import asyncio\n# import logging\n# import re\n# import types\n# \n# from tornado.concurrent import (\n#     Future,\n#     future_add_done_callback,\n#     future_set_result_unless_cancelled,\n# )\n# from tornado.escape import native_str, utf8\n# from tornado import gen\n# from tornado import httputil\n# from tornado import iostream\n# from tornado.log import gen_log, app_log\n# from tornado.util import GzipDecompressor\n# \n# \n# from typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple\n# --------------------------------------------------\n\ndef with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n    Added the ``quiet_exceptions`` argument and the logging of unhandled\n    exceptions.\n\n    .. versionchanged:: 4.4\n    Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n    ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/id5", "ground_truth": "def with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.IOLoop.add_timeout` (i.e. a `datetime.timedelta` or\n    an absolute time relative to `.IOLoop.time`)\n\n    If the wrapped `.Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n       Added the ``quiet_exceptions`` argument and the logging of unhandled\n       exceptions.\n\n    .. versionchanged:: 4.4\n       Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n       ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n    # It's tempting to optimize this by cancelling the input future on timeout\n    # instead of creating a new one, but A) we can't know if we are the only\n    # one waiting on the input future, so cancelling it might disrupt other\n    # callers and B) concurrent futures can only be cancelled while they are\n    # in the queue, so cancellation cannot reliably bound our waiting time.\n    future_converted = convert_yielded(future)\n    result = _create_future()\n    chain_future(future_converted, result)\n    io_loop = IOLoop.current()\n\n    def error_callback(future: Future) -> None:\n        try:\n            future.result()\n        except asyncio.CancelledError:\n            pass\n        except Exception as e:\n            if not isinstance(e, quiet_exceptions):\n                app_log.error(\n                    \"Exception in Future %r after timeout\", future, exc_info=True\n                )\n\n    def timeout_callback() -> None:\n        if not result.done():\n            result.set_exception(TimeoutError(\"Timeout\"))\n        # In case the wrapped future goes on to fail, log it.\n        future_add_done_callback(future_converted, error_callback)\n\n    timeout_handle = io_loop.add_timeout(timeout, timeout_callback)\n    if isinstance(future_converted, Future):\n        # We know this future will resolve on the IOLoop, so we don't\n        # need the extra thread-safety of IOLoop.add_future (and we also\n        # don't care about StackContext here.\n        future_add_done_callback(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    else:\n        # concurrent.futures.Futures may resolve on any thread, so we\n        # need to route them back to the IOLoop.\n        io_loop.add_future(\n            future_converted, lambda future: io_loop.remove_timeout(timeout_handle)\n        )\n    return result", "fpath_tuple": ["tornado", "gen.py"], "function_name": "with_timeout", "lineno": 0, "context_start_lineno": 0, "_id": 5, "query_window": {"context": "import asyncio\nimport datetime\nimport logging\nfrom typing import Union, Any, Tuple, Type, _Yieldable\nfrom tornado import gen\nfrom tornado.concurrent import Future\n# Set up logging (to be configured as needed in your application)\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\ndef with_timeout(", "metadata": {"fpath_tuple": ["tornado", "gen.py"], "line_no": 0, "prediction": "import asyncio\nimport datetime\nimport logging\nfrom typing import Union, Any, Tuple, Type, _Yieldable\nfrom tornado import gen\nfrom tornado.concurrent import Future\n\n# Set up logging (to be configured as needed in your application)\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\ndef with_timeout(\n    timeout: Union[float, datetime.timedelta],\n    future: _Yieldable,\n    quiet_exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]] = (),\n) -> Future:\n    \"\"\"Wraps a `.Future` (or other yieldable object) in a timeout.\n\n    Raises `tornado.util.TimeoutError` if the input future does not\n    complete before ``timeout``, which may be specified in any form\n    allowed by `.timeout` (i.e., a `datetime.timedelta` or\n    an absolute time relative to `.time`).\n\n    If the wrapped `Future` fails after it has timed out, the exception\n    will be logged unless it is either of a type contained in\n    ``quiet_exceptions`` (which may be an exception type or a sequence of\n    types), or an ``asyncio.CancelledError``.\n\n    The wrapped `.Future` is not canceled when the timeout expires,\n    permitting it to be reused. `asyncio.wait_for` is similar to this\n    function but it does cancel the wrapped `.Future` on timeout.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.1\n    Added the ``quiet_exceptions`` argument and the logging of unhandled\n    exceptions.\n\n    .. versionchanged:: 4.4\n    Added support for yieldable objects other than `.Future`.\n\n    .. versionchanged:: 6.0.3\n    ``asyncio.CancelledError`` is now always considered \"quiet\".\n\n    \"\"\"\n    if isinstance(timeout, datetime.timedelta):\n        timeout = timeout.total_seconds()\n\n    fut = Future()  # Create a new future to return\n    \n    # Define the wrapper function to handle the timeout\n    async def wrapper():\n        try:\n            # Wait for the given future with timeout\n            await asyncio.wait_for(future, timeout)\n            fut.set_result(future.result())  # Set the result if future completes successfully\n        except Exception as e:\n            if isinstance(e, asyncio.TimeoutError):\n                fut.set_exception(gen.TimeoutError(\"Future timed out\"))\n            elif isinstance(e, quiet_exceptions):\n                # If the exception is in quiet_exceptions, only log it\n                logger.debug(f\"Quiet exception: {e}\")\n            else:\n                # Log and set the exception for other exceptions\n                logger.error(f\"Unhandled exception: {e}\", exc_info=True)\n                fut.set_exception(e)\n\n    # Run the wrapper as a coroutine\n    asyncio.ensure_future(wrapper())\n    return fut", "task_id": "tornado/id5", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "import asyncio\nimport logging\nimport re\nimport types\n\nfrom tornado.concurrent import (\n    Future,\n    future_add_done_callback,\n    future_set_result_unless_cancelled,\n)\nfrom tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple\n", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25263157894736843}, {"context": "import sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union\n\n_T = typing.TypeVar(\"_T\")\n\n\nclass ReturnValueIgnoredError(Exception):\n    # No longer used; was previously used by @return_future\n    pass\n\n\nFuture = asyncio.Future\n\nFUTURES = (futures.Future, Future)\n", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22916666666666666}, {"context": "import textwrap\n\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\n\nfrom typing import (\n    Any,\n    Iterator,\n    Iterable,\n    Tuple,\n    Set,\n    Dict,\n    Callable,\n    List,\n    TextIO,\n    Optional,\n)\n\n", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2261904761904762}, {"context": "import time\nimport math\nimport random\n\nfrom tornado.concurrent import (\n    Future,\n    is_future,\n    chain_future,\n    future_set_exc_info,\n    future_add_done_callback,\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n\nif typing.TYPE_CHECKING:\n    from typing import Dict, List  # noqa: F401\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21212121212121213}, {"context": "import numbers\nimport datetime\nimport ssl\n\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional, Set\n\n_INITIAL_CONNECT_TIMEOUT = 0.3\n\n\nclass _Connector(object):\n    \"\"\"A stateless implementation of the \"Happy Eyeballs\" algorithm.\n\n    \"Happy Eyeballs\" is documented in RFC6555 as the recommended practice", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20967741935483872}, {"context": "    ReversibleRuleRouter,\n    URLSpec,\n    _RuleList,\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\n\nurl = URLSpec\n\nfrom typing import (\n    Dict,\n    Any,\n    Union,\n    Optional,\n    Awaitable,\n    Tuple,\n    List,\n    Callable,\n    Iterable,\n    Generator,\n    Type,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20930232558139536}, {"context": "\"\"\"\n\nimport asyncio\nimport concurrent.futures\nimport datetime\nimport functools\nimport logging\nimport numbers\nimport os\nimport sys\nimport time\nimport math\nimport random\n\nfrom tornado.concurrent import (\n    Future,\n    is_future,\n    chain_future,\n    future_set_exc_info,\n    future_add_done_callback,", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2073170731707317}, {"context": "import os\nimport socket\nimport ssl\nimport sys\nimport re\n\nfrom tornado.concurrent import Future, future_set_result_unless_cancelled\nfrom tornado import ioloop\nfrom tornado.log import gen_log\nfrom tornado.netutil import ssl_wrap_socket, _client_ssl_defaults, _server_ssl_defaults\nfrom tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\n    Union,\n    Optional,\n    Awaitable,\n    Callable,\n    Pattern,\n    Any,", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20652173913043478}, {"context": "\nWhile this module is an important part of Tornado's internal\nimplementation, applications rarely need to interact with it\ndirectly.\n\n\"\"\"\n\nimport asyncio\nfrom concurrent import futures\nimport functools\nimport sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union\n\n_T = typing.TypeVar(\"_T\")\n", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20212765957446807}, {"context": "import asyncio\nimport functools\nimport traceback\nimport typing\nimport unittest\n\nfrom tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.httpclient import HTTPError, HTTPRequest\nfrom tornado.locks import Event", "metadata": [{"fpath_tuple": ["tornado", "test", "websocket_test.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19444444444444445}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# import sys\n# import types\n# \n# from tornado.log import app_log\n# \n# import typing\n# from typing import Any, Callable, Optional, Tuple, Union\n# \n# _T = typing.TypeVar(\"_T\")\n# \n# \n# class ReturnValueIgnoredError(Exception):\n#     # No longer used; was previously used by @return_future\n#     pass\n# \n# \n# Future = asyncio.Future\n# \n# FUTURES = (futures.Future, Future)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     ReversibleRuleRouter,\n#     URLSpec,\n#     _RuleList,\n# )\n# from tornado.util import ObjectDict, unicode_type, _websocket_mask\n# \n# url = URLSpec\n# \n# from typing import (\n#     Dict,\n#     Any,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Tuple,\n#     List,\n#     Callable,\n#     Iterable,\n#     Generator,\n#     Type,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# import time\n# import math\n# import random\n# \n# from tornado.concurrent import (\n#     Future,\n#     is_future,\n#     chain_future,\n#     future_set_exc_info,\n#     future_add_done_callback,\n# )\n# from tornado.log import app_log\n# from tornado.util import Configurable, TimeoutError, import_object\n# \n# import typing\n# from typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Dict, List  # noqa: F401\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httpclient.py\n# --------------------------------------------------\n# from io import BytesIO\n# import ssl\n# import time\n# import weakref\n# \n# from tornado.concurrent import (\n#     Future,\n#     future_set_result_unless_cancelled,\n#     future_set_exception_unless_cancelled,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado import gen, httputil\n# from tornado.ioloop import IOLoop\n# from tornado.util import Configurable\n# \n# from typing import Type, Any, Union, Dict, Callable, Optional, cast\n# \n# \n# class HTTPClient(object):\n#     \"\"\"A blocking HTTP client.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# netutil.py\n# --------------------------------------------------\n# import sys\n# import socket\n# import ssl\n# import stat\n# \n# from tornado.concurrent import dummy_executor, run_on_executor\n# from tornado.ioloop import IOLoop\n# from tornado.util import Configurable, errno_from_exception\n# \n# from typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional\n# \n# # Note that the naming of ssl.Purpose is confusing; the purpose\n# # of a context is to authentiate the opposite side of the connection.\n# _client_ssl_defaults = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n# _server_ssl_defaults = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n# if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n#     # See netutil.ssl_options_to_context\n#     _client_ssl_defaults.options |= ssl.OP_NO_COMPRESSION\n#     _server_ssl_defaults.options |= ssl.OP_NO_COMPRESSION\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/caresresolver.py\n# --------------------------------------------------\n# import pycares  # type: ignore\n# import socket\n# \n# from tornado.concurrent import Future\n# from tornado import gen\n# from tornado.ioloop import IOLoop\n# from tornado.netutil import Resolver, is_valid_ip\n# \n# import typing\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/caresresolver.py\n# --------------------------------------------------\n# import pycares  # type: ignore\n# import socket\n# \n# from tornado.concurrent import Future\n# from tornado import gen\n# from tornado.ioloop import IOLoop\n# from tornado.netutil import Resolver, is_valid_ip\n# \n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Generator, Any, List, Tuple, Dict  # noqa: F401\n# \n# \n# class CaresResolver(Resolver):\n#     \"\"\"Name resolver based on the c-ares library.\n# \n#     This is a non-blocking and non-threaded resolver.  It may not produce\n#     the same results as the system resolver, but can be used for non-blocking\n#     resolution when threads cannot be used.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n# import numbers\n# import datetime\n# import ssl\n# \n# from tornado.concurrent import Future, future_add_done_callback\n# from tornado.ioloop import IOLoop\n# from tornado.iostream import IOStream\n# from tornado import gen\n# from tornado.netutil import Resolver\n# from tornado.gen import TimeoutError\n# \n# from typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional, Set\n# \n# _INITIAL_CONNECT_TIMEOUT = 0.3\n# \n# \n# class _Connector(object):\n#     \"\"\"A stateless implementation of the \"Happy Eyeballs\" algorithm.\n# \n#     \"Happy Eyeballs\" is documented in RFC6555 as the recommended practice\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#    of Tornado (but may reduce performance of other ``asyncio``-based libraries\n#    in the same process).\n# \"\"\"\n# \n# import asyncio\n# import atexit\n# import concurrent.futures\n# import errno\n# import functools\n# import select\n# import socket\n# import sys\n# import threading\n# import typing\n# from tornado.gen import convert_yielded\n# from tornado.ioloop import IOLoop, _Selectable\n# \n# from typing import Any, TypeVar, Awaitable, Callable, Union, Optional, List, Tuple, Dict\n# \n# if typing.TYPE_CHECKING:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n# import socket\n# import sys\n# import threading\n# import typing\n# from tornado.gen import convert_yielded\n# from tornado.ioloop import IOLoop, _Selectable\n# \n# from typing import Any, TypeVar, Awaitable, Callable, Union, Optional, List, Tuple, Dict\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Set  # noqa: F401\n#     from typing_extensions import Protocol\n# \n#     class _HasFileno(Protocol):\n#         def fileno(self) -> int:\n#             pass\n# \n#     _FileDescriptorLike = Union[int, _HasFileno]\n# \n# _T = TypeVar(\"_T\")\n# --------------------------------------------------\n\ndef convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n    @convert_yielded.register(asyncio.Future)\n    def _(asyncio_future):\n    return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/id6", "ground_truth": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n        @convert_yielded.register(asyncio.Future)\n        def _(asyncio_future):\n            return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n    if yielded is None or yielded is moment:\n        return moment\n    elif yielded is _null_future:\n        return _null_future\n    elif isinstance(yielded, (list, dict)):\n        return multi(yielded)  # type: ignore\n    elif is_future(yielded):\n        return typing.cast(Future, yielded)\n    elif isawaitable(yielded):\n        return _wrap_awaitable(yielded)  # type: ignore\n    else:\n        raise BadYieldError(\"yielded unknown object %r\" % (yielded,))", "fpath_tuple": ["tornado", "gen.py"], "function_name": "convert_yielded", "lineno": 0, "context_start_lineno": 0, "_id": 6, "query_window": {"context": "from typing import Any, Dict, List, Tuple, Union\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.concurrent import Future\nimport asyncio\nimport sys\n# Assuming _Yieldable is defined somewhere in your actual codebase.\n_Yieldable = Union[List[Any], Dict[Any, Any], Future, asyncio.Future]\ndef convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded into a `.Future`.", "metadata": {"fpath_tuple": ["tornado", "gen.py"], "line_no": 0, "prediction": "from typing import Any, Dict, List, Tuple, Union\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.concurrent import Future\nimport asyncio\nimport sys\n\n# Assuming _Yieldable is defined somewhere in your actual codebase.\n_Yieldable = Union[List[Any], Dict[Any, Any], Future, asyncio.Future]\n\ndef convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types.\n    \"\"\"\n\n    if isinstance(yielded, Future):\n        return yielded\n\n    if isinstance(yielded, asyncio.Future):\n        # Convert asyncio.Future to Tornado Future\n        return tornado.platform.asyncio.to_tornado_future(yielded)\n\n    if isinstance(yielded, list):\n        # Handle list by converting each element\n        future = Future()\n        results = []\n        for item in yielded:\n            results.append(convert_yielded(item))\n        future.set_result(results)\n        return future\n\n    if isinstance(yielded, dict):\n        # Handle dictionary by converting each value\n        future = Future()\n        results = {}\n        for key, value in yielded.items():\n            results[key] = convert_yielded(value)\n        future.set_result(results)\n        return future\n\n    # Here we can add more type checks and conversions as necessary\n\n    # If none of the above, return a resolved Future with the original value\n    future = Future()\n    future.set_result(yielded)\n    return future", "task_id": "tornado/id6", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "import socket\nimport sys\nimport threading\nimport typing\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\n\nfrom typing import Any, TypeVar, Awaitable, Callable, Union, Optional, List, Tuple, Dict\n\nif typing.TYPE_CHECKING:\n    from typing import Set  # noqa: F401\n    from typing_extensions import Protocol\n\n    class _HasFileno(Protocol):\n        def fileno(self) -> int:\n            pass\n\n    _FileDescriptorLike = Union[int, _HasFileno]\n\n_T = TypeVar(\"_T\")", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.30434782608695654}, {"context": "   of Tornado (but may reduce performance of other ``asyncio``-based libraries\n   in the same process).\n\"\"\"\n\nimport asyncio\nimport atexit\nimport concurrent.futures\nimport errno\nimport functools\nimport select\nimport socket\nimport sys\nimport threading\nimport typing\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\n\nfrom typing import Any, TypeVar, Awaitable, Callable, Union, Optional, List, Tuple, Dict\n\nif typing.TYPE_CHECKING:", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2743362831858407}, {"context": "import numbers\nimport datetime\nimport ssl\n\nfrom tornado.concurrent import Future, future_add_done_callback\nfrom tornado.ioloop import IOLoop\nfrom tornado.iostream import IOStream\nfrom tornado import gen\nfrom tornado.netutil import Resolver\nfrom tornado.gen import TimeoutError\n\nfrom typing import Any, Union, Dict, Tuple, List, Callable, Iterator, Optional, Set\n\n_INITIAL_CONNECT_TIMEOUT = 0.3\n\n\nclass _Connector(object):\n    \"\"\"A stateless implementation of the \"Happy Eyeballs\" algorithm.\n\n    \"Happy Eyeballs\" is documented in RFC6555 as the recommended practice", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25396825396825395}, {"context": "import pycares  # type: ignore\nimport socket\n\nfrom tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.netutil import Resolver, is_valid_ip\n\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Generator, Any, List, Tuple, Dict  # noqa: F401\n\n\nclass CaresResolver(Resolver):\n    \"\"\"Name resolver based on the c-ares library.\n\n    This is a non-blocking and non-threaded resolver.  It may not produce\n    the same results as the system resolver, but can be used for non-blocking\n    resolution when threads cannot be used.", "metadata": [{"fpath_tuple": ["tornado", "platform", "caresresolver.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24193548387096775}, {"context": "import pycares  # type: ignore\nimport socket\n\nfrom tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.netutil import Resolver, is_valid_ip\n\nimport typing\n", "metadata": [{"fpath_tuple": ["tornado", "platform", "caresresolver.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24050632911392406}, {"context": "import sys\nimport socket\nimport ssl\nimport stat\n\nfrom tornado.concurrent import dummy_executor, run_on_executor\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable, errno_from_exception\n\nfrom typing import List, Callable, Any, Type, Dict, Union, Tuple, Awaitable, Optional\n\n# Note that the naming of ssl.Purpose is confusing; the purpose\n# of a context is to authentiate the opposite side of the connection.\n_client_ssl_defaults = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n_server_ssl_defaults = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\nif hasattr(ssl, \"OP_NO_COMPRESSION\"):\n    # See netutil.ssl_options_to_context\n    _client_ssl_defaults.options |= ssl.OP_NO_COMPRESSION\n    _server_ssl_defaults.options |= ssl.OP_NO_COMPRESSION\n", "metadata": [{"fpath_tuple": ["tornado", "netutil.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23880597014925373}, {"context": "from io import BytesIO\nimport ssl\nimport time\nimport weakref\n\nfrom tornado.concurrent import (\n    Future,\n    future_set_result_unless_cancelled,\n    future_set_exception_unless_cancelled,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado import gen, httputil\nfrom tornado.ioloop import IOLoop\nfrom tornado.util import Configurable\n\nfrom typing import Type, Any, Union, Dict, Callable, Optional, cast\n\n\nclass HTTPClient(object):\n    \"\"\"A blocking HTTP client.", "metadata": [{"fpath_tuple": ["tornado", "httpclient.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23853211009174313}, {"context": "import time\nimport math\nimport random\n\nfrom tornado.concurrent import (\n    Future,\n    is_future,\n    chain_future,\n    future_set_exc_info,\n    future_add_done_callback,\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n\nif typing.TYPE_CHECKING:\n    from typing import Dict, List  # noqa: F401\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23076923076923078}, {"context": "    ReversibleRuleRouter,\n    URLSpec,\n    _RuleList,\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\n\nurl = URLSpec\n\nfrom typing import (\n    Dict,\n    Any,\n    Union,\n    Optional,\n    Awaitable,\n    Tuple,\n    List,\n    Callable,\n    Iterable,\n    Generator,\n    Type,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23076923076923078}, {"context": "import sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union\n\n_T = typing.TypeVar(\"_T\")\n\n\nclass ReturnValueIgnoredError(Exception):\n    # No longer used; was previously used by @return_future\n    pass\n\n\nFuture = asyncio.Future\n\nFUTURES = (futures.Future, Future)\n", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22330097087378642}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#         or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n#         both will be used if available.\n# \n#         The ``backlog`` argument has the same meaning as for\n#         `socket.listen <socket.socket.listen>`. The ``reuse_port`` argument\n#         has the same meaning as for `.bind_sockets`.\n# \n#         This method may be called multiple times prior to `start` to listen\n#         on multiple ports or interfaces.\n# \n#         .. versionchanged:: 4.4\n#            Added the ``reuse_port`` argument.\n#         \"\"\"\n#         sockets = bind_sockets(\n#             port, address=address, family=family, backlog=backlog, reuse_port=reuse_port\n#         )\n#         if self._started:\n#             self.add_sockets(sockets)\n#         else:\n#             self._pending_sockets.extend(sockets)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#         port = None\n#     return (host, port)\n# \n# \n# def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n#     \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     for k, vs in qs.items():\n#         for v in vs:\n#             yield (k, v)\n# \n# \n# _OctalPatt = re.compile(r\"\\\\[0-3][0-7][0-7]\")\n# _QuotePatt = re.compile(r\"[\\\\].\")\n# _nulljoin = \"\".join\n# \n# \n# def _unquote_cookie(s: str) -> str:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/util.py\n# --------------------------------------------------\n# \n# def refusing_port():\n#     \"\"\"Returns a local port number that will refuse all connections.\n# \n#     Return value is (cleanup_func, port); the cleanup function\n#     must be called to free the port to be reused.\n#     \"\"\"\n#     # On travis-ci, port numbers are reassigned frequently. To avoid\n#     # collisions with other tests, we use an open client-side socket's\n#     # ephemeral port number to ensure that nothing can listen on that\n#     # port.\n#     server_socket, port = bind_unused_port()\n#     server_socket.setblocking(True)\n#     client_socket = socket.socket()\n#     client_socket.connect((\"127.0.0.1\", port))\n#     conn, client_addr = server_socket.accept()\n#     conn.close()\n#     server_socket.close()\n#     return (client_socket.close, client_addr[1])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#     .. versionchanged:: 5.0\n#        The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n#     \"\"\"\n# \n#     def __init__(self, resolver: Optional[Resolver] = None) -> None:\n#         if resolver is not None:\n#             self.resolver = resolver\n#             self._own_resolver = False\n#         else:\n#             self.resolver = Resolver()\n#             self._own_resolver = True\n# \n#     def close(self) -> None:\n#         if self._own_resolver:\n#             self.resolver.close()\n# \n#     async def connect(\n#         self,\n#         host: str,\n#         port: int,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# netutil.py\n# --------------------------------------------------\n# # Default backlog used when calling sock.listen()\n# _DEFAULT_BACKLOG = 128\n# \n# \n# def bind_sockets(\n#     port: int,\n#     address: Optional[str] = None,\n#     family: socket.AddressFamily = socket.AF_UNSPEC,\n#     backlog: int = _DEFAULT_BACKLOG,\n#     flags: Optional[int] = None,\n#     reuse_port: bool = False,\n# ) -> List[socket.socket]:\n#     \"\"\"Creates listening sockets bound to the given port and address.\n# \n#     Returns a list of socket objects (multiple sockets are returned if\n#     the given address maps to multiple IP addresses, which is most common\n#     for mixed IPv4 and IPv6 use).\n# \n#     Address may be either an IP address or hostname.  If it's a hostname,\n#     the server will listen on all IP addresses associated with the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/util.py\n# --------------------------------------------------\n#     # port.\n#     server_socket, port = bind_unused_port()\n#     server_socket.setblocking(True)\n#     client_socket = socket.socket()\n#     client_socket.connect((\"127.0.0.1\", port))\n#     conn, client_addr = server_socket.accept()\n#     conn.close()\n#     server_socket.close()\n#     return (client_socket.close, client_addr[1])\n# \n# \n# def exec_test(caller_globals, caller_locals, s):\n#     \"\"\"Execute ``s`` in a given context and return the result namespace.\n# \n#     Used to define functions for tests in particular python\n#     versions that would be syntax errors in older versions.\n#     \"\"\"\n#     # Flatten the real global and local namespace into our fake\n#     # globals: it's all global from the perspective of code defined\n#     # in s.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n#     return doctest.DocTestSuite()\n# \n# \n# _netloc_re = re.compile(r\"^(.+):(\\d+)$\")\n# \n# \n# def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n#     \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n# \n#     Returned ``port`` will be ``None`` if not present.\n# \n#     .. versionadded:: 4.1\n#     \"\"\"\n#     match = _netloc_re.match(netloc)\n#     if match:\n#         host = match.group(1)\n#         port = int(match.group(2))  # type: Optional[int]\n#     else:\n#         host = netloc\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     Returned ``port`` will be ``None`` if not present.\n# \n#     .. versionadded:: 4.1\n#     \"\"\"\n#     match = _netloc_re.match(netloc)\n#     if match:\n#         host = match.group(1)\n#         port = int(match.group(2))  # type: Optional[int]\n#     else:\n#         host = netloc\n#         port = None\n#     return (host, port)\n# \n# \n# def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n#     \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     for k, vs in qs.items():\n# --------------------------------------------------\n\ndef bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n    Always binds to ``127.0.0.1`` without resolving the name\n    ``localhost``.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id7", "ground_truth": "def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n       Always binds to ``127.0.0.1`` without resolving the name\n       ``localhost``.\n    \"\"\"\n    sock = netutil.bind_sockets(\n        0, \"127.0.0.1\", family=socket.AF_INET, reuse_port=reuse_port\n    )[0]\n    port = sock.getsockname()[1]\n    return sock, port", "fpath_tuple": ["tornado", "testing.py"], "function_name": "bind_unused_port", "lineno": 0, "context_start_lineno": 0, "_id": 7, "query_window": {"context": "import socket\nfrom typing import Tuple\ndef bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n    Returns a tuple (socket, port).\n    .. versionchanged:: 4.4\n    Always binds to ``127.0.0.1`` without resolving the name\n    ``localhost``.\n    \"\"\"\n    # Create a socket", "metadata": {"fpath_tuple": ["tornado", "testing.py"], "line_no": 0, "prediction": "import socket\nfrom typing import Tuple\n\ndef bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n    Always binds to ``127.0.0.1`` without resolving the name\n    ``localhost``.\n    \"\"\"\n    # Create a socket\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    if reuse_port:\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n    # Bind to localhost and port 0, which means we will assign an available port\n    s.bind((\"127.0.0.1\", 0))\n    # Get the port number assigned\n    port = s.getsockname()[1]\n    \n    # Return the socket and the assigned port\n    return s, port", "task_id": "tornado/id7", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)\n\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1040, "start_line_no": 1030, "end_line_no": 1050, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.265625}, {"context": "\n    return doctest.DocTestSuite()\n\n\n_netloc_re = re.compile(r\"^(.+):(\\d+)$\")\n\n\ndef split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1030, "start_line_no": 1020, "end_line_no": 1040, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24793388429752067}, {"context": "    # port.\n    server_socket, port = bind_unused_port()\n    server_socket.setblocking(True)\n    client_socket = socket.socket()\n    client_socket.connect((\"127.0.0.1\", port))\n    conn, client_addr = server_socket.accept()\n    conn.close()\n    server_socket.close()\n    return (client_socket.close, client_addr[1])\n\n\ndef exec_test(caller_globals, caller_locals, s):\n    \"\"\"Execute ``s`` in a given context and return the result namespace.\n\n    Used to define functions for tests in particular python\n    versions that would be syntax errors in older versions.\n    \"\"\"\n    # Flatten the real global and local namespace into our fake\n    # globals: it's all global from the perspective of code defined\n    # in s.", "metadata": [{"fpath_tuple": ["tornado", "test", "util.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24242424242424243}, {"context": "# Default backlog used when calling sock.listen()\n_DEFAULT_BACKLOG = 128\n\n\ndef bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the", "metadata": [{"fpath_tuple": ["tornado", "netutil.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2323943661971831}, {"context": "    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n    \"\"\"\n\n    def __init__(self, resolver: Optional[Resolver] = None) -> None:\n        if resolver is not None:\n            self.resolver = resolver\n            self._own_resolver = False\n        else:\n            self.resolver = Resolver()\n            self._own_resolver = True\n\n    def close(self) -> None:\n        if self._own_resolver:\n            self.resolver.close()\n\n    async def connect(\n        self,\n        host: str,\n        port: int,", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22935779816513763}, {"context": "\ndef refusing_port():\n    \"\"\"Returns a local port number that will refuse all connections.\n\n    Return value is (cleanup_func, port); the cleanup function\n    must be called to free the port to be reused.\n    \"\"\"\n    # On travis-ci, port numbers are reassigned frequently. To avoid\n    # collisions with other tests, we use an open client-side socket's\n    # ephemeral port number to ensure that nothing can listen on that\n    # port.\n    server_socket, port = bind_unused_port()\n    server_socket.setblocking(True)\n    client_socket = socket.socket()\n    client_socket.connect((\"127.0.0.1\", port))\n    conn, client_addr = server_socket.accept()\n    conn.close()\n    server_socket.close()\n    return (client_socket.close, client_addr[1])\n", "metadata": [{"fpath_tuple": ["tornado", "test", "util.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22388059701492538}, {"context": "        port = None\n    return (host, port)\n\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():\n        for v in vs:\n            yield (k, v)\n\n\n_OctalPatt = re.compile(r\"\\\\[0-3][0-7][0-7]\")\n_QuotePatt = re.compile(r\"[\\\\].\")\n_nulljoin = \"\".join\n\n\ndef _unquote_cookie(s: str) -> str:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1050, "start_line_no": 1040, "end_line_no": 1060, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21641791044776118}, {"context": "        or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n        both will be used if available.\n\n        The ``backlog`` argument has the same meaning as for\n        `socket.listen <socket.socket.listen>`. The ``reuse_port`` argument\n        has the same meaning as for `.bind_sockets`.\n\n        This method may be called multiple times prior to `start` to listen\n        on multiple ports or interfaces.\n\n        .. versionchanged:: 4.4\n           Added the ``reuse_port`` argument.\n        \"\"\"\n        sockets = bind_sockets(\n            port, address=address, family=family, backlog=backlog, reuse_port=reuse_port\n        )\n        if self._started:\n            self.add_sockets(sockets)\n        else:\n            self._pending_sockets.extend(sockets)", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21212121212121213}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \n#         .. versionchanged:: 5.0\n#            This method also sets the current `asyncio` event loop.\n#         \"\"\"\n#         # The asyncio event loops override this method.\n#         raise NotImplementedError()\n# \n#     @staticmethod\n#     def clear_current() -> None:\n#         \"\"\"Clears the `IOLoop` for the current thread.\n# \n#         Intended primarily for use by test frameworks in between tests.\n# \n#         .. versionchanged:: 5.0\n#            This method also clears the current `asyncio` event loop.\n#         \"\"\"\n#         old = IOLoop.current(instance=False)\n#         if old is not None:\n#             old._clear_current_hook()\n#         if asyncio is None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         .. deprecated:: 5.0\n#         \"\"\"\n#         self.make_current()\n# \n#     @staticmethod\n#     def clear_instance() -> None:\n#         \"\"\"Deprecated alias for `clear_current()`.\n# \n#         .. versionchanged:: 5.0\n# \n#            Previously, this method would clear the `IOLoop` used as\n#            the global singleton by `IOLoop.instance()`. Now that\n#            `instance()` is an alias for `current()`,\n#            `clear_instance()` is an alias for `clear_current()`.\n# \n#         .. deprecated:: 5.0\n# \n#         \"\"\"\n#         IOLoop.clear_current()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#     def install(self) -> None:\n#         \"\"\"Deprecated alias for `make_current()`.\n# \n#         .. versionchanged:: 5.0\n# \n#            Previously, this method would set this `IOLoop` as the\n#            global singleton used by `IOLoop.instance()`. Now that\n#            `instance()` is an alias for `current()`, `install()`\n#            is an alias for `make_current()`.\n# \n#         .. deprecated:: 5.0\n#         \"\"\"\n#         self.make_current()\n# \n#     @staticmethod\n#     def clear_instance() -> None:\n#         \"\"\"Deprecated alias for `clear_current()`.\n# \n#         .. versionchanged:: 5.0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \n#     def call_at(\n#         self, when: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n#     ) -> object:\n#         \"\"\"Runs the ``callback`` at the absolute time designated by ``when``.\n# \n#         ``when`` must be a number using the same reference point as\n#         `IOLoop.time`.\n# \n#         Returns an opaque handle that may be passed to `remove_timeout`\n#         to cancel.  Note that unlike the `asyncio` method of the same\n#         name, the returned object does not have a ``cancel()`` method.\n# \n#         See `add_timeout` for comments on thread-safety and subclassing.\n# \n#         .. versionadded:: 4.0\n#         \"\"\"\n#         return self.add_timeout(when, callback, *args, **kwargs)\n# \n#     def remove_timeout(self, timeout: object) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \n#         Intended primarily for use by test frameworks in between tests.\n# \n#         .. versionchanged:: 5.0\n#            This method also clears the current `asyncio` event loop.\n#         \"\"\"\n#         old = IOLoop.current(instance=False)\n#         if old is not None:\n#             old._clear_current_hook()\n#         if asyncio is None:\n#             IOLoop._current.instance = None\n# \n#     def _clear_current_hook(self) -> None:\n#         \"\"\"Instance method called when an IOLoop ceases to be current.\n# \n#         May be overridden by subclasses as a counterpart to make_current.\n#         \"\"\"\n#         pass\n# \n#     @classmethod\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n# \n#     def _clear_current_hook(self) -> None:\n#         if self.is_current:\n#             asyncio.set_event_loop(self.old_asyncio)\n#             self.is_current = False\n# \n# \n# def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. versionchanged:: 4.3\n#        Now accepts any yieldable object, not just\n#        `tornado.concurrent.Future`.\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n# --------------------------------------------------\n\ndef get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n", "metadata": {"task_id": "tornado/id8", "ground_truth": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n    env = os.environ.get(\"ASYNC_TEST_TIMEOUT\")\n    if env is not None:\n        try:\n            return float(env)\n        except ValueError:\n            pass\n    return 5", "fpath_tuple": ["tornado", "testing.py"], "function_name": "get_async_test_timeout", "lineno": 0, "context_start_lineno": 0, "_id": 8, "query_window": {"context": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n    Returns a float, the timeout in seconds.\n    .. versionadded:: 3.1\n    \"\"\"\n    return 30.0  # Default timeout for async tests is set to 30 seconds.", "metadata": {"fpath_tuple": ["tornado", "testing.py"], "line_no": 0, "prediction": "def get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n\n    Returns a float, the timeout in seconds.\n\n    .. versionadded:: 3.1\n    \"\"\"\n    return 30.0  # Default timeout for async tests is set to 30 seconds.", "task_id": "tornado/id8", "start_line_no": 0, "end_line_no": 6, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24444444444444444}, {"context": "\n    def _clear_current_hook(self) -> None:\n        if self.is_current:\n            asyncio.set_event_loop(self.old_asyncio)\n            self.is_current = False\n\n\ndef to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21428571428571427}, {"context": "\n        Intended primarily for use by test frameworks in between tests.\n\n        .. versionchanged:: 5.0\n           This method also clears the current `asyncio` event loop.\n        \"\"\"\n        old = IOLoop.current(instance=False)\n        if old is not None:\n            old._clear_current_hook()\n        if asyncio is None:\n            IOLoop._current.instance = None\n\n    def _clear_current_hook(self) -> None:\n        \"\"\"Instance method called when an IOLoop ceases to be current.\n\n        May be overridden by subclasses as a counterpart to make_current.\n        \"\"\"\n        pass\n\n    @classmethod", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20952380952380953}, {"context": "\n    def call_at(\n        self, when: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the absolute time designated by ``when``.\n\n        ``when`` must be a number using the same reference point as\n        `IOLoop.time`.\n\n        Returns an opaque handle that may be passed to `remove_timeout`\n        to cancel.  Note that unlike the `asyncio` method of the same\n        name, the returned object does not have a ``cancel()`` method.\n\n        See `add_timeout` for comments on thread-safety and subclassing.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        return self.add_timeout(when, callback, *args, **kwargs)\n\n    def remove_timeout(self, timeout: object) -> None:", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.208}, {"context": "    def install(self) -> None:\n        \"\"\"Deprecated alias for `make_current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method would set this `IOLoop` as the\n           global singleton used by `IOLoop.instance()`. Now that\n           `instance()` is an alias for `current()`, `install()`\n           is an alias for `make_current()`.\n\n        .. deprecated:: 5.0\n        \"\"\"\n        self.make_current()\n\n    @staticmethod\n    def clear_instance() -> None:\n        \"\"\"Deprecated alias for `clear_current()`.\n\n        .. versionchanged:: 5.0\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20689655172413793}, {"context": "        .. deprecated:: 5.0\n        \"\"\"\n        self.make_current()\n\n    @staticmethod\n    def clear_instance() -> None:\n        \"\"\"Deprecated alias for `clear_current()`.\n\n        .. versionchanged:: 5.0\n\n           Previously, this method would clear the `IOLoop` used as\n           the global singleton by `IOLoop.instance()`. Now that\n           `instance()` is an alias for `current()`,\n           `clear_instance()` is an alias for `clear_current()`.\n\n        .. deprecated:: 5.0\n\n        \"\"\"\n        IOLoop.clear_current()\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20481927710843373}, {"context": "\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20430107526881722}, {"context": "\n        .. versionchanged:: 5.0\n           This method also sets the current `asyncio` event loop.\n        \"\"\"\n        # The asyncio event loops override this method.\n        raise NotImplementedError()\n\n    @staticmethod\n    def clear_current() -> None:\n        \"\"\"Clears the `IOLoop` for the current thread.\n\n        Intended primarily for use by test frameworks in between tests.\n\n        .. versionchanged:: 5.0\n           This method also clears the current `asyncio` event loop.\n        \"\"\"\n        old = IOLoop.current(instance=False)\n        if old is not None:\n            old._clear_current_hook()\n        if asyncio is None:", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20192307692307693}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#             IOLoop._current.instance = None\n# \n#     def _clear_current_hook(self) -> None:\n#         \"\"\"Instance method called when an IOLoop ceases to be current.\n# \n#         May be overridden by subclasses as a counterpart to make_current.\n#         \"\"\"\n#         pass\n# \n#     @classmethod\n#     def configurable_base(cls) -> Type[Configurable]:\n#         return IOLoop\n# \n#     @classmethod\n#     def configurable_default(cls) -> Type[Configurable]:\n#         from tornado.platform.asyncio import AsyncIOLoop\n# \n#         return AsyncIOLoop\n# \n#     def initialize(self, make_current: Optional[bool] = None) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     put = _unimplemented_method  # type: Callable[..., Optional[Awaitable[None]]]\n#     options = _unimplemented_method  # type: Callable[..., Optional[Awaitable[None]]]\n# \n#     def prepare(self) -> Optional[Awaitable[None]]:\n#         \"\"\"Called at the beginning of a request before  `get`/`post`/etc.\n# \n#         Override this method to perform common initialization regardless\n#         of the request method.\n# \n#         Asynchronous support: Use ``async def`` or decorate this method with\n#         `.gen.coroutine` to make it asynchronous.\n#         If this method returns an  ``Awaitable`` execution will not proceed\n#         until the ``Awaitable`` is done.\n# \n#         .. versionadded:: 3.1\n#            Asynchronous support.\n#         \"\"\"\n#         pass\n# \n#     def on_finish(self) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n# \n# @typing.overload\n# def future_add_done_callback(\n#     future: \"futures.Future[_T]\", callback: Callable[[\"futures.Future[_T]\"], None]\n# ) -> None:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def future_add_done_callback(\n#     future: \"Future[_T]\", callback: Callable[[\"Future[_T]\"], None]\n# ) -> None:\n#     pass\n# \n# \n# def future_add_done_callback(  # noqa: F811\n#     future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n# ) -> None:\n#     \"\"\"Arrange to call ``callback`` when ``future`` is complete.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     \"\"\"Parses global options from a config file.\n# \n#     See `OptionParser.parse_config_file`.\n#     \"\"\"\n#     return options.parse_config_file(path, final=final)\n# \n# \n# def print_help(file: Optional[TextIO] = None) -> None:\n#     \"\"\"Prints all the command line options to stderr (or another file).\n# \n#     See `OptionParser.print_help`.\n#     \"\"\"\n#     return options.print_help(file)\n# \n# \n# def add_parse_callback(callback: Callable[[], None]) -> None:\n#     \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n# \n#     See `OptionParser.add_parse_callback`\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# \"\"\"\n# \n# \n# def define(\n#     name: str,\n#     default: Any = None,\n#     type: Optional[type] = None,\n#     help: Optional[str] = None,\n#     metavar: Optional[str] = None,\n#     multiple: bool = False,\n#     group: Optional[str] = None,\n#     callback: Optional[Callable[[Any], None]] = None,\n# ) -> None:\n#     \"\"\"Defines an option in the global namespace.\n# \n#     See `OptionParser.define`.\n#     \"\"\"\n#     return options.define(\n#         name,\n#         default=default,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/testing_test.py\n# --------------------------------------------------\n# from tornado import gen, ioloop\n# from tornado.httpserver import HTTPServer\n# from tornado.locks import Event\n# from tornado.testing import AsyncHTTPTestCase, AsyncTestCase, bind_unused_port, gen_test\n# from tornado.web import Application\n# import asyncio\n# import contextlib\n# import gc\n# import os\n# import platform\n# import traceback\n# import unittest\n# import warnings\n# \n# \n# @contextlib.contextmanager\n# def set_environ(name, value):\n#     old_value = os.environ.get(name)\n#     os.environ[name] = value\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/concurrent_test.py\n# --------------------------------------------------\n# from tornado.testing import AsyncTestCase, bind_unused_port, gen_test\n# \n# \n# class MiscFutureTest(AsyncTestCase):\n#     def test_future_set_result_unless_cancelled(self):\n#         fut = Future()  # type: Future[int]\n#         future_set_result_unless_cancelled(fut, 42)\n#         self.assertEqual(fut.result(), 42)\n#         self.assertFalse(fut.cancelled())\n# \n#         fut = Future()\n#         fut.cancel()\n#         is_cancelled = fut.cancelled()\n#         future_set_result_unless_cancelled(fut, 42)\n#         self.assertEqual(fut.cancelled(), is_cancelled)\n#         if not is_cancelled:\n#             self.assertEqual(fut.result(), 42)\n# \n# \n# # The following series of classes demonstrate and test various styles\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n# def _fake_ctx_run(f: Callable[..., _T], *args: Any, **kw: Any) -> _T:\n#     return f(*args, **kw)\n# \n# \n# @overload\n# def coroutine(\n#     func: Callable[..., \"Generator[Any, Any, _T]\"]\n# ) -> Callable[..., \"Future[_T]\"]:\n#     ...\n# \n# \n# @overload\n# def coroutine(func: Callable[..., _T]) -> Callable[..., \"Future[_T]\"]:\n#     ...\n# \n# \n# def coroutine(\n#     func: Union[Callable[..., \"Generator[Any, Any, _T]\"], Callable[..., _T]]\n# ) -> Callable[..., \"Future[_T]\"]:\n#     \"\"\"Decorator for asynchronous generators.\n# --------------------------------------------------\n\ndef gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test\n    def test_something(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n    class MyTest(AsyncHTTPTestCase):\n    @gen_test(timeout=10)\n    def test_something_slow(self):\n    response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n    The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n    variable.\n\n    .. versionchanged:: 4.0\n    The wrapper now passes along ``*args, **kwargs`` so it can be used\n    on functions with arguments.\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/id9", "ground_truth": "def gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n]:\n    \"\"\"Testing equivalent of ``@gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example::\n\n        class MyTest(AsyncHTTPTestCase):\n            @gen_test\n            def test_something(self):\n                response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument::\n\n        class MyTest(AsyncHTTPTestCase):\n            @gen_test(timeout=10)\n            def test_something_slow(self):\n                response = yield self.http_client.fetch(self.get_url('/'))\n\n    Note that ``@gen_test`` is incompatible with `AsyncTestCase.stop`,\n    `AsyncTestCase.wait`, and `AsyncHTTPTestCase.fetch`. Use ``yield\n    self.http_client.fetch(self.get_url())`` as shown above instead.\n\n    .. versionadded:: 3.1\n       The ``timeout`` argument and ``ASYNC_TEST_TIMEOUT`` environment\n       variable.\n\n    .. versionchanged:: 4.0\n       The wrapper now passes along ``*args, **kwargs`` so it can be used\n       on functions with arguments.\n\n    \"\"\"\n    if timeout is None:\n        timeout = get_async_test_timeout()\n\n    def wrap(f: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n        # Stack up several decorators to allow us to access the generator\n        # object itself.  In the innermost wrapper, we capture the generator\n        # and save it in an attribute of self.  Next, we run the wrapped\n        # function through @gen.coroutine.  Finally, the coroutine is\n        # wrapped again to make it synchronous with run_sync.\n        #\n        # This is a good case study arguing for either some sort of\n        # extensibility in the gen decorators or cancellation support.\n        @functools.wraps(f)\n        def pre_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> Union[Generator, Coroutine]\n            # Type comments used to avoid pypy3 bug.\n            result = f(self, *args, **kwargs)\n            if isinstance(result, Generator) or inspect.iscoroutine(result):\n                self._test_generator = result\n            else:\n                self._test_generator = None\n            return result\n\n        if inspect.iscoroutinefunction(f):\n            coro = pre_coroutine\n        else:\n            coro = gen.coroutine(pre_coroutine)\n\n        @functools.wraps(coro)\n        def post_coroutine(self, *args, **kwargs):\n            # type: (AsyncTestCase, *Any, **Any) -> None\n            try:\n                return self.io_loop.run_sync(\n                    functools.partial(coro, self, *args, **kwargs), timeout=timeout\n                )\n            except TimeoutError as e:\n                # run_sync raises an error with an unhelpful traceback.\n                # If the underlying generator is still running, we can throw the\n                # exception back into it so the stack trace is replaced by the\n                # point where the test is stopped. The only reason the generator\n                # would not be running would be if it were cancelled, which means\n                # a native coroutine, so we can rely on the cr_running attribute.\n                if self._test_generator is not None and getattr(\n                    self._test_generator, \"cr_running\", True\n                ):\n                    self._test_generator.throw(type(e), e)\n                    # In case the test contains an overly broad except\n                    # clause, we may get back here.\n                # Coroutine was stopped or didn't raise a useful stack trace,\n                # so re-raise the original exception which is better than nothing.\n                raise\n\n        return post_coroutine\n\n    if func is not None:\n        # Used like:\n        #     @gen_test\n        #     def f(self):\n        #         pass\n        return wrap(func)\n    else:\n        # Used like @gen_test(timeout=10)\n        return wrap", "fpath_tuple": ["tornado", "testing.py"], "function_name": "gen_test", "lineno": 0, "context_start_lineno": 0, "_id": 9, "query_window": {"context": "from typing import Optional, Callable, TypeVar, Any\nfrom tornado import gen\nfrom tornado.testing import AsyncTestCase\nFuncType = TypeVar('FuncType', bound=Callable[..., Any])\ndef gen_test(\n    func: Optional[FuncType] = None,\n    timeout: Optional[float] = None,\n) -> Callable[[FuncType], FuncType]:\n    \"\"\"\n    Testing equivalent of ``gen.coroutine``, to be applied to test methods.", "metadata": {"fpath_tuple": ["tornado", "testing.py"], "line_no": 0, "prediction": "from typing import Optional, Callable, TypeVar, Any\nfrom tornado import gen\nfrom tornado.testing import AsyncTestCase\n\nFuncType = TypeVar('FuncType', bound=Callable[..., Any])\n\ndef gen_test(\n    func: Optional[FuncType] = None,\n    timeout: Optional[float] = None,\n) -> Callable[[FuncType], FuncType]:\n    \"\"\"\n    Testing equivalent of ``gen.coroutine``, to be applied to test methods.\n\n    ``@gen.coroutine`` cannot be used on tests because the `.IOLoop` is not\n    already running.  ``@gen_test`` should be applied to test methods\n    on subclasses of `AsyncTestCase`.\n\n    Example:\n\n    class MyTest(AsyncTestCase):\n        @gen_test\n        def test_something(self):\n            response = yield self.http_client.fetch(self.get_url('/'))\n\n    By default, ``@gen_test`` times out after 5 seconds. The timeout may be\n    overridden globally with the ``ASYNC_TEST_TIMEOUT`` environment variable,\n    or for each test with the ``timeout`` keyword argument.\n    \"\"\"\n\n    if func is None:\n        # If no function is provided, we are in the case of being used as a decorator.\n        return lambda f: gen_test(f, timeout)\n\n    # Set the timeout for the test if specified\n    if timeout is not None:\n        AsyncTestCase.set_timeout(timeout)\n\n    # Wrap the function to make it work with the Tornado's IOLoop\n    @gen.coroutine\n    def wrapped(*args, **kwargs):\n        # Call the original test function\n        result = yield func(*args, **kwargs)\n        raise gen.Return(result)\n    \n    # Set the wrapped function's attributes to retain metadata\n    wrapped.__name__ = func.__name__\n    wrapped.__doc__ = func.__doc__\n\n    return wrapped", "task_id": "tornado/id9", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "def _fake_ctx_run(f: Callable[..., _T], *args: Any, **kw: Any) -> _T:\n    return f(*args, **kw)\n\n\n@overload\ndef coroutine(\n    func: Callable[..., \"Generator[Any, Any, _T]\"]\n) -> Callable[..., \"Future[_T]\"]:\n    ...\n\n\n@overload\ndef coroutine(func: Callable[..., _T]) -> Callable[..., \"Future[_T]\"]:\n    ...\n\n\ndef coroutine(\n    func: Union[Callable[..., \"Generator[Any, Any, _T]\"], Callable[..., _T]]\n) -> Callable[..., \"Future[_T]\"]:\n    \"\"\"Decorator for asynchronous generators.", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23469387755102042}, {"context": "from tornado.testing import AsyncTestCase, bind_unused_port, gen_test\n\n\nclass MiscFutureTest(AsyncTestCase):\n    def test_future_set_result_unless_cancelled(self):\n        fut = Future()  # type: Future[int]\n        future_set_result_unless_cancelled(fut, 42)\n        self.assertEqual(fut.result(), 42)\n        self.assertFalse(fut.cancelled())\n\n        fut = Future()\n        fut.cancel()\n        is_cancelled = fut.cancelled()\n        future_set_result_unless_cancelled(fut, 42)\n        self.assertEqual(fut.cancelled(), is_cancelled)\n        if not is_cancelled:\n            self.assertEqual(fut.result(), 42)\n\n\n# The following series of classes demonstrate and test various styles", "metadata": [{"fpath_tuple": ["tornado", "test", "concurrent_test.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21052631578947367}, {"context": "from tornado import gen, ioloop\nfrom tornado.httpserver import HTTPServer\nfrom tornado.locks import Event\nfrom tornado.testing import AsyncHTTPTestCase, AsyncTestCase, bind_unused_port, gen_test\nfrom tornado.web import Application\nimport asyncio\nimport contextlib\nimport gc\nimport os\nimport platform\nimport traceback\nimport unittest\nimport warnings\n\n\n@contextlib.contextmanager\ndef set_environ(name, value):\n    old_value = os.environ.get(name)\n    os.environ[name] = value\n", "metadata": [{"fpath_tuple": ["tornado", "test", "testing_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20952380952380953}, {"context": "\"\"\"\n\n\ndef define(\n    name: str,\n    default: Any = None,\n    type: Optional[type] = None,\n    help: Optional[str] = None,\n    metavar: Optional[str] = None,\n    multiple: bool = False,\n    group: Optional[str] = None,\n    callback: Optional[Callable[[Any], None]] = None,\n) -> None:\n    \"\"\"Defines an option in the global namespace.\n\n    See `OptionParser.define`.\n    \"\"\"\n    return options.define(\n        name,\n        default=default,", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2079207920792079}, {"context": "    \"\"\"Parses global options from a config file.\n\n    See `OptionParser.parse_config_file`.\n    \"\"\"\n    return options.parse_config_file(path, final=final)\n\n\ndef print_help(file: Optional[TextIO] = None) -> None:\n    \"\"\"Prints all the command line options to stderr (or another file).\n\n    See `OptionParser.print_help`.\n    \"\"\"\n    return options.print_help(file)\n\n\ndef add_parse_callback(callback: Callable[[], None]) -> None:\n    \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n\n    See `OptionParser.add_parse_callback`\n    \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20689655172413793}, {"context": "\n\n@typing.overload\ndef future_add_done_callback(\n    future: \"futures.Future[_T]\", callback: Callable[[\"futures.Future[_T]\"], None]\n) -> None:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef future_add_done_callback(\n    future: \"Future[_T]\", callback: Callable[[\"Future[_T]\"], None]\n) -> None:\n    pass\n\n\ndef future_add_done_callback(  # noqa: F811\n    future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n) -> None:\n    \"\"\"Arrange to call ``callback`` when ``future`` is complete.", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20588235294117646}, {"context": "    put = _unimplemented_method  # type: Callable[..., Optional[Awaitable[None]]]\n    options = _unimplemented_method  # type: Callable[..., Optional[Awaitable[None]]]\n\n    def prepare(self) -> Optional[Awaitable[None]]:\n        \"\"\"Called at the beginning of a request before  `get`/`post`/etc.\n\n        Override this method to perform common initialization regardless\n        of the request method.\n\n        Asynchronous support: Use ``async def`` or decorate this method with\n        `.gen.coroutine` to make it asynchronous.\n        If this method returns an  ``Awaitable`` execution will not proceed\n        until the ``Awaitable`` is done.\n\n        .. versionadded:: 3.1\n           Asynchronous support.\n        \"\"\"\n        pass\n\n    def on_finish(self) -> None:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20437956204379562}, {"context": "            IOLoop._current.instance = None\n\n    def _clear_current_hook(self) -> None:\n        \"\"\"Instance method called when an IOLoop ceases to be current.\n\n        May be overridden by subclasses as a counterpart to make_current.\n        \"\"\"\n        pass\n\n    @classmethod\n    def configurable_base(cls) -> Type[Configurable]:\n        return IOLoop\n\n    @classmethod\n    def configurable_default(cls) -> Type[Configurable]:\n        from tornado.platform.asyncio import AsyncIOLoop\n\n        return AsyncIOLoop\n\n    def initialize(self, make_current: Optional[bool] = None) -> None:", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20353982300884957}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# \"\"\"\n# \n# import array\n# import atexit\n# from inspect import getfullargspec\n# import os\n# import re\n# import typing\n# import zlib\n# \n# from typing import (\n#     Any,\n#     Optional,\n#     Dict,\n#     Mapping,\n#     List,\n#     Tuple,\n#     Match,\n#     Callable,\n#     Type,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     \"\"\"\n#     start = start or 0\n#     end = (end or total) - 1\n#     return \"bytes %s-%s/%s\" % (start, end, total)\n# \n# \n# def _int_or_none(val: str) -> Optional[int]:\n#     val = val.strip()\n#     if val == \"\":\n#         return None\n#     return int(val)\n# \n# \n# def parse_body_arguments(\n#     content_type: str,\n#     body: bytes,\n#     arguments: Dict[str, List[bytes]],\n#     files: Dict[str, List[HTTPFile]],\n#     headers: Optional[HTTPHeaders] = None,\n# ) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# log.py\n# --------------------------------------------------\n# import logging.handlers\n# import sys\n# \n# from tornado.escape import _unicode\n# from tornado.util import unicode_type, basestring_type\n# \n# try:\n#     import colorama  # type: ignore\n# except ImportError:\n#     colorama = None\n# \n# try:\n#     import curses\n# except ImportError:\n#     curses = None  # type: ignore\n# \n# from typing import Dict, Any, cast, Optional\n# \n# # Logger objects for internal tornado use\n# access_log = logging.getLogger(\"tornado.access\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     return key_version\n# \n# \n# def _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n#     hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n#     for part in parts:\n#         hash.update(utf8(part))\n#     return utf8(hash.hexdigest())\n# \n# \n# def _create_signature_v2(secret: Union[str, bytes], s: bytes) -> bytes:\n#     hash = hmac.new(utf8(secret), digestmod=hashlib.sha256)\n#     hash.update(utf8(s))\n#     return utf8(hash.hexdigest())\n# \n# \n# def is_absolute(path: str) -> bool:\n#     return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n#     value = utf8(value)\n#     version = _get_version(value)\n#     if version < 2:\n#         return None\n#     try:\n#         key_version, _, _, _, _ = _decode_fields_v2(value)\n#     except ValueError:\n#         return None\n# \n#     return key_version\n# \n# \n# def _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n#     hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n#     for part in parts:\n#         hash.update(utf8(part))\n#     return utf8(hash.hexdigest())\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# import textwrap\n# \n# from tornado.escape import _unicode, native_str\n# from tornado.log import define_logging_options\n# from tornado.util import basestring_type, exec_in\n# \n# from typing import (\n#     Any,\n#     Iterator,\n#     Iterable,\n#     Tuple,\n#     Set,\n#     Dict,\n#     Callable,\n#     List,\n#     TextIO,\n#     Optional,\n# )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#     HTTPFile,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado.log import gen_log\n# from tornado.testing import ExpectLog\n# \n# import copy\n# import datetime\n# import logging\n# import pickle\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# \n# import html.entities\n# import json\n# import re\n# import urllib.parse\n# \n# from tornado.util import unicode_type\n# \n# import typing\n# from typing import Union, Any, Optional, Dict, List, Callable\n# \n# \n# _XHTML_ESCAPE_RE = re.compile(\"[&<>\\\"']\")\n# _XHTML_ESCAPE_DICT = {\n#     \"&\": \"&amp;\",\n#     \"<\": \"&lt;\",\n#     \">\": \"&gt;\",\n#     '\"': \"&quot;\",\n#     \"'\": \"&#39;\",\n# }\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# simple_httpclient.py\n# --------------------------------------------------\n# from tornado.log import gen_log\n# from tornado.tcpclient import TCPClient\n# \n# import base64\n# import collections\n# import copy\n# import functools\n# import re\n# import socket\n# import ssl\n# import sys\n# import time\n# from io import BytesIO\n# import urllib.parse\n# \n# from typing import Dict, Any, Callable, Optional, Type, Union\n# from types import TracebackType\n# import typing\n# \n# if typing.TYPE_CHECKING:\n# --------------------------------------------------\n\ndef _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n", "metadata": {"task_id": "tornado/id10", "ground_truth": "def _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See http://oauth.net/core/1.0/#signing_process\n    \"\"\"\n    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(\n            \"%s=%s\" % (k, _oauth_escape(str(v))) for k, v in sorted(parameters.items())\n        )\n    )\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n\n    key_elems = [escape.utf8(consumer_token[\"secret\"])]\n    key_elems.append(escape.utf8(token[\"secret\"] if token else \"\"))\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]", "fpath_tuple": ["tornado", "auth.py"], "function_name": "_oauth_signature", "lineno": 0, "context_start_lineno": 0, "_id": 10, "query_window": {"context": "import hmac\nimport hashlib\nimport base64\nimport urllib.parse\nfrom typing import Dict, Any, Optional\ndef _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},", "metadata": {"fpath_tuple": ["tornado", "auth.py"], "line_no": 0, "prediction": "import hmac\nimport hashlib\nimport base64\nimport urllib.parse\nfrom typing import Dict, Any, Optional\n\ndef _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n\n    See httpoauth.net/core/.0/#sning_process\n    \"\"\"\n    \n    # Include the necessary OAuth parameters\n    oauth_params = {\n        'oauth_consumer_key': consumer_token['key'],\n        'oauth_nonce': consumer_token['nonce'],\n        'oauth_signature_method': 'HMAC-SHA1',\n        'oauth_timestamp': consumer_token['timestamp'],\n        'oauth_version': '1.0',\n    }\n\n    if token:\n        oauth_params['oauth_token'] = token['key']\n    \n    # Combine parameters\n    all_params = {**parameters, **oauth_params}\n    \n    # Percent-encode the parameters\n    encoded_params = '&'.join(\n        f\"{urllib.parse.quote(str(k), safe='')}={urllib.parse.quote(str(v), safe='')}\"\n        for k, v in sorted(all_params.items())\n    )\n    \n    # Create the base string\n    base_string = '&'.join([\n        method.upper(),\n        urllib.parse.quote(url, safe=''),\n        urllib.parse.quote(encoded_params, safe='')\n    ])\n    \n    # Create the signing key\n    signing_key = f\"{urllib.parse.quote(consumer_token['secret'], safe='')}&\"\n    if token:\n        signing_key += urllib.parse.quote(token['secret'], safe='')\n\n    # Create the HMAC-SHA1 signature\n    signature = hmac.new(\n        signing_key.encode('utf-8'),\n        base_string.encode('utf-8'),\n        hashlib.sha1\n    ).digest()\n    \n    # Return the base64 encoded signature\n    return base64.b64encode(signature)", "task_id": "tornado/id10", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "from tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing\n\nif typing.TYPE_CHECKING:", "metadata": [{"fpath_tuple": ["tornado", "simple_httpclient.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24050632911392406}, {"context": "    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23809523809523808}, {"context": "\nimport html.entities\nimport json\nimport re\nimport urllib.parse\n\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable\n\n\n_XHTML_ESCAPE_RE = re.compile(\"[&<>\\\"']\")\n_XHTML_ESCAPE_DICT = {\n    \"&\": \"&amp;\",\n    \"<\": \"&lt;\",\n    \">\": \"&gt;\",\n    '\"': \"&quot;\",\n    \"'\": \"&#39;\",\n}", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21505376344086022}, {"context": "    HTTPFile,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado.log import gen_log\nfrom tornado.testing import ExpectLog\n\nimport copy\nimport datetime\nimport logging\nimport pickle\nimport time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20618556701030927}, {"context": "import textwrap\n\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\n\nfrom typing import (\n    Any,\n    Iterator,\n    Iterable,\n    Tuple,\n    Set,\n    Dict,\n    Callable,\n    List,\n    TextIO,\n    Optional,\n)\n\n", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2}, {"context": "def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n    value = utf8(value)\n    version = _get_version(value)\n    if version < 2:\n        return None\n    try:\n        key_version, _, _, _, _ = _decode_fields_v2(value)\n    except ValueError:\n        return None\n\n    return key_version\n\n\ndef _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n    for part in parts:\n        hash.update(utf8(part))\n    return utf8(hash.hexdigest())\n\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3570, "start_line_no": 3560, "end_line_no": 3580, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19607843137254902}, {"context": "    return key_version\n\n\ndef _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n    for part in parts:\n        hash.update(utf8(part))\n    return utf8(hash.hexdigest())\n\n\ndef _create_signature_v2(secret: Union[str, bytes], s: bytes) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha256)\n    hash.update(utf8(s))\n    return utf8(hash.hexdigest())\n\n\ndef is_absolute(path: str) -> bool:\n    return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3580, "start_line_no": 3570, "end_line_no": 3588, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1941747572815534}, {"context": "import logging.handlers\nimport sys\n\nfrom tornado.escape import _unicode\nfrom tornado.util import unicode_type, basestring_type\n\ntry:\n    import colorama  # type: ignore\nexcept ImportError:\n    colorama = None\n\ntry:\n    import curses\nexcept ImportError:\n    curses = None  # type: ignore\n\nfrom typing import Dict, Any, cast, Optional\n\n# Logger objects for internal tornado use\naccess_log = logging.getLogger(\"tornado.access\")", "metadata": [{"fpath_tuple": ["tornado", "log.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18604651162790697}, {"context": "    \"\"\"\n    start = start or 0\n    end = (end or total) - 1\n    return \"bytes %s-%s/%s\" % (start, end, total)\n\n\ndef _int_or_none(val: str) -> Optional[int]:\n    val = val.strip()\n    if val == \"\":\n        return None\n    return int(val)\n\n\ndef parse_body_arguments(\n    content_type: str,\n    body: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n    headers: Optional[HTTPHeaders] = None,\n) -> None:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18556701030927836}, {"context": "\"\"\"\n\nimport array\nimport atexit\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\n\nfrom typing import (\n    Any,\n    Optional,\n    Dict,\n    Mapping,\n    List,\n    Tuple,\n    Match,\n    Callable,\n    Type,", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18181818181818182}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# \n#     mypy insists on type annotations for dict literals, so this lets us avoid\n#     the verbose types throughout this test.\n#     \"\"\"\n#     return {}, {}\n# \n# \n# class TestUrlConcat(unittest.TestCase):\n#     def test_url_concat_no_query_params(self):\n#         url = url_concat(\"https://localhost/path\", [(\"y\", \"y\"), (\"z\", \"z\")])\n#         self.assertEqual(url, \"https://localhost/path?y=y&z=z\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     .. versionadded:: 3.2\n#     \"\"\"\n# \n#     pass\n# \n# \n# class _DecompressTooLargeError(Exception):\n#     pass\n# \n# \n# class _WebSocketParams(object):\n#     def __init__(\n#         self,\n#         ping_interval: Optional[float] = None,\n#         ping_timeout: Optional[float] = None,\n#         max_message_size: int = _default_max_message_size,\n#         compression_options: Optional[Dict[str, Any]] = None,\n#     ) -> None:\n#         self.ping_interval = ping_interval\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httpclient.py\n# --------------------------------------------------\n#     def __init__(\n#         self, request: HTTPRequest, defaults: Optional[Dict[str, Any]]\n#     ) -> None:\n#         self.request = request\n#         self.defaults = defaults\n# \n#     def __getattr__(self, name: str) -> Any:\n#         request_attr = getattr(self.request, name)\n#         if request_attr is not None:\n#             return request_attr\n#         elif self.defaults is not None:\n#             return self.defaults.get(name, None)\n#         else:\n#             return None\n# \n# \n# def main() -> None:\n#     from tornado.options import define, options, parse_command_line\n# \n#     define(\"print_headers\", type=bool, default=False)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n#     value = utf8(value)\n#     version = _get_version(value)\n#     if version < 2:\n#         return None\n#     try:\n#         key_version, _, _, _, _ = _decode_fields_v2(value)\n#     except ValueError:\n#         return None\n# \n#     return key_version\n# \n# \n# def _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n#     hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n#     for part in parts:\n#         hash.update(utf8(part))\n#     return utf8(hash.hexdigest())\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# simple_httpclient.py\n# --------------------------------------------------\n# from tornado.log import gen_log\n# from tornado.tcpclient import TCPClient\n# \n# import base64\n# import collections\n# import copy\n# import functools\n# import re\n# import socket\n# import ssl\n# import sys\n# import time\n# from io import BytesIO\n# import urllib.parse\n# \n# from typing import Dict, Any, Callable, Optional, Type, Union\n# from types import TracebackType\n# import typing\n# \n# if typing.TYPE_CHECKING:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         \"\"\"\n#         options = dict(\n#             persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n#         )  # type: Dict[str, Any]\n#         wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n#         if wbits_header is None:\n#             options[\"max_wbits\"] = zlib.MAX_WBITS\n#         else:\n#             options[\"max_wbits\"] = int(wbits_header)\n#         options[\"compression_options\"] = compression_options\n#         return options\n# \n#     def _create_compressors(\n#         self,\n#         side: str,\n#         agreed_parameters: Dict[str, Any],\n#         compression_options: Optional[Dict[str, Any]] = None,\n#     ) -> None:\n#         # TODO: handle invalid parameters gracefully\n#         allowed_keys = set(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# \n# import html.entities\n# import json\n# import re\n# import urllib.parse\n# \n# from tornado.util import unicode_type\n# \n# import typing\n# from typing import Union, Any, Optional, Dict, List, Callable\n# \n# \n# _XHTML_ESCAPE_RE = re.compile(\"[&<>\\\"']\")\n# _XHTML_ESCAPE_DICT = {\n#     \"&\": \"&amp;\",\n#     \"<\": \"&lt;\",\n#     \">\": \"&gt;\",\n#     '\"': \"&quot;\",\n#     \"'\": \"&#39;\",\n# }\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#     HTTPFile,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado.log import gen_log\n# from tornado.testing import ExpectLog\n# \n# import copy\n# import datetime\n# import logging\n# import pickle\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n# --------------------------------------------------\n\ndef _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n", "metadata": {"task_id": "tornado/id11", "ground_truth": "def _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See http://oauth.net/core/1.0a/#signing_process\n    \"\"\"\n    parts = urllib.parse.urlparse(url)\n    scheme, netloc, path = parts[:3]\n    normalized_url = scheme.lower() + \"://\" + netloc.lower() + path\n\n    base_elems = []\n    base_elems.append(method.upper())\n    base_elems.append(normalized_url)\n    base_elems.append(\n        \"&\".join(\n            \"%s=%s\" % (k, _oauth_escape(str(v))) for k, v in sorted(parameters.items())\n        )\n    )\n\n    base_string = \"&\".join(_oauth_escape(e) for e in base_elems)\n    key_elems = [escape.utf8(urllib.parse.quote(consumer_token[\"secret\"], safe=\"~\"))]\n    key_elems.append(\n        escape.utf8(urllib.parse.quote(token[\"secret\"], safe=\"~\") if token else \"\")\n    )\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]", "fpath_tuple": ["tornado", "auth.py"], "function_name": "_oauth10a_signature", "lineno": 0, "context_start_lineno": 0, "_id": 11, "query_window": {"context": "import hmac\nimport hashlib\nimport urllib.parse\nfrom typing import Dict, Any, Optional\ndef _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,", "metadata": {"fpath_tuple": ["tornado", "auth.py"], "line_no": 0, "prediction": "import hmac\nimport hashlib\nimport urllib.parse\nfrom typing import Dict, Any, Optional\n\ndef _oauth10a_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth 1.0a signature for the given request.\n\n    See httpoauth.net/core/10a/#signing_process\n    \"\"\"\n    \n    # Step 1: Normalize the parameters\n    oauth_parameters = {\n        'oauth_consumer_key': consumer_token['key'],\n        'oauth_nonce': str(int(time.time())),  # Create a unique nonce\n        'oauth_signature_method': 'HMAC-SHA1',\n        'oauth_timestamp': str(int(time.time())),  # Current timestamp\n        'oauth_version': '1.0'\n    }\n    \n    if token:\n        oauth_parameters['oauth_token'] = token['key']\n    \n    # Combine the provided parameters with OAuth parameters\n    all_parameters = {**oauth_parameters, **parameters}\n    \n    # Step 2: Create the signature base string\n    encoded_parameters = urllib.parse.urlencode(sorted(all_parameters.items()))\n    base_string = '&'.join([\n        method.upper(),\n        urllib.parse.quote(url, safe=''),\n        urllib.parse.quote(encoded_parameters, safe='')\n    ])\n    \n    # Step 3: Create the signing key\n    signing_key = f\"{urllib.parse.quote(consumer_token['secret'], safe='')}\"\n\n    if token:\n        signing_key += f\"&{urllib.parse.quote(token['secret'], safe='')}\"\n    \n    # Step 4: Calculate the HMAC-SHA1 signature\n    signature = hmac.new(\n        signing_key.encode(),\n        base_string.encode(),\n        hashlib.sha1\n    ).digest()\n    \n    return signature", "task_id": "tornado/id11", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2413793103448276}, {"context": "    HTTPFile,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado.log import gen_log\nfrom tornado.testing import ExpectLog\n\nimport copy\nimport datetime\nimport logging\nimport pickle\nimport time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2222222222222222}, {"context": "\nimport html.entities\nimport json\nimport re\nimport urllib.parse\n\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable\n\n\n_XHTML_ESCAPE_RE = re.compile(\"[&<>\\\"']\")\n_XHTML_ESCAPE_DICT = {\n    \"&\": \"&amp;\",\n    \"<\": \"&lt;\",\n    \">\": \"&gt;\",\n    '\"': \"&quot;\",\n    \"'\": \"&#39;\",\n}", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21875}, {"context": "        \"\"\"\n        options = dict(\n            persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n        )  # type: Dict[str, Any]\n        wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n        if wbits_header is None:\n            options[\"max_wbits\"] = zlib.MAX_WBITS\n        else:\n            options[\"max_wbits\"] = int(wbits_header)\n        options[\"compression_options\"] = compression_options\n        return options\n\n    def _create_compressors(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        # TODO: handle invalid parameters gracefully\n        allowed_keys = set(", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20175438596491227}, {"context": "from tornado.log import gen_log\nfrom tornado.tcpclient import TCPClient\n\nimport base64\nimport collections\nimport copy\nimport functools\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nfrom io import BytesIO\nimport urllib.parse\n\nfrom typing import Dict, Any, Callable, Optional, Type, Union\nfrom types import TracebackType\nimport typing\n\nif typing.TYPE_CHECKING:", "metadata": [{"fpath_tuple": ["tornado", "simple_httpclient.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2}, {"context": "def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n    value = utf8(value)\n    version = _get_version(value)\n    if version < 2:\n        return None\n    try:\n        key_version, _, _, _, _ = _decode_fields_v2(value)\n    except ValueError:\n        return None\n\n    return key_version\n\n\ndef _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n    for part in parts:\n        hash.update(utf8(part))\n    return utf8(hash.hexdigest())\n\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3570, "start_line_no": 3560, "end_line_no": 3580, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2}, {"context": "    def __init__(\n        self, request: HTTPRequest, defaults: Optional[Dict[str, Any]]\n    ) -> None:\n        self.request = request\n        self.defaults = defaults\n\n    def __getattr__(self, name: str) -> Any:\n        request_attr = getattr(self.request, name)\n        if request_attr is not None:\n            return request_attr\n        elif self.defaults is not None:\n            return self.defaults.get(name, None)\n        else:\n            return None\n\n\ndef main() -> None:\n    from tornado.options import define, options, parse_command_line\n\n    define(\"print_headers\", type=bool, default=False)", "metadata": [{"fpath_tuple": ["tornado", "httpclient.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19387755102040816}, {"context": "\n    .. versionadded:: 3.2\n    \"\"\"\n\n    pass\n\n\nclass _DecompressTooLargeError(Exception):\n    pass\n\n\nclass _WebSocketParams(object):\n    def __init__(\n        self,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        self.ping_interval = ping_interval", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1935483870967742}, {"context": "import time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n\n    mypy insists on type annotations for dict literals, so this lets us avoid\n    the verbose types throughout this test.\n    \"\"\"\n    return {}, {}\n\n\nclass TestUrlConcat(unittest.TestCase):\n    def test_url_concat_no_query_params(self):\n        url = url_concat(\"https://localhost/path\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?y=y&z=z\")", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19285714285714287}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n#     ``callback`` is invoked with one argument, the ``future``.\n# \n#     If ``future`` is already done, ``callback`` is invoked immediately.\n#     This may differ from the behavior of ``Future.add_done_callback``,\n#     which makes no such guarantee.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if future.done():\n#         callback(future)\n#     else:\n#         future.add_done_callback(callback)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n#     .. versionchanged:: 6.0\n# \n#        If the future is already cancelled, this function is a no-op.\n#        (previously ``asyncio.InvalidStateError`` would be raised)\n# \n#     \"\"\"\n#     if exc_info[1] is None:\n#         raise Exception(\"future_set_exc_info called with no exception\")\n#     future_set_exception_unless_cancelled(future, exc_info[1])\n# \n# \n# @typing.overload\n# def future_add_done_callback(\n#     future: \"futures.Future[_T]\", callback: Callable[[\"futures.Future[_T]\"], None]\n# ) -> None:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# --------------------------------------------------\n# the below code fragment can be found in:\n# netutil.py\n# --------------------------------------------------\n#     ``close_resolver=False``; use this if you want to reuse the same\n#     executor elsewhere.\n# \n#     .. versionchanged:: 5.0\n#        The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n# \n#     .. deprecated:: 5.0\n#        The default `Resolver` now uses `.IOLoop.run_in_executor`; use that instead\n#        of this class.\n#     \"\"\"\n# \n#     def initialize(\n#         self,\n#         executor: Optional[concurrent.futures.Executor] = None,\n#         close_executor: bool = True,\n#     ) -> None:\n#         self.io_loop = IOLoop.current()\n#         if executor is not None:\n#             self.executor = executor\n#             self.close_executor = close_executor\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n# def convert_yielded(yielded: _Yieldable) -> Future:\n#     \"\"\"Convert a yielded object into a `.Future`.\n# \n#     The default implementation accepts lists, dictionaries, and\n#     Futures. This has the side effect of starting any coroutines that\n#     did not start themselves, similar to `asyncio.ensure_future`.\n# \n#     If the `~functools.singledispatch` library is available, this function\n#     may be extended to support additional types. For example::\n# \n#         @convert_yielded.register(asyncio.Future)\n#         def _(asyncio_future):\n#             return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n# \n#     .. versionadded:: 4.1\n# \n#     \"\"\"\n#     if yielded is None or yielded is moment:\n#         return moment\n#     elif yielded is _null_future:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"Calls the given callback on the next IOLoop iteration.\n# \n#         As of Tornado 6.0, this method is equivalent to `add_callback`.\n# \n#         .. versionadded:: 4.0\n#         \"\"\"\n#         self.add_callback(callback, *args, **kwargs)\n# \n#     def add_future(\n#         self,\n#         future: \"Union[Future[_T], concurrent.futures.Future[_T]]\",\n#         callback: Callable[[\"Future[_T]\"], None],\n#     ) -> None:\n#         \"\"\"Schedules a callback on the ``IOLoop`` when the given\n#         `.Future` is finished.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n#     exc_info: Tuple[\n#         Optional[type], Optional[BaseException], Optional[types.TracebackType]\n#     ],\n# ) -> None:\n#     \"\"\"Set the given ``exc_info`` as the `Future`'s exception.\n# \n#     Understands both `asyncio.Future` and the extensions in older\n#     versions of Tornado to enable better tracebacks on Python 2.\n# \n#     .. versionadded:: 5.0\n# \n#     .. versionchanged:: 6.0\n# \n#        If the future is already cancelled, this function is a no-op.\n#        (previously ``asyncio.InvalidStateError`` would be raised)\n# \n#     \"\"\"\n#     if exc_info[1] is None:\n#         raise Exception(\"future_set_exc_info called with no exception\")\n#     future_set_exception_unless_cancelled(future, exc_info[1])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n# \n# def future_set_result_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n# ) -> None:\n#     \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n# \n#     Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n#     a cancelled `asyncio.Future`.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if not future.cancelled():\n#         future.set_result(value)\n# \n# \n# def future_set_exception_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n# ) -> None:\n#     \"\"\"Set the given ``exc`` as the `Future`'s exception.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n#     \"\"\"Chain two futures together so that when one completes, so does the other.\n# \n#     The result (success or failure) of ``a`` will be copied to ``b``, unless\n#     ``b`` has already been completed or cancelled by the time ``a`` finishes.\n# \n#     .. versionchanged:: 5.0\n# \n#        Now accepts both Tornado/asyncio `Future` objects and\n#        `concurrent.futures.Future`.\n# \n#     \"\"\"\n# \n#     def copy(future: \"Future[_T]\") -> None:\n#         assert future is a\n#         if b.done():\n#             return\n#         if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n#             future_set_exc_info(b, a.exc_info())  # type: ignore\n#         elif a.exception() is not None:\n#             b.set_exception(a.exception())\n# --------------------------------------------------\n\ndef to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n    Tornado ``Futures`` have been merged with `asyncio.Future`,\n    so this method is now a no-op.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id12", "ground_truth": "def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future", "fpath_tuple": ["tornado", "platform", "asyncio.py"], "function_name": "to_tornado_future", "lineno": 0, "context_start_lineno": 0, "_id": 12, "query_window": {"context": "import asyncio\ndef to_tornado_future(future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n    .. versionadded:: 4.1\n    .. deprecated:: 5.0\n    Tornado ``Futures`` have been merged with `asyncio.Future`,\n    so this method is now a no-op.\n    \"\"\"\n    return future", "metadata": {"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 0, "prediction": "import asyncio\n\ndef to_tornado_future(future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n    Tornado ``Futures`` have been merged with `asyncio.Future`,\n    so this method is now a no-op.\n    \"\"\"\n    return future", "task_id": "tornado/id12", "start_line_no": 0, "end_line_no": 9, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    \"\"\"Chain two futures together so that when one completes, so does the other.\n\n    The result (success or failure) of ``a`` will be copied to ``b``, unless\n    ``b`` has already been completed or cancelled by the time ``a`` finishes.\n\n    .. versionchanged:: 5.0\n\n       Now accepts both Tornado/asyncio `Future` objects and\n       `concurrent.futures.Future`.\n\n    \"\"\"\n\n    def copy(future: \"Future[_T]\") -> None:\n        assert future is a\n        if b.done():\n            return\n        if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n            future_set_exc_info(b, a.exc_info())  # type: ignore\n        elif a.exception() is not None:\n            b.set_exception(a.exception())", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2748091603053435}, {"context": "\n\ndef future_set_result_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n) -> None:\n    \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if not future.cancelled():\n        future.set_result(value)\n\n\ndef future_set_exception_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n) -> None:\n    \"\"\"Set the given ``exc`` as the `Future`'s exception.", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26605504587155965}, {"context": "    exc_info: Tuple[\n        Optional[type], Optional[BaseException], Optional[types.TracebackType]\n    ],\n) -> None:\n    \"\"\"Set the given ``exc_info`` as the `Future`'s exception.\n\n    Understands both `asyncio.Future` and the extensions in older\n    versions of Tornado to enable better tracebacks on Python 2.\n\n    .. versionadded:: 5.0\n\n    .. versionchanged:: 6.0\n\n       If the future is already cancelled, this function is a no-op.\n       (previously ``asyncio.InvalidStateError`` would be raised)\n\n    \"\"\"\n    if exc_info[1] is None:\n        raise Exception(\"future_set_exc_info called with no exception\")\n    future_set_exception_unless_cancelled(future, exc_info[1])", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2631578947368421}, {"context": "        \"\"\"\n        raise NotImplementedError()\n\n    def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Calls the given callback on the next IOLoop iteration.\n\n        As of Tornado 6.0, this method is equivalent to `add_callback`.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        self.add_callback(callback, *args, **kwargs)\n\n    def add_future(\n        self,\n        future: \"Union[Future[_T], concurrent.futures.Future[_T]]\",\n        callback: Callable[[\"Future[_T]\"], None],\n    ) -> None:\n        \"\"\"Schedules a callback on the ``IOLoop`` when the given\n        `.Future` is finished.\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 660, "start_line_no": 650, "end_line_no": 670, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2627118644067797}, {"context": "def convert_yielded(yielded: _Yieldable) -> Future:\n    \"\"\"Convert a yielded object into a `.Future`.\n\n    The default implementation accepts lists, dictionaries, and\n    Futures. This has the side effect of starting any coroutines that\n    did not start themselves, similar to `asyncio.ensure_future`.\n\n    If the `~functools.singledispatch` library is available, this function\n    may be extended to support additional types. For example::\n\n        @convert_yielded.register(asyncio.Future)\n        def _(asyncio_future):\n            return tornado.platform.asyncio.to_tornado_future(asyncio_future)\n\n    .. versionadded:: 4.1\n\n    \"\"\"\n    if yielded is None or yielded is moment:\n        return moment\n    elif yielded is _null_future:", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 850, "start_line_no": 840, "end_line_no": 860, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25735294117647056}, {"context": "    ``close_resolver=False``; use this if you want to reuse the same\n    executor elsewhere.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. deprecated:: 5.0\n       The default `Resolver` now uses `.IOLoop.run_in_executor`; use that instead\n       of this class.\n    \"\"\"\n\n    def initialize(\n        self,\n        executor: Optional[concurrent.futures.Executor] = None,\n        close_executor: bool = True,\n    ) -> None:\n        self.io_loop = IOLoop.current()\n        if executor is not None:\n            self.executor = executor\n            self.close_executor = close_executor", "metadata": [{"fpath_tuple": ["tornado", "netutil.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.256198347107438}, {"context": "\n    .. versionchanged:: 6.0\n\n       If the future is already cancelled, this function is a no-op.\n       (previously ``asyncio.InvalidStateError`` would be raised)\n\n    \"\"\"\n    if exc_info[1] is None:\n        raise Exception(\"future_set_exc_info called with no exception\")\n    future_set_exception_unless_cancelled(future, exc_info[1])\n\n\n@typing.overload\ndef future_add_done_callback(\n    future: \"futures.Future[_T]\", callback: Callable[[\"futures.Future[_T]\"], None]\n) -> None:\n    pass\n\n\n@typing.overload  # noqa: F811", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25396825396825395}, {"context": "\n    ``callback`` is invoked with one argument, the ``future``.\n\n    If ``future`` is already done, ``callback`` is invoked immediately.\n    This may differ from the behavior of ``Future.add_done_callback``,\n    which makes no such guarantee.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if future.done():\n        callback(future)\n    else:\n        future.add_done_callback(callback)", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 263, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25287356321839083}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/netutil_test.py\n# --------------------------------------------------\n#     @unittest.skipIf(\n#         not hasattr(socket, \"SO_REUSEPORT\"), \"SO_REUSEPORT is not supported\"\n#     )\n#     def test_reuse_port(self):\n#         sockets = []  # type: List[socket.socket]\n#         socket, port = bind_unused_port(reuse_port=True)\n#         try:\n#             sockets = bind_sockets(port, \"127.0.0.1\", reuse_port=True)\n#             self.assertTrue(all(s.getsockname()[1] == port for s in sockets))\n#         finally:\n#             socket.close()\n#             for sock in sockets:\n#                 sock.close()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#         return stream\n# \n#     def _create_stream(\n#         self,\n#         max_buffer_size: int,\n#         af: socket.AddressFamily,\n#         addr: Tuple,\n#         source_ip: Optional[str] = None,\n#         source_port: Optional[int] = None,\n#     ) -> Tuple[IOStream, \"Future[IOStream]\"]:\n#         # Always connect in plaintext; we'll convert to ssl if necessary\n#         # after one connection has completed.\n#         source_port_bind = source_port if isinstance(source_port, int) else 0\n#         source_ip_bind = source_ip\n#         if source_port_bind and not source_ip:\n#             # User required a specific port, but did not specify\n#             # a certain source IP, will bind to the default loopback.\n#             source_ip_bind = \"::1\" if af == socket.AF_INET6 else \"127.0.0.1\"\n#             # Trying to use the same address family as the requested af socket:\n#             # - 127.0.0.1 for IPv4\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#             self._own_resolver = True\n# \n#     def close(self) -> None:\n#         if self._own_resolver:\n#             self.resolver.close()\n# \n#     async def connect(\n#         self,\n#         host: str,\n#         port: int,\n#         af: socket.AddressFamily = socket.AF_UNSPEC,\n#         ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n#         max_buffer_size: Optional[int] = None,\n#         source_ip: Optional[str] = None,\n#         source_port: Optional[int] = None,\n#         timeout: Optional[Union[float, datetime.timedelta]] = None,\n#     ) -> IOStream:\n#         \"\"\"Connect to the given host and port.\n# \n#         Asynchronously returns an `.IOStream` (or `.SSLIOStream` if\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         return retval\n# \n#     @overload\n#     def get_argument(self, name: str, default: str, strip: bool = True) -> str:\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: _ArgDefaultMarker = _ARG_DEFAULT, strip: bool = True\n#     ) -> str:\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: None, strip: bool = True\n#     ) -> Optional[str]:\n#         pass\n# \n#     def get_argument(  # noqa: F811\n#         self,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     Returned ``port`` will be ``None`` if not present.\n# \n#     .. versionadded:: 4.1\n#     \"\"\"\n#     match = _netloc_re.match(netloc)\n#     if match:\n#         host = match.group(1)\n#         port = int(match.group(2))  # type: Optional[int]\n#     else:\n#         host = netloc\n#         port = None\n#     return (host, port)\n# \n# \n# def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n#     \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     for k, vs in qs.items():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#                 stream = await gen.with_timeout(\n#                     timeout,\n#                     stream.start_tls(\n#                         False, ssl_options=ssl_options, server_hostname=host\n#                     ),\n#                 )\n#             else:\n#                 stream = await stream.start_tls(\n#                     False, ssl_options=ssl_options, server_hostname=host\n#                 )\n#         return stream\n# \n#     def _create_stream(\n#         self,\n#         max_buffer_size: int,\n#         af: socket.AddressFamily,\n#         addr: Tuple,\n#         source_ip: Optional[str] = None,\n#         source_port: Optional[int] = None,\n#     ) -> Tuple[IOStream, \"Future[IOStream]\"]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#         self.add_sockets([socket])\n# \n#     def bind(\n#         self,\n#         port: int,\n#         address: Optional[str] = None,\n#         family: socket.AddressFamily = socket.AF_UNSPEC,\n#         backlog: int = 128,\n#         reuse_port: bool = False,\n#     ) -> None:\n#         \"\"\"Binds this server to the given port on the given address.\n# \n#         To start the server, call `start`. If you want to run this server\n#         in a single process, you can call `listen` as a shortcut to the\n#         sequence of `bind` and `start` calls.\n# \n#         Address may be either an IP address or hostname.  If it's a hostname,\n#         the server will listen on all IP addresses associated with the\n#         name.  Address may be an empty string or None to listen on all\n#         available interfaces.  Family may be set to either `socket.AF_INET`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#         control over the initialization of a multi-process server.\n#         \"\"\"\n#         for sock in sockets:\n#             self._sockets[sock.fileno()] = sock\n#             self._handlers[sock.fileno()] = add_accept_handler(\n#                 sock, self._handle_connection\n#             )\n# \n#     def add_socket(self, socket: socket.socket) -> None:\n#         \"\"\"Singular version of `add_sockets`.  Takes a single socket object.\"\"\"\n#         self.add_sockets([socket])\n# \n#     def bind(\n#         self,\n#         port: int,\n#         address: Optional[str] = None,\n#         family: socket.AddressFamily = socket.AF_UNSPEC,\n#         backlog: int = 128,\n#         reuse_port: bool = False,\n#     ) -> None:\n# --------------------------------------------------\n\ndef bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id13", "ground_truth": "def bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n    if reuse_port and not hasattr(socket, \"SO_REUSEPORT\"):\n        raise ValueError(\"the platform doesn't support SO_REUSEPORT\")\n\n    sockets = []\n    if address == \"\":\n        address = None\n    if not socket.has_ipv6 and family == socket.AF_UNSPEC:\n        # Python can be compiled with --disable-ipv6, which causes\n        # operations on AF_INET6 sockets to fail, but does not\n        # automatically exclude those results from getaddrinfo\n        # results.\n        # http://bugs.python.org/issue16208\n        family = socket.AF_INET\n    if flags is None:\n        flags = socket.AI_PASSIVE\n    bound_port = None\n    unique_addresses = set()  # type: set\n    for res in sorted(\n        socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags),\n        key=lambda x: x[0],\n    ):\n        if res in unique_addresses:\n            continue\n\n        unique_addresses.add(res)\n\n        af, socktype, proto, canonname, sockaddr = res\n        if (\n            sys.platform == \"darwin\"\n            and address == \"localhost\"\n            and af == socket.AF_INET6\n            and sockaddr[3] != 0\n        ):\n            # Mac OS X includes a link-local address fe80::1%lo0 in the\n            # getaddrinfo results for 'localhost'.  However, the firewall\n            # doesn't understand that this is a local address and will\n            # prompt for access (often repeatedly, due to an apparent\n            # bug in its ability to remember granting access to an\n            # application). Skip these addresses.\n            continue\n        try:\n            sock = socket.socket(af, socktype, proto)\n        except socket.error as e:\n            if errno_from_exception(e) == errno.EAFNOSUPPORT:\n                continue\n            raise\n        if os.name != \"nt\":\n            try:\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            except socket.error as e:\n                if errno_from_exception(e) != errno.ENOPROTOOPT:\n                    # Hurd doesn't support SO_REUSEADDR.\n                    raise\n        if reuse_port:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        if af == socket.AF_INET6:\n            # On linux, ipv6 sockets accept ipv4 too by default,\n            # but this makes it impossible to bind to both\n            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,\n            # separate sockets *must* be used to listen for both ipv4\n            # and ipv6.  For consistency, always disable ipv4 on our\n            # ipv6 sockets and use a separate ipv4 socket when needed.\n            #\n            # Python 2.x on windows doesn't have IPPROTO_IPV6.\n            if hasattr(socket, \"IPPROTO_IPV6\"):\n                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)\n\n        # automatic port allocation with port=None\n        # should bind on the same port on IPv4 and IPv6\n        host, requested_port = sockaddr[:2]\n        if requested_port == 0 and bound_port is not None:\n            sockaddr = tuple([host, bound_port] + list(sockaddr[2:]))\n\n        sock.setblocking(False)\n        try:\n            sock.bind(sockaddr)\n        except OSError as e:\n            if (\n                errno_from_exception(e) == errno.EADDRNOTAVAIL\n                and address == \"localhost\"\n                and sockaddr[0] == \"::1\"\n            ):\n                # On some systems (most notably docker with default\n                # configurations), ipv6 is partially disabled:\n                # socket.has_ipv6 is true, we can create AF_INET6\n                # sockets, and getaddrinfo(\"localhost\", ...,\n                # AF_PASSIVE) resolves to ::1, but we get an error\n                # when binding.\n                #\n                # Swallow the error, but only for this specific case.\n                # If EADDRNOTAVAIL occurs in other situations, it\n                # might be a real problem like a typo in a\n                # configuration.\n                sock.close()\n                continue\n            else:\n                raise\n        bound_port = sock.getsockname()[1]\n        sock.listen(backlog)\n        sockets.append(sock)\n    return sockets", "fpath_tuple": ["tornado", "netutil.py"], "function_name": "bind_sockets", "lineno": 0, "context_start_lineno": 0, "_id": 13, "query_window": {"context": "import socket\nfrom typing import List, Optional\n_DEFAULT_BACKLOG = 5  # Default backlog for socket listening\ndef bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,", "metadata": {"fpath_tuple": ["tornado", "netutil.py"], "line_no": 0, "prediction": "import socket\nfrom typing import List, Optional\n\n_DEFAULT_BACKLOG = 5  # Default backlog for socket listening\n\ndef bind_sockets(\n    port: int,\n    address: Optional[str] = None,\n    family: socket.AddressFamily = socket.AF_UNSPEC,\n    backlog: int = _DEFAULT_BACKLOG,\n    flags: Optional[int] = None,\n    reuse_port: bool = False,\n) -> List[socket.socket]:\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen()`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in list. If your this option ValueError will be raised.\n    \"\"\"\n    if flags is None:\n        flags = socket.AI_PASSIVE\n\n    # Get the addresses to bind to\n    addr_info = socket.getaddrinfo(\n        address or '', port, family, socket.SOCK_STREAM, 0, flags\n    )\n\n    sockets = []\n    for res in addr_info:\n        af, socktype, proto, _, sa = res\n        sock = socket.socket(af, socktype, proto)\n        \n        if reuse_port:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n\n        sock.bind(sa)\n        sock.listen(backlog)\n        sockets.append(sock)\n\n    return sockets", "task_id": "tornado/id13", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        control over the initialization of a multi-process server.\n        \"\"\"\n        for sock in sockets:\n            self._sockets[sock.fileno()] = sock\n            self._handlers[sock.fileno()] = add_accept_handler(\n                sock, self._handle_connection\n            )\n\n    def add_socket(self, socket: socket.socket) -> None:\n        \"\"\"Singular version of `add_sockets`.  Takes a single socket object.\"\"\"\n        self.add_sockets([socket])\n\n    def bind(\n        self,\n        port: int,\n        address: Optional[str] = None,\n        family: socket.AddressFamily = socket.AF_UNSPEC,\n        backlog: int = 128,\n        reuse_port: bool = False,\n    ) -> None:", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.32673267326732675}, {"context": "        self.add_sockets([socket])\n\n    def bind(\n        self,\n        port: int,\n        address: Optional[str] = None,\n        family: socket.AddressFamily = socket.AF_UNSPEC,\n        backlog: int = 128,\n        reuse_port: bool = False,\n    ) -> None:\n        \"\"\"Binds this server to the given port on the given address.\n\n        To start the server, call `start`. If you want to run this server\n        in a single process, you can call `listen` as a shortcut to the\n        sequence of `bind` and `start` calls.\n\n        Address may be either an IP address or hostname.  If it's a hostname,\n        the server will listen on all IP addresses associated with the\n        name.  Address may be an empty string or None to listen on all\n        available interfaces.  Family may be set to either `socket.AF_INET`", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26666666666666666}, {"context": "                stream = await gen.with_timeout(\n                    timeout,\n                    stream.start_tls(\n                        False, ssl_options=ssl_options, server_hostname=host\n                    ),\n                )\n            else:\n                stream = await stream.start_tls(\n                    False, ssl_options=ssl_options, server_hostname=host\n                )\n        return stream\n\n    def _create_stream(\n        self,\n        max_buffer_size: int,\n        af: socket.AddressFamily,\n        addr: Tuple,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n    ) -> Tuple[IOStream, \"Future[IOStream]\"]:", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21649484536082475}, {"context": "    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)\n\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1040, "start_line_no": 1030, "end_line_no": 1050, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2066115702479339}, {"context": "        return retval\n\n    @overload\n    def get_argument(self, name: str, default: str, strip: bool = True) -> str:\n        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: _ArgDefaultMarker = _ARG_DEFAULT, strip: bool = True\n    ) -> str:\n        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: None, strip: bool = True\n    ) -> Optional[str]:\n        pass\n\n    def get_argument(  # noqa: F811\n        self,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20238095238095238}, {"context": "            self._own_resolver = True\n\n    def close(self) -> None:\n        if self._own_resolver:\n            self.resolver.close()\n\n    async def connect(\n        self,\n        host: str,\n        port: int,\n        af: socket.AddressFamily = socket.AF_UNSPEC,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        max_buffer_size: Optional[int] = None,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n        timeout: Optional[Union[float, datetime.timedelta]] = None,\n    ) -> IOStream:\n        \"\"\"Connect to the given host and port.\n\n        Asynchronously returns an `.IOStream` (or `.SSLIOStream` if", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20175438596491227}, {"context": "        return stream\n\n    def _create_stream(\n        self,\n        max_buffer_size: int,\n        af: socket.AddressFamily,\n        addr: Tuple,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n    ) -> Tuple[IOStream, \"Future[IOStream]\"]:\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        source_port_bind = source_port if isinstance(source_port, int) else 0\n        source_ip_bind = source_ip\n        if source_port_bind and not source_ip:\n            # User required a specific port, but did not specify\n            # a certain source IP, will bind to the default loopback.\n            source_ip_bind = \"::1\" if af == socket.AF_INET6 else \"127.0.0.1\"\n            # Trying to use the same address family as the requested af socket:\n            # - 127.0.0.1 for IPv4", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19852941176470587}, {"context": "    @unittest.skipIf(\n        not hasattr(socket, \"SO_REUSEPORT\"), \"SO_REUSEPORT is not supported\"\n    )\n    def test_reuse_port(self):\n        sockets = []  # type: List[socket.socket]\n        socket, port = bind_unused_port(reuse_port=True)\n        try:\n            sockets = bind_sockets(port, \"127.0.0.1\", reuse_port=True)\n            self.assertTrue(all(s.getsockname()[1] == port for s in sockets))\n        finally:\n            socket.close()\n            for sock in sockets:\n                sock.close()", "metadata": [{"fpath_tuple": ["tornado", "test", "netutil_test.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 233, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19811320754716982}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# autoreload.py\n# --------------------------------------------------\n#     the command-line interface in `main`)\n#     \"\"\"\n#     io_loop = ioloop.IOLoop()\n#     io_loop.add_callback(start)\n#     io_loop.start()\n# \n# \n# def watch(filename: str) -> None:\n#     \"\"\"Add a file to the watch list.\n# \n#     All imported modules are watched by default.\n#     \"\"\"\n#     _watched_files.add(filename)\n# \n# \n# def add_reload_hook(fn: Callable[[], None]) -> None:\n#     \"\"\"Add a function to be called before reloading the process.\n# \n#     Note that for open file and socket handles it is generally\n#     preferable to set the ``FD_CLOEXEC`` flag (using `fcntl` or\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         \"\"\"Cancels a pending timeout.\n# \n#         The argument is a handle as returned by `add_timeout`.  It is\n#         safe to call `remove_timeout` even if the callback has already\n#         been run.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def add_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"Calls the given callback on the next I/O loop iteration.\n# \n#         It is safe to call this method from any thread at any time,\n#         except from a signal handler.  Note that this is the **only**\n#         method in `IOLoop` that makes this thread-safety guarantee; all\n#         other interaction with the `IOLoop` must be done from that\n#         `IOLoop`'s thread.  `add_callback()` may be used to transfer\n#         control from other threads to the `IOLoop`'s thread.\n# \n#         To add a callback from a signal handler, see\n#         `add_callback_from_signal`.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \n#     def call_at(\n#         self, when: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n#     ) -> object:\n#         \"\"\"Runs the ``callback`` at the absolute time designated by ``when``.\n# \n#         ``when`` must be a number using the same reference point as\n#         `IOLoop.time`.\n# \n#         Returns an opaque handle that may be passed to `remove_timeout`\n#         to cancel.  Note that unlike the `asyncio` method of the same\n#         name, the returned object does not have a ``cancel()`` method.\n# \n#         See `add_timeout` for comments on thread-safety and subclassing.\n# \n#         .. versionadded:: 4.0\n#         \"\"\"\n#         return self.add_timeout(when, callback, *args, **kwargs)\n# \n#     def remove_timeout(self, timeout: object) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \n#         It is safe to call this method from any thread at any time,\n#         except from a signal handler.  Note that this is the **only**\n#         method in `IOLoop` that makes this thread-safety guarantee; all\n#         other interaction with the `IOLoop` must be done from that\n#         `IOLoop`'s thread.  `add_callback()` may be used to transfer\n#         control from other threads to the `IOLoop`'s thread.\n# \n#         To add a callback from a signal handler, see\n#         `add_callback_from_signal`.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def add_callback_from_signal(\n#         self, callback: Callable, *args: Any, **kwargs: Any\n#     ) -> None:\n#         \"\"\"Calls the given callback on the next I/O loop iteration.\n# \n#         Safe for use from a Python signal handler; should not be used\n#         otherwise.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     \"\"\"Parses global options from a config file.\n# \n#     See `OptionParser.parse_config_file`.\n#     \"\"\"\n#     return options.parse_config_file(path, final=final)\n# \n# \n# def print_help(file: Optional[TextIO] = None) -> None:\n#     \"\"\"Prints all the command line options to stderr (or another file).\n# \n#     See `OptionParser.print_help`.\n#     \"\"\"\n#     return options.print_help(file)\n# \n# \n# def add_parse_callback(callback: Callable[[], None]) -> None:\n#     \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n# \n#     See `OptionParser.add_parse_callback`\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     See `OptionParser.print_help`.\n#     \"\"\"\n#     return options.print_help(file)\n# \n# \n# def add_parse_callback(callback: Callable[[], None]) -> None:\n#     \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n# \n#     See `OptionParser.add_parse_callback`\n#     \"\"\"\n#     options.add_parse_callback(callback)\n# \n# \n# # Default options\n# define_logging_options(options)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         `time.time`.\n# \n#         \"\"\"\n#         return time.time()\n# \n#     def add_timeout(\n#         self,\n#         deadline: Union[float, datetime.timedelta],\n#         callback: Callable[..., None],\n#         *args: Any,\n#         **kwargs: Any\n#     ) -> object:\n#         \"\"\"Runs the ``callback`` at the time ``deadline`` from the I/O loop.\n# \n#         Returns an opaque handle that may be passed to\n#         `remove_timeout` to cancel.\n# \n#         ``deadline`` may be a number denoting a time (on the same\n#         scale as `IOLoop.time`, normally `time.time`), or a\n#         `datetime.timedelta` object for a deadline relative to the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#         sockets = bind_sockets(port, address=address)\n#         self.add_sockets(sockets)\n# \n#     def add_sockets(self, sockets: Iterable[socket.socket]) -> None:\n#         \"\"\"Makes this server start accepting connections on the given sockets.\n# \n#         The ``sockets`` parameter is a list of socket objects such as\n#         those returned by `~tornado.netutil.bind_sockets`.\n#         `add_sockets` is typically used in combination with that\n#         method and `tornado.process.fork_processes` to provide greater\n#         control over the initialization of a multi-process server.\n#         \"\"\"\n#         for sock in sockets:\n#             self._sockets[sock.fileno()] = sock\n#             self._handlers[sock.fileno()] = add_accept_handler(\n#                 sock, self._handle_connection\n#             )\n# \n#     def add_socket(self, socket: socket.socket) -> None:\n#         \"\"\"Singular version of `add_sockets`.  Takes a single socket object.\"\"\"\n# --------------------------------------------------\n\ndef add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n    The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n    A callable is returned (``None`` was returned before).\n    \"\"\"\n", "metadata": {"task_id": "tornado/id14", "ground_truth": "def add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n       A callable is returned (``None`` was returned before).\n    \"\"\"\n    io_loop = IOLoop.current()\n    removed = [False]\n\n    def accept_handler(fd: socket.socket, events: int) -> None:\n        # More connections may come in while we're handling callbacks;\n        # to prevent starvation of other tasks we must limit the number\n        # of connections we accept at a time.  Ideally we would accept\n        # up to the number of connections that were waiting when we\n        # entered this method, but this information is not available\n        # (and rearranging this method to call accept() as many times\n        # as possible before running any callbacks would have adverse\n        # effects on load balancing in multiprocess configurations).\n        # Instead, we use the (default) listen backlog as a rough\n        # heuristic for the number of connections we can reasonably\n        # accept at once.\n        for i in range(_DEFAULT_BACKLOG):\n            if removed[0]:\n                # The socket was probably closed\n                return\n            try:\n                connection, address = sock.accept()\n            except BlockingIOError:\n                # EWOULDBLOCK indicates we have accepted every\n                # connection that is available.\n                return\n            except ConnectionAbortedError:\n                # ECONNABORTED indicates that there was a connection\n                # but it was closed while still in the accept queue.\n                # (observed on FreeBSD).\n                continue\n            callback(connection, address)\n\n    def remove_handler() -> None:\n        io_loop.remove_handler(sock)\n        removed[0] = True\n\n    io_loop.add_handler(sock, accept_handler, IOLoop.READ)\n    return remove_handler", "fpath_tuple": ["tornado", "netutil.py"], "function_name": "add_accept_handler", "lineno": 0, "context_start_lineno": 0, "_id": 14, "query_window": {"context": "import socket\nfrom tornado.ioloop import IOLoop\nfrom typing import Callable, Any\ndef add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature", "metadata": {"fpath_tuple": ["tornado", "netutil.py"], "line_no": 0, "prediction": "import socket\nfrom tornado.ioloop import IOLoop\nfrom typing import Callable, Any\n\ndef add_accept_handler(\n    sock: socket.socket, callback: Callable[[socket.socket, Any], None]\n) -> Callable[[], None]:\n    \"\"\"Adds an `.IOLoop` event handler to accept new connections on ``sock``.\n\n    When a connection is accepted, ``callback(connection, address)`` will\n    be run (``connection`` is a socket object, and ``address`` is the\n    address of the other end of the connection).  Note that this signature\n    is different from the ``callback(fd, events)`` signature used for\n    `.IOLoop` handlers.\n\n    A callable is returned which, when called, will remove the `.IOLoop`\n    event handler and stop processing further incoming connections.\n\n    .. versionchanged:: 5.0\n    The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n\n    .. versionchanged:: 5.0\n    A callable is returned (``None`` was returned before).\n    \"\"\"\n\n    def accept_handler(fd):\n        connection, address = sock.accept()\n        callback(connection, address)\n\n    # Register the accept handler with the IOLoop\n    IOLoop.current().add_handler(\n        sock.fileno(), accept_handler, IOLoop.READ\n    )\n\n    def remove_handler() -> None:\n        \"\"\"Remove the accept handler from the IOLoop.\"\"\"\n        IOLoop.current().remove_handler(sock.fileno())\n    \n    return remove_handler", "task_id": "tornado/id14", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        sockets = bind_sockets(port, address=address)\n        self.add_sockets(sockets)\n\n    def add_sockets(self, sockets: Iterable[socket.socket]) -> None:\n        \"\"\"Makes this server start accepting connections on the given sockets.\n\n        The ``sockets`` parameter is a list of socket objects such as\n        those returned by `~tornado.netutil.bind_sockets`.\n        `add_sockets` is typically used in combination with that\n        method and `tornado.process.fork_processes` to provide greater\n        control over the initialization of a multi-process server.\n        \"\"\"\n        for sock in sockets:\n            self._sockets[sock.fileno()] = sock\n            self._handlers[sock.fileno()] = add_accept_handler(\n                sock, self._handle_connection\n            )\n\n    def add_socket(self, socket: socket.socket) -> None:\n        \"\"\"Singular version of `add_sockets`.  Takes a single socket object.\"\"\"", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.272108843537415}, {"context": "        `time.time`.\n\n        \"\"\"\n        return time.time()\n\n    def add_timeout(\n        self,\n        deadline: Union[float, datetime.timedelta],\n        callback: Callable[..., None],\n        *args: Any,\n        **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the time ``deadline`` from the I/O loop.\n\n        Returns an opaque handle that may be passed to\n        `remove_timeout` to cancel.\n\n        ``deadline`` may be a number denoting a time (on the same\n        scale as `IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 550, "start_line_no": 540, "end_line_no": 560, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26153846153846155}, {"context": "    See `OptionParser.print_help`.\n    \"\"\"\n    return options.print_help(file)\n\n\ndef add_parse_callback(callback: Callable[[], None]) -> None:\n    \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n\n    See `OptionParser.add_parse_callback`\n    \"\"\"\n    options.add_parse_callback(callback)\n\n\n# Default options\ndefine_logging_options(options)", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 730, "start_line_no": 720, "end_line_no": 735, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25742574257425743}, {"context": "    \"\"\"Parses global options from a config file.\n\n    See `OptionParser.parse_config_file`.\n    \"\"\"\n    return options.parse_config_file(path, final=final)\n\n\ndef print_help(file: Optional[TextIO] = None) -> None:\n    \"\"\"Prints all the command line options to stderr (or another file).\n\n    See `OptionParser.print_help`.\n    \"\"\"\n    return options.print_help(file)\n\n\ndef add_parse_callback(callback: Callable[[], None]) -> None:\n    \"\"\"Adds a parse callback, to be invoked when option parsing is done.\n\n    See `OptionParser.add_parse_callback`\n    \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2540983606557377}, {"context": "\n        It is safe to call this method from any thread at any time,\n        except from a signal handler.  Note that this is the **only**\n        method in `IOLoop` that makes this thread-safety guarantee; all\n        other interaction with the `IOLoop` must be done from that\n        `IOLoop`'s thread.  `add_callback()` may be used to transfer\n        control from other threads to the `IOLoop`'s thread.\n\n        To add a callback from a signal handler, see\n        `add_callback_from_signal`.\n        \"\"\"\n        raise NotImplementedError()\n\n    def add_callback_from_signal(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> None:\n        \"\"\"Calls the given callback on the next I/O loop iteration.\n\n        Safe for use from a Python signal handler; should not be used\n        otherwise.", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2517482517482518}, {"context": "\n    def call_at(\n        self, when: float, callback: Callable[..., None], *args: Any, **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the absolute time designated by ``when``.\n\n        ``when`` must be a number using the same reference point as\n        `IOLoop.time`.\n\n        Returns an opaque handle that may be passed to `remove_timeout`\n        to cancel.  Note that unlike the `asyncio` method of the same\n        name, the returned object does not have a ``cancel()`` method.\n\n        See `add_timeout` for comments on thread-safety and subclassing.\n\n        .. versionadded:: 4.0\n        \"\"\"\n        return self.add_timeout(when, callback, *args, **kwargs)\n\n    def remove_timeout(self, timeout: object) -> None:", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25170068027210885}, {"context": "        \"\"\"Cancels a pending timeout.\n\n        The argument is a handle as returned by `add_timeout`.  It is\n        safe to call `remove_timeout` even if the callback has already\n        been run.\n        \"\"\"\n        raise NotImplementedError()\n\n    def add_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Calls the given callback on the next I/O loop iteration.\n\n        It is safe to call this method from any thread at any time,\n        except from a signal handler.  Note that this is the **only**\n        method in `IOLoop` that makes this thread-safety guarantee; all\n        other interaction with the `IOLoop` must be done from that\n        `IOLoop`'s thread.  `add_callback()` may be used to transfer\n        control from other threads to the `IOLoop`'s thread.\n\n        To add a callback from a signal handler, see\n        `add_callback_from_signal`.", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25}, {"context": "    the command-line interface in `main`)\n    \"\"\"\n    io_loop = ioloop.IOLoop()\n    io_loop.add_callback(start)\n    io_loop.start()\n\n\ndef watch(filename: str) -> None:\n    \"\"\"Add a file to the watch list.\n\n    All imported modules are watched by default.\n    \"\"\"\n    _watched_files.add(filename)\n\n\ndef add_reload_hook(fn: Callable[[], None]) -> None:\n    \"\"\"Add a function to be called before reloading the process.\n\n    Note that for open file and socket handles it is generally\n    preferable to set the ``FD_CLOEXEC`` flag (using `fcntl` or", "metadata": [{"fpath_tuple": ["tornado", "autoreload.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24817518248175183}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     If the argument is already a byte string or None, it is returned unchanged.\n#     Otherwise it must be a unicode string and is encoded as utf8.\n#     \"\"\"\n#     if isinstance(value, _UTF8_TYPES):\n#         return value\n#     if not isinstance(value, unicode_type):\n#         raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n#     return value.encode(\"utf-8\")\n# \n# \n# _TO_UNICODE_TYPES = (unicode_type, type(None))\n# \n# \n# @typing.overload\n# def to_unicode(value: str) -> str:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def to_unicode(value: bytes) -> str:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def get_body_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request body.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.body_arguments, strip)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request query string.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the request more than once, we return the\n#         last value.\n# \n#         This method searches both the query and body arguments.\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.arguments, strip)\n# \n#     def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: None, strip: bool = True\n#     ) -> Optional[str]:\n#         pass\n# \n#     def get_argument(  # noqa: F811\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the request more than once, we return the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the body arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.body_arguments, strip)\n# \n#     def get_query_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request query string.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         last value.\n# \n#         This method searches both the query and body arguments.\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.arguments, strip)\n# \n#     def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         This method searches both the query and body arguments.\n#         \"\"\"\n# \n#         # Make sure `get_arguments` isn't accidentally being called with a\n#         # positional argument that's assumed to be a default (like in\n#         # `get_argument`.)\n#         assert isinstance(strip, bool)\n# \n#         return self._get_arguments(name, self.request.arguments, strip)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.body_arguments, strip)\n# \n#     def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the body arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.body_arguments, strip)\n# \n#     def get_query_argument(\n# --------------------------------------------------\n\ndef is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id15", "ground_truth": "def is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n    if not ip or \"\\x00\" in ip:\n        # getaddrinfo resolves empty strings to localhost, and truncates\n        # on zero bytes.\n        return False\n    try:\n        res = socket.getaddrinfo(\n            ip, 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_NUMERICHOST\n        )\n        return bool(res)\n    except socket.gaierror as e:\n        if e.args[0] == socket.EAI_NONAME:\n            return False\n        raise\n    return True", "fpath_tuple": ["tornado", "netutil.py"], "function_name": "is_valid_ip", "lineno": 0, "context_start_lineno": 0, "_id": 15, "query_window": {"context": "import ipaddress\ndef is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n    Supports IPv4 and IPv6.\n    \"\"\"\n    try:\n        # If the string can be converted to an IP address, it's valid\n        ipaddress.ip_address(ip)\n        return True\n    except ValueError:", "metadata": {"fpath_tuple": ["tornado", "netutil.py"], "line_no": 0, "prediction": "import ipaddress\n\ndef is_valid_ip(ip: str) -> bool:\n    \"\"\"Returns ``True`` if the given string is a well-formed IP address.\n\n    Supports IPv4 and IPv6.\n    \"\"\"\n    try:\n        # If the string can be converted to an IP address, it's valid\n        ipaddress.ip_address(ip)\n        return True\n    except ValueError:\n        # If a ValueError is raised, it's not a valid IP address\n        return False", "task_id": "tornado/id15", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)\n\n    def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n\n    def get_query_argument(", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25}, {"context": "        last value.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)\n\n    def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n\n        # Make sure `get_arguments` isn't accidentally being called with a\n        # positional argument that's assumed to be a default (like in\n        # `get_argument`.)\n        assert isinstance(strip, bool)\n\n        return self._get_arguments(name, self.request.arguments, strip)", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24324324324324326}, {"context": "    def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n\n    def get_query_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2396694214876033}, {"context": "        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: None, strip: bool = True\n    ) -> Optional[str]:\n        pass\n\n    def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23893805309734514}, {"context": "        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the\n        last value.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)\n\n    def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the arguments with the given name.\n\n        If the argument is not present, returns an empty list.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22950819672131148}, {"context": "        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22764227642276422}, {"context": "\n    def get_body_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.226890756302521}, {"context": "    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n    if isinstance(value, _UTF8_TYPES):\n        return value\n    if not isinstance(value, unicode_type):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.encode(\"utf-8\")\n\n\n_TO_UNICODE_TYPES = (unicode_type, type(None))\n\n\n@typing.overload\ndef to_unicode(value: str) -> str:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef to_unicode(value: bytes) -> str:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.226890756302521}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def write_message(\n#         self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n#     ) -> \"Future[None]\":\n#         \"\"\"Sends the given message to the client of this Web Socket.\n# \n#         The message may be either a string or a dict (which will be\n#         encoded as json).  If the ``binary`` argument is false, the\n#         message will be sent as utf8; in binary mode any byte string\n#         is allowed.\n# \n#         If the connection is already closed, raises `WebSocketClosedError`.\n#         Returns a `.Future` which can be used for flow control.\n# \n#         .. versionchanged:: 3.2\n#            `WebSocketClosedError` was added (previously a closed connection\n#            would raise an `AttributeError`)\n# \n#         .. versionchanged:: 4.3\n#            Returns a `.Future` which can be used for flow control.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# \n#     def start_tls(\n#         self,\n#         server_side: bool,\n#         ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n#         server_hostname: Optional[str] = None,\n#     ) -> Awaitable[\"SSLIOStream\"]:\n#         \"\"\"Convert this `IOStream` to an `SSLIOStream`.\n# \n#         This enables protocols that begin in clear-text mode and\n#         switch to SSL after some initial negotiation (such as the\n#         ``STARTTLS`` extension to SMTP and IMAP).\n# \n#         This method cannot be used if there are outstanding reads\n#         or writes on the stream, or if there is any data in the\n#         IOStream's buffer (data in the operating system's socket\n#         buffer is allowed).  This means it must generally be used\n#         immediately after reading or writing the last clear-text\n#         data.  It can also be used immediately after connecting,\n#         before any reads or writes.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def parse_url_path(self, url_path: str) -> str:\n#         \"\"\"Converts a static URL path into a filesystem path.\n# \n#         ``url_path`` is the path component of the URL with\n#         ``static_url_prefix`` removed.  The return value should be\n#         filesystem path relative to ``static_path``.\n# \n#         This is the inverse of `make_static_url`.\n#         \"\"\"\n#         if os.path.sep != \"/\":\n#             url_path = url_path.replace(\"/\", os.path.sep)\n#         return url_path\n# \n#     @classmethod\n#     def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n#         \"\"\"Generate the version string to be used in static URLs.\n# \n#         ``settings`` is the `Application.settings` dictionary and ``path``\n#         is the relative location of the requested asset on the filesystem.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#     .. versionadded:: 3.1\n#        The ``max_buffer_size`` argument.\n# \n#     .. versionchanged:: 5.0\n#        The ``io_loop`` argument has been removed.\n#     \"\"\"\n# \n#     def __init__(\n#         self,\n#         ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n#         max_buffer_size: Optional[int] = None,\n#         read_chunk_size: Optional[int] = None,\n#     ) -> None:\n#         self.ssl_options = ssl_options\n#         self._sockets = {}  # type: Dict[int, socket.socket]\n#         self._handlers = {}  # type: Dict[int, Callable[[], None]]\n#         self._pending_sockets = []  # type: List[socket.socket]\n#         self._started = False\n#         self._stopped = False\n#         self.max_buffer_size = max_buffer_size\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#             server.add_sockets(sockets)\n#             IOLoop.current().start()\n# \n#        The `add_sockets` interface is more complicated, but it can be\n#        used with `tornado.process.fork_processes` to give you more\n#        flexibility in when the fork happens.  `add_sockets` can\n#        also be used in single-process servers if you want to create\n#        your listening sockets in some way other than\n#        `~tornado.netutil.bind_sockets`.\n# \n#     .. versionadded:: 3.1\n#        The ``max_buffer_size`` argument.\n# \n#     .. versionchanged:: 5.0\n#        The ``io_loop`` argument has been removed.\n#     \"\"\"\n# \n#     def __init__(\n#         self,\n#         ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# \n# \n# class SSLIOStream(IOStream):\n#     \"\"\"A utility class to write to and read from a non-blocking SSL socket.\n# \n#     If the socket passed to the constructor is already connected,\n#     it should be wrapped with::\n# \n#         ssl.wrap_socket(sock, do_handshake_on_connect=False, **kwargs)\n# \n#     before constructing the `SSLIOStream`.  Unconnected sockets will be\n#     wrapped when `IOStream.connect` is finished.\n#     \"\"\"\n# \n#     socket = None  # type: ssl.SSLSocket\n# \n#     def __init__(self, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"The ``ssl_options`` keyword argument may either be an\n#         `ssl.SSLContext` object or a dictionary of keywords arguments\n#         for `ssl.wrap_socket`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#     before constructing the `SSLIOStream`.  Unconnected sockets will be\n#     wrapped when `IOStream.connect` is finished.\n#     \"\"\"\n# \n#     socket = None  # type: ssl.SSLSocket\n# \n#     def __init__(self, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"The ``ssl_options`` keyword argument may either be an\n#         `ssl.SSLContext` object or a dictionary of keywords arguments\n#         for `ssl.wrap_socket`\n#         \"\"\"\n#         self._ssl_options = kwargs.pop(\"ssl_options\", _client_ssl_defaults)\n#         super().__init__(*args, **kwargs)\n#         self._ssl_accepting = True\n#         self._handshake_reading = False\n#         self._handshake_writing = False\n#         self._server_hostname = None  # type: Optional[str]\n# \n#         # If the socket is already connected, attempt to start the handshake.\n#         try:\n# --------------------------------------------------\n\ndef ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its\n    `~ssl.SSLContext` equivalent, and may be used when a component which\n    accepts both forms needs to upgrade to the `~ssl.SSLContext` version\n    to use features like SNI or NPN.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id16", "ground_truth": "def ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its\n    `~ssl.SSLContext` equivalent, and may be used when a component which\n    accepts both forms needs to upgrade to the `~ssl.SSLContext` version\n    to use features like SNI or NPN.\n    \"\"\"\n    if isinstance(ssl_options, ssl.SSLContext):\n        return ssl_options\n    assert isinstance(ssl_options, dict)\n    assert all(k in _SSL_CONTEXT_KEYWORDS for k in ssl_options), ssl_options\n    # Can't use create_default_context since this interface doesn't\n    # tell us client vs server.\n    context = ssl.SSLContext(ssl_options.get(\"ssl_version\", ssl.PROTOCOL_SSLv23))\n    if \"certfile\" in ssl_options:\n        context.load_cert_chain(\n            ssl_options[\"certfile\"], ssl_options.get(\"keyfile\", None)\n        )\n    if \"cert_reqs\" in ssl_options:\n        context.verify_mode = ssl_options[\"cert_reqs\"]\n    if \"ca_certs\" in ssl_options:\n        context.load_verify_locations(ssl_options[\"ca_certs\"])\n    if \"ciphers\" in ssl_options:\n        context.set_ciphers(ssl_options[\"ciphers\"])\n    if hasattr(ssl, \"OP_NO_COMPRESSION\"):\n        # Disable TLS compression to avoid CRIME and related attacks.\n        # This constant depends on openssl version 1.0.\n        # TODO: Do we need to do this ourselves or can we trust\n        # the defaults?\n        context.options |= ssl.OP_NO_COMPRESSION\n    return context", "fpath_tuple": ["tornado", "netutil.py"], "function_name": "ssl_options_to_context", "lineno": 0, "context_start_lineno": 0, "_id": 16, "query_window": {"context": "import ssl\nfrom typing import Dict, Any, Union\ndef ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its", "metadata": {"fpath_tuple": ["tornado", "netutil.py"], "line_no": 0, "prediction": "import ssl\nfrom typing import Dict, Any, Union\n\ndef ssl_options_to_context(\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext]\n) -> ssl.SSLContext:\n    \"\"\"Try to convert an ``ssl_options`` dictionary to an\n    `~ssl.SSLContext` object.\n\n    The ``ssl_options`` dictionary contains keywords to be passed to\n    `ssl.wrap_socket`.  In Python 2.7.9+, `ssl.SSLContext` objects can\n    be used instead.  This function converts the dict form to its\n    `~ssl.SSLContext` equivalent, and may be used when a component which\n    accepts both forms needs to upgrade to the `~ssl.SSLContext` version\n    to use features like SNI or NPN.\n    \"\"\"\n    if isinstance(ssl_options, ssl.SSLContext):\n        return ssl_options  # Already an SSLContext, return it as is\n\n    # Create a new SSLContext based on the provided options\n    context = ssl.SSLContext(ssl.PROTOCOL_TLS)  # Default to TLS protocol\n\n    # Set options based on the ssl_options dictionary\n    if 'protocol' in ssl_options:\n        context.protocol = ssl_options['protocol']\n\n    if 'certfile' in ssl_options:\n        context.load_cert_chain(certfile=ssl_options['certfile'])\n\n    if 'keyfile' in ssl_options:\n        context.load_cert_chain(keyfile=ssl_options['keyfile'])\n\n    if 'ciphers' in ssl_options:\n        context.set_ciphers(ssl_options['ciphers'])\n\n    if 'verify_mode' in ssl_options:\n        context.verify_mode = ssl_options['verify_mode']\n\n    # You can add more settings according to the keys expected in the ssl_options dictionary\n\n    return context", "task_id": "tornado/id16", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    before constructing the `SSLIOStream`.  Unconnected sockets will be\n    wrapped when `IOStream.connect` is finished.\n    \"\"\"\n\n    socket = None  # type: ssl.SSLSocket\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"The ``ssl_options`` keyword argument may either be an\n        `ssl.SSLContext` object or a dictionary of keywords arguments\n        for `ssl.wrap_socket`\n        \"\"\"\n        self._ssl_options = kwargs.pop(\"ssl_options\", _client_ssl_defaults)\n        super().__init__(*args, **kwargs)\n        self._ssl_accepting = True\n        self._handshake_reading = False\n        self._handshake_writing = False\n        self._server_hostname = None  # type: Optional[str]\n\n        # If the socket is already connected, attempt to start the handshake.\n        try:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1360, "start_line_no": 1350, "end_line_no": 1370, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24305555555555555}, {"context": "\n\nclass SSLIOStream(IOStream):\n    \"\"\"A utility class to write to and read from a non-blocking SSL socket.\n\n    If the socket passed to the constructor is already connected,\n    it should be wrapped with::\n\n        ssl.wrap_socket(sock, do_handshake_on_connect=False, **kwargs)\n\n    before constructing the `SSLIOStream`.  Unconnected sockets will be\n    wrapped when `IOStream.connect` is finished.\n    \"\"\"\n\n    socket = None  # type: ssl.SSLSocket\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"The ``ssl_options`` keyword argument may either be an\n        `ssl.SSLContext` object or a dictionary of keywords arguments\n        for `ssl.wrap_socket`", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1350, "start_line_no": 1340, "end_line_no": 1360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2357142857142857}, {"context": "            server.add_sockets(sockets)\n            IOLoop.current().start()\n\n       The `add_sockets` interface is more complicated, but it can be\n       used with `tornado.process.fork_processes` to give you more\n       flexibility in when the fork happens.  `add_sockets` can\n       also be used in single-process servers if you want to create\n       your listening sockets in some way other than\n       `~tornado.netutil.bind_sockets`.\n\n    .. versionadded:: 3.1\n       The ``max_buffer_size`` argument.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument has been removed.\n    \"\"\"\n\n    def __init__(\n        self,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22297297297297297}, {"context": "    .. versionadded:: 3.1\n       The ``max_buffer_size`` argument.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument has been removed.\n    \"\"\"\n\n    def __init__(\n        self,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        max_buffer_size: Optional[int] = None,\n        read_chunk_size: Optional[int] = None,\n    ) -> None:\n        self.ssl_options = ssl_options\n        self._sockets = {}  # type: Dict[int, socket.socket]\n        self._handlers = {}  # type: Dict[int, Callable[[], None]]\n        self._pending_sockets = []  # type: List[socket.socket]\n        self._started = False\n        self._stopped = False\n        self.max_buffer_size = max_buffer_size", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2222222222222222}, {"context": "\n    def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"\n        if os.path.sep != \"/\":\n            url_path = url_path.replace(\"/\", os.path.sep)\n        return url_path\n\n    @classmethod\n    def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n        \"\"\"Generate the version string to be used in static URLs.\n\n        ``settings`` is the `Application.settings` dictionary and ``path``\n        is the relative location of the requested asset on the filesystem.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2960, "start_line_no": 2950, "end_line_no": 2970, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21481481481481482}, {"context": "\n    def start_tls(\n        self,\n        server_side: bool,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        server_hostname: Optional[str] = None,\n    ) -> Awaitable[\"SSLIOStream\"]:\n        \"\"\"Convert this `IOStream` to an `SSLIOStream`.\n\n        This enables protocols that begin in clear-text mode and\n        switch to SSL after some initial negotiation (such as the\n        ``STARTTLS`` extension to SMTP and IMAP).\n\n        This method cannot be used if there are outstanding reads\n        or writes on the stream, or if there is any data in the\n        IOStream's buffer (data in the operating system's socket\n        buffer is allowed).  This means it must generally be used\n        immediately after reading or writing the last clear-text\n        data.  It can also be used immediately after connecting,\n        before any reads or writes.", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1230, "start_line_no": 1220, "end_line_no": 1240, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2111801242236025}, {"context": "\n    def write_message(\n        self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\n\n        The message may be either a string or a dict (which will be\n        encoded as json).  If the ``binary`` argument is false, the\n        message will be sent as utf8; in binary mode any byte string\n        is allowed.\n\n        If the connection is already closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 3.2\n           `WebSocketClosedError` was added (previously a closed connection\n           would raise an `AttributeError`)\n\n        .. versionchanged:: 4.3\n           Returns a `.Future` which can be used for flow control.", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21052631578947367}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n# \n#         .. versionchanged:: 6.0\n# \n#            The ``callback`` argument was removed. Use the returned awaitable object instead.\n#         \"\"\"\n#         url = self._FACEBOOK_BASE_URL + path\n#         return await self.oauth2_request(\n#             url, access_token=access_token, post_args=post_args, **args\n#         )\n# \n# \n# def _oauth_signature(\n#     consumer_token: Dict[str, Any],\n#     method: str,\n#     url: str,\n#     parameters: Dict[str, Any] = {},\n#     token: Optional[Dict[str, Any]] = None,\n# ) -> bytes:\n#     \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n#             args[\"code\"] = code\n#         if client_id is not None:\n#             args[\"client_id\"] = client_id\n#         if client_secret is not None:\n#             args[\"client_secret\"] = client_secret\n#         if extra_params:\n#             args.update(extra_params)\n#         return url_concat(url, args)\n# \n#     async def oauth2_request(\n#         self,\n#         url: str,\n#         access_token: Optional[str] = None,\n#         post_args: Optional[Dict[str, Any]] = None,\n#         **args: Any\n#     ) -> Any:\n#         \"\"\"Fetches the given URL auth an OAuth2 access token.\n# \n#         If the request is a POST, ``post_args`` should be provided. Query\n#         string arguments should be given as keyword arguments.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n# from tornado.web import RequestHandler\n# \n# from typing import List, Any, Dict, cast, Iterable, Union, Optional\n# \n# \n# class AuthError(Exception):\n#     pass\n# \n# \n# class OpenIdMixin(object):\n#     \"\"\"Abstract implementation of OpenID and Attribute Exchange.\n# \n#     Class attributes:\n# \n#     * ``_OPENID_ENDPOINT``: the identity provider's URI.\n#     \"\"\"\n# \n#     def authenticate_redirect(\n#         self,\n#         callback_uri: Optional[str] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         if ssl_options is None:\n#             if server_side:\n#                 ssl_options = _server_ssl_defaults\n#             else:\n#                 ssl_options = _client_ssl_defaults\n# \n#         socket = self.socket\n#         self.io_loop.remove_handler(socket)\n#         self.socket = None  # type: ignore\n#         socket = ssl_wrap_socket(\n#             socket,\n#             ssl_options,\n#             server_hostname=server_hostname,\n#             server_side=server_side,\n#             do_handshake_on_connect=False,\n#         )\n#         orig_close_callback = self._close_callback\n#         self._close_callback = None\n# \n#         future = Future()  # type: Future[SSLIOStream]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# \n# \n# class SSLIOStream(IOStream):\n#     \"\"\"A utility class to write to and read from a non-blocking SSL socket.\n# \n#     If the socket passed to the constructor is already connected,\n#     it should be wrapped with::\n# \n#         ssl.wrap_socket(sock, do_handshake_on_connect=False, **kwargs)\n# \n#     before constructing the `SSLIOStream`.  Unconnected sockets will be\n#     wrapped when `IOStream.connect` is finished.\n#     \"\"\"\n# \n#     socket = None  # type: ssl.SSLSocket\n# \n#     def __init__(self, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"The ``ssl_options`` keyword argument may either be an\n#         `ssl.SSLContext` object or a dictionary of keywords arguments\n#         for `ssl.wrap_socket`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#             self._own_resolver = True\n# \n#     def close(self) -> None:\n#         if self._own_resolver:\n#             self.resolver.close()\n# \n#     async def connect(\n#         self,\n#         host: str,\n#         port: int,\n#         af: socket.AddressFamily = socket.AF_UNSPEC,\n#         ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n#         max_buffer_size: Optional[int] = None,\n#         source_ip: Optional[str] = None,\n#         source_port: Optional[int] = None,\n#         timeout: Optional[Union[float, datetime.timedelta]] = None,\n#     ) -> IOStream:\n#         \"\"\"Connect to the given host and port.\n# \n#         Asynchronously returns an `.IOStream` (or `.SSLIOStream` if\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpserver.py\n# --------------------------------------------------\n#     .. versionadded:: 3.1\n#        The ``max_buffer_size`` argument.\n# \n#     .. versionchanged:: 5.0\n#        The ``io_loop`` argument has been removed.\n#     \"\"\"\n# \n#     def __init__(\n#         self,\n#         ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n#         max_buffer_size: Optional[int] = None,\n#         read_chunk_size: Optional[int] = None,\n#     ) -> None:\n#         self.ssl_options = ssl_options\n#         self._sockets = {}  # type: Dict[int, socket.socket]\n#         self._handlers = {}  # type: Dict[int, Callable[[], None]]\n#         self._pending_sockets = []  # type: List[socket.socket]\n#         self._started = False\n#         self._stopped = False\n#         self.max_buffer_size = max_buffer_size\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#     before constructing the `SSLIOStream`.  Unconnected sockets will be\n#     wrapped when `IOStream.connect` is finished.\n#     \"\"\"\n# \n#     socket = None  # type: ssl.SSLSocket\n# \n#     def __init__(self, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"The ``ssl_options`` keyword argument may either be an\n#         `ssl.SSLContext` object or a dictionary of keywords arguments\n#         for `ssl.wrap_socket`\n#         \"\"\"\n#         self._ssl_options = kwargs.pop(\"ssl_options\", _client_ssl_defaults)\n#         super().__init__(*args, **kwargs)\n#         self._ssl_accepting = True\n#         self._handshake_reading = False\n#         self._handshake_writing = False\n#         self._server_hostname = None  # type: Optional[str]\n# \n#         # If the socket is already connected, attempt to start the handshake.\n#         try:\n# --------------------------------------------------\n\ndef ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n", "metadata": {"task_id": "tornado/id17", "ground_truth": "def ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`).  Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n    context = ssl_options_to_context(ssl_options)\n    if ssl.HAS_SNI:\n        # In python 3.4, wrap_socket only accepts the server_hostname\n        # argument if HAS_SNI is true.\n        # TODO: add a unittest (python added server-side SNI support in 3.4)\n        # In the meantime it can be manually tested with\n        # python3 -m tornado.httpclient https://sni.velox.ch\n        return context.wrap_socket(socket, server_hostname=server_hostname, **kwargs)\n    else:\n        return context.wrap_socket(socket, **kwargs)", "fpath_tuple": ["tornado", "netutil.py"], "function_name": "ssl_wrap_socket", "lineno": 0, "context_start_lineno": 0, "_id": 17, "query_window": {"context": "import socket\nimport ssl\nfrom typing import Union, Dict, Any, Optional\ndef ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.", "metadata": {"fpath_tuple": ["tornado", "netutil.py"], "line_no": 0, "prediction": "import socket\nimport ssl\nfrom typing import Union, Dict, Any, Optional\n\ndef ssl_wrap_socket(\n    socket: socket.socket,\n    ssl_options: Union[Dict[str, Any], ssl.SSLContext],\n    server_hostname: Optional[str] = None,\n    **kwargs: Any\n) -> ssl.SSLSocket:\n    \"\"\"Returns an ``ssl.SSLSocket`` wrapping the given socket.\n\n    ``ssl_options`` may be either an `ssl.SSLContext` object or a\n    dictionary (as accepted by `ssl_options_to_context`). Additional\n    keyword arguments are passed to ``wrap_socket`` (either the\n    `~ssl.SSLContext` method or the `ssl` module function as\n    appropriate).\n    \"\"\"\n    if isinstance(ssl_options, ssl.SSLContext):\n        context = ssl_options\n    else:\n        # Assuming ssl_options is a dictionary\n        context = ssl.create_default_context()\n        for option, value in ssl_options.items():\n            setattr(context, option, value)\n\n    # Wrap the socket with SSL\n    return context.wrap_socket(socket, server_hostname=server_hostname, **kwargs)", "task_id": "tornado/id17", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    before constructing the `SSLIOStream`.  Unconnected sockets will be\n    wrapped when `IOStream.connect` is finished.\n    \"\"\"\n\n    socket = None  # type: ssl.SSLSocket\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"The ``ssl_options`` keyword argument may either be an\n        `ssl.SSLContext` object or a dictionary of keywords arguments\n        for `ssl.wrap_socket`\n        \"\"\"\n        self._ssl_options = kwargs.pop(\"ssl_options\", _client_ssl_defaults)\n        super().__init__(*args, **kwargs)\n        self._ssl_accepting = True\n        self._handshake_reading = False\n        self._handshake_writing = False\n        self._server_hostname = None  # type: Optional[str]\n\n        # If the socket is already connected, attempt to start the handshake.\n        try:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1360, "start_line_no": 1350, "end_line_no": 1370, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.3064516129032258}, {"context": "    .. versionadded:: 3.1\n       The ``max_buffer_size`` argument.\n\n    .. versionchanged:: 5.0\n       The ``io_loop`` argument has been removed.\n    \"\"\"\n\n    def __init__(\n        self,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        max_buffer_size: Optional[int] = None,\n        read_chunk_size: Optional[int] = None,\n    ) -> None:\n        self.ssl_options = ssl_options\n        self._sockets = {}  # type: Dict[int, socket.socket]\n        self._handlers = {}  # type: Dict[int, Callable[[], None]]\n        self._pending_sockets = []  # type: List[socket.socket]\n        self._started = False\n        self._stopped = False\n        self.max_buffer_size = max_buffer_size", "metadata": [{"fpath_tuple": ["tornado", "tcpserver.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2803738317757009}, {"context": "            self._own_resolver = True\n\n    def close(self) -> None:\n        if self._own_resolver:\n            self.resolver.close()\n\n    async def connect(\n        self,\n        host: str,\n        port: int,\n        af: socket.AddressFamily = socket.AF_UNSPEC,\n        ssl_options: Optional[Union[Dict[str, Any], ssl.SSLContext]] = None,\n        max_buffer_size: Optional[int] = None,\n        source_ip: Optional[str] = None,\n        source_port: Optional[int] = None,\n        timeout: Optional[Union[float, datetime.timedelta]] = None,\n    ) -> IOStream:\n        \"\"\"Connect to the given host and port.\n\n        Asynchronously returns an `.IOStream` (or `.SSLIOStream` if", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2636363636363636}, {"context": "\n\nclass SSLIOStream(IOStream):\n    \"\"\"A utility class to write to and read from a non-blocking SSL socket.\n\n    If the socket passed to the constructor is already connected,\n    it should be wrapped with::\n\n        ssl.wrap_socket(sock, do_handshake_on_connect=False, **kwargs)\n\n    before constructing the `SSLIOStream`.  Unconnected sockets will be\n    wrapped when `IOStream.connect` is finished.\n    \"\"\"\n\n    socket = None  # type: ssl.SSLSocket\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"The ``ssl_options`` keyword argument may either be an\n        `ssl.SSLContext` object or a dictionary of keywords arguments\n        for `ssl.wrap_socket`", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1350, "start_line_no": 1340, "end_line_no": 1360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25806451612903225}, {"context": "        if ssl_options is None:\n            if server_side:\n                ssl_options = _server_ssl_defaults\n            else:\n                ssl_options = _client_ssl_defaults\n\n        socket = self.socket\n        self.io_loop.remove_handler(socket)\n        self.socket = None  # type: ignore\n        socket = ssl_wrap_socket(\n            socket,\n            ssl_options,\n            server_hostname=server_hostname,\n            server_side=server_side,\n            do_handshake_on_connect=False,\n        )\n        orig_close_callback = self._close_callback\n        self._close_callback = None\n\n        future = Future()  # type: Future[SSLIOStream]", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1280, "start_line_no": 1270, "end_line_no": 1290, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24175824175824176}, {"context": "from tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional\n\n\nclass AuthError(Exception):\n    pass\n\n\nclass OpenIdMixin(object):\n    \"\"\"Abstract implementation of OpenID and Attribute Exchange.\n\n    Class attributes:\n\n    * ``_OPENID_ENDPOINT``: the identity provider's URI.\n    \"\"\"\n\n    def authenticate_redirect(\n        self,\n        callback_uri: Optional[str] = None,", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2376237623762376}, {"context": "            args[\"code\"] = code\n        if client_id is not None:\n            args[\"client_id\"] = client_id\n        if client_secret is not None:\n            args[\"client_secret\"] = client_secret\n        if extra_params:\n            args.update(extra_params)\n        return url_concat(url, args)\n\n    async def oauth2_request(\n        self,\n        url: str,\n        access_token: Optional[str] = None,\n        post_args: Optional[Dict[str, Any]] = None,\n        **args: Any\n    ) -> Any:\n        \"\"\"Fetches the given URL auth an OAuth2 access token.\n\n        If the request is a POST, ``post_args`` should be provided. Query\n        string arguments should be given as keyword arguments.", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23636363636363636}, {"context": "\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned awaitable object instead.\n        \"\"\"\n        url = self._FACEBOOK_BASE_URL + path\n        return await self.oauth2_request(\n            url, access_token=access_token, post_args=post_args, **args\n        )\n\n\ndef _oauth_signature(\n    consumer_token: Dict[str, Any],\n    method: str,\n    url: str,\n    parameters: Dict[str, Any] = {},\n    token: Optional[Dict[str, Any]] = None,\n) -> bytes:\n    \"\"\"Calculates the HMAC-SHA1 OAuth signature for the given request.\n", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 1100, "start_line_no": 1090, "end_line_no": 1110, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23333333333333334}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#         .. versionchanged:: 5.0\n#            Consistently raises `WebSocketClosedError`. Previously could\n#            sometimes raise `.StreamClosedError`.\n#         \"\"\"\n#         if self.ws_connection is None or self.ws_connection.is_closing():\n#             raise WebSocketClosedError()\n#         if isinstance(message, dict):\n#             message = tornado.escape.json_encode(message)\n#         return self.ws_connection.write_message(message, binary=binary)\n# \n#     def select_subprotocol(self, subprotocols: List[str]) -> Optional[str]:\n#         \"\"\"Override to implement subprotocol negotiation.\n# \n#         ``subprotocols`` is a list of strings identifying the\n#         subprotocols proposed by the client.  This method may be\n#         overridden to return one of those strings to select it, or\n#         ``None`` to not select a subprotocol.\n# \n#         Failure to select a subprotocol does not automatically abort\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         See `clear_cookie` for more information on the path and domain\n#         parameters.\n# \n#         Similar to `set_cookie`, the effect of this method will not be\n#         seen until the following request.\n# \n#         .. versionchanged:: 3.2\n# \n#            Added the ``path`` and ``domain`` parameters.\n#         \"\"\"\n#         for name in self.request.cookies:\n#             self.clear_cookie(name, path=path, domain=domain)\n# \n#     def set_secure_cookie(\n#         self,\n#         name: str,\n#         value: Union[str, bytes],\n#         expires_days: Optional[float] = 30,\n#         version: Optional[int] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def select_subprotocol(self, subprotocols: List[str]) -> Optional[str]:\n#         \"\"\"Override to implement subprotocol negotiation.\n# \n#         ``subprotocols`` is a list of strings identifying the\n#         subprotocols proposed by the client.  This method may be\n#         overridden to return one of those strings to select it, or\n#         ``None`` to not select a subprotocol.\n# \n#         Failure to select a subprotocol does not automatically abort\n#         the connection, although clients may close the connection if\n#         none of their proposed subprotocols was selected.\n# \n#         The list may be empty, in which case this method must return\n#         None. This method is always called exactly once even if no\n#         subprotocols were proposed so that the handler can be advised\n#         of this fact.\n# \n#         .. versionchanged:: 5.1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#             **kwargs\n#         )\n# \n#     def create_signed_value(\n#         self, name: str, value: Union[str, bytes], version: Optional[int] = None\n#     ) -> bytes:\n#         \"\"\"Signs and timestamps a string so it cannot be forged.\n# \n#         Normally used via set_secure_cookie, but provided as a separate\n#         method for non-cookie uses.  To decode a value not stored\n#         as a cookie use the optional value argument to get_secure_cookie.\n# \n#         .. versionchanged:: 3.2.1\n# \n#            Added the ``version`` argument.  Introduced cookie version 2\n#            and made it the default.\n#         \"\"\"\n#         self.require_setting(\"cookie_secret\", \"secure cookies\")\n#         secret = self.application.settings[\"cookie_secret\"]\n#         key_version = None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         as a cookie use the optional value argument to get_secure_cookie.\n# \n#         .. versionchanged:: 3.2.1\n# \n#            Added the ``version`` argument.  Introduced cookie version 2\n#            and made it the default.\n#         \"\"\"\n#         self.require_setting(\"cookie_secret\", \"secure cookies\")\n#         secret = self.application.settings[\"cookie_secret\"]\n#         key_version = None\n#         if isinstance(secret, dict):\n#             if self.application.settings.get(\"key_version\") is None:\n#                 raise Exception(\"key_version setting must be used for secret_key dicts\")\n#             key_version = self.application.settings[\"key_version\"]\n# \n#         return create_signed_value(\n#             secret, name, value, version=version, key_version=key_version\n#         )\n# \n#     def get_secure_cookie(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     out = [key]\n#     # Sort the parameters just to make it easy to test.\n#     for k, v in sorted(pdict.items()):\n#         if v is None:\n#             out.append(k)\n#         else:\n#             # TODO: quote if necessary.\n#             out.append(\"%s=%s\" % (k, v))\n#     return \"; \".join(out)\n# \n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         .. versionchanged:: 3.2.1\n# \n#            Added the ``version`` argument.  Introduced cookie version 2\n#            and made it the default.\n#         \"\"\"\n#         self.set_cookie(\n#             name,\n#             self.create_signed_value(name, value, version=version),\n#             expires_days=expires_days,\n#             **kwargs\n#         )\n# \n#     def create_signed_value(\n#         self, name: str, value: Union[str, bytes], version: Optional[int] = None\n#     ) -> bytes:\n#         \"\"\"Signs and timestamps a string so it cannot be forged.\n# \n#         Normally used via set_secure_cookie, but provided as a separate\n#         method for non-cookie uses.  To decode a value not stored\n# --------------------------------------------------\n\ndef xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n    Added the single quote to the list of escaped characters.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id18", "ground_truth": "def xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n       Added the single quote to the list of escaped characters.\n    \"\"\"\n    return _XHTML_ESCAPE_RE.sub(\n        lambda match: _XHTML_ESCAPE_DICT[match.group(0)], to_basestring(value)\n    )", "fpath_tuple": ["tornado", "escape.py"], "function_name": "xhtml_escape", "lineno": 0, "context_start_lineno": 0, "_id": 18, "query_window": {"context": "def xhtml_escape(data: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n    .. versionchanged:: 3.2\n    Added the single quote to the list of escaped characters.\n    \"\"\"\n    if isinstance(data, bytes):\n        data = data.decode('utf-8')  # Decode bytes to string if necessary", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "def xhtml_escape(data: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n    Added the single quote to the list of escaped characters.\n    \"\"\"\n    if isinstance(data, bytes):\n        data = data.decode('utf-8')  # Decode bytes to string if necessary\n\n    # Escape the necessary characters\n    return (data.replace(\"&\", \"&amp;\")\n                .replace(\"<\", \"&lt;\")\n                .replace(\">\", \"&gt;\")\n                .replace(\"\\\"\", \"&quot;\")\n                .replace(\"'\", \"&apos;\"))", "task_id": "tornado/id18", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.set_cookie(\n            name,\n            self.create_signed_value(name, value, version=version),\n            expires_days=expires_days,\n            **kwargs\n        )\n\n    def create_signed_value(\n        self, name: str, value: Union[str, bytes], version: Optional[int] = None\n    ) -> bytes:\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n\n        Normally used via set_secure_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24475524475524477}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24444444444444444}, {"context": "    out = [key]\n    # Sort the parameters just to make it easy to test.\n    for k, v in sorted(pdict.items()):\n        if v is None:\n            out.append(k)\n        else:\n            # TODO: quote if necessary.\n            out.append(\"%s=%s\" % (k, v))\n    return \"; \".join(out)\n\n\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1000, "start_line_no": 990, "end_line_no": 1010, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24305555555555555}, {"context": "        as a cookie use the optional value argument to get_secure_cookie.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        secret = self.application.settings[\"cookie_secret\"]\n        key_version = None\n        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n\n        return create_signed_value(\n            secret, name, value, version=version, key_version=key_version\n        )\n\n    def get_secure_cookie(", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23880597014925373}, {"context": "            **kwargs\n        )\n\n    def create_signed_value(\n        self, name: str, value: Union[str, bytes], version: Optional[int] = None\n    ) -> bytes:\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n\n        Normally used via set_secure_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored\n        as a cookie use the optional value argument to get_secure_cookie.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        secret = self.application.settings[\"cookie_secret\"]\n        key_version = None", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 730, "start_line_no": 720, "end_line_no": 740, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23841059602649006}, {"context": "\n    def select_subprotocol(self, subprotocols: List[str]) -> Optional[str]:\n        \"\"\"Override to implement subprotocol negotiation.\n\n        ``subprotocols`` is a list of strings identifying the\n        subprotocols proposed by the client.  This method may be\n        overridden to return one of those strings to select it, or\n        ``None`` to not select a subprotocol.\n\n        Failure to select a subprotocol does not automatically abort\n        the connection, although clients may close the connection if\n        none of their proposed subprotocols was selected.\n\n        The list may be empty, in which case this method must return\n        None. This method is always called exactly once even if no\n        subprotocols were proposed so that the handler can be advised\n        of this fact.\n\n        .. versionchanged:: 5.1\n", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2361111111111111}, {"context": "\n        See `clear_cookie` for more information on the path and domain\n        parameters.\n\n        Similar to `set_cookie`, the effect of this method will not be\n        seen until the following request.\n\n        .. versionchanged:: 3.2\n\n           Added the ``path`` and ``domain`` parameters.\n        \"\"\"\n        for name in self.request.cookies:\n            self.clear_cookie(name, path=path, domain=domain)\n\n    def set_secure_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        expires_days: Optional[float] = 30,\n        version: Optional[int] = None,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22556390977443608}, {"context": "\n        .. versionchanged:: 5.0\n           Consistently raises `WebSocketClosedError`. Previously could\n           sometimes raise `.StreamClosedError`.\n        \"\"\"\n        if self.ws_connection is None or self.ws_connection.is_closing():\n            raise WebSocketClosedError()\n        if isinstance(message, dict):\n            message = tornado.escape.json_encode(message)\n        return self.ws_connection.write_message(message, binary=binary)\n\n    def select_subprotocol(self, subprotocols: List[str]) -> Optional[str]:\n        \"\"\"Override to implement subprotocol negotiation.\n\n        ``subprotocols`` is a list of strings identifying the\n        subprotocols proposed by the client.  This method may be\n        overridden to return one of those strings to select it, or\n        ``None`` to not select a subprotocol.\n\n        Failure to select a subprotocol does not automatically abort", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22151898734177214}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         result = []\n#         for f in self._get_resources(\"css_files\"):\n#             if isinstance(f, (unicode_type, bytes)):\n#                 result.append(f)\n#             else:\n#                 result.extend(f)\n#         return result\n# \n#     def html_head(self) -> str:\n#         return \"\".join(self._get_resources(\"html_head\"))\n# \n#     def html_body(self) -> str:\n#         return \"\".join(self._get_resources(\"html_body\"))\n# \n# \n# class _UIModuleNamespace(object):\n#     \"\"\"Lazy namespace which creates UIModule proxies bound to a handler.\"\"\"\n# \n#     def __init__(\n#         self, handler: RequestHandler, ui_modules: Dict[str, Type[UIModule]]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n#             self.regex.pattern,\n#             self.handler_class,\n#             self.kwargs,\n#             self.name,\n#         )\n# \n# \n# @overload\n# def _unquote_or_none(s: str) -> bytes:\n#     pass\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         frame += data\n#         self._wire_bytes_out += len(frame)\n#         return self.stream.write(frame)\n# \n#     def write_message(\n#         self, message: Union[str, bytes], binary: bool = False\n#     ) -> \"Future[None]\":\n#         \"\"\"Sends the given message to the client of this Web Socket.\"\"\"\n#         if binary:\n#             opcode = 0x2\n#         else:\n#             opcode = 0x1\n#         message = tornado.escape.utf8(message)\n#         assert isinstance(message, bytes)\n#         self._message_bytes_out += len(message)\n#         flags = 0\n#         if self._compressor:\n#             message = self._compressor.compress(message)\n#             flags |= self.RSV1\n#         # For historical reasons, write methods in Tornado operate in a semi-synchronous\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# \n#     Note that args are passed as bytes so the handler can decide what\n#     encoding to use.\n#     \"\"\"\n#     if s is None:\n#         return s\n#     return url_unescape(s, encoding=None, plus=False)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# def import_object(name: str) -> Any:\n#     \"\"\"Imports an object by name.\n# \n#     ``import_object('x')`` is equivalent to ``import x``.\n#     ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n# \n#     >>> import tornado.escape\n#     >>> import_object('tornado.escape') is tornado.escape\n#     True\n#     >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n#     True\n#     >>> import_object('tornado') is tornado\n#     True\n#     >>> import_object('tornado.missing_module')\n#     Traceback (most recent call last):\n#         ...\n#     ImportError: No module named missing_module\n#     \"\"\"\n#     if name.count(\".\") == 0:\n#         return __import__(name)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#             if isinstance(f, (unicode_type, bytes)):\n#                 result.append(f)\n#             else:\n#                 result.extend(f)\n#         return result\n# \n#     def embedded_css(self) -> str:\n#         return \"\\n\".join(self._get_resources(\"embedded_css\"))\n# \n#     def css_files(self) -> Iterable[str]:\n#         result = []\n#         for f in self._get_resources(\"css_files\"):\n#             if isinstance(f, (unicode_type, bytes)):\n#                 result.append(f)\n#             else:\n#                 result.extend(f)\n#         return result\n# \n#     def html_head(self) -> str:\n#         return \"\".join(self._get_resources(\"html_head\"))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     value = utf8(value)\n#     version = _get_version(value)\n# \n#     if version < min_version:\n#         return None\n#     if version == 1:\n#         assert not isinstance(secret, dict)\n#         return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n#     elif version == 2:\n#         return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n#     else:\n#         return None\n# \n# \n# def _decode_signed_value_v1(\n#     secret: Union[str, bytes],\n#     name: str,\n#     value: bytes,\n#     max_age_days: float,\n# --------------------------------------------------\n\ndef xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n", "metadata": {"task_id": "tornado/id19", "ground_truth": "def xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n    return re.sub(r\"&(#?)(\\w+?);\", _convert_entity, _unicode(value))", "fpath_tuple": ["tornado", "escape.py"], "function_name": "xhtml_unescape", "lineno": 0, "context_start_lineno": 0, "_id": 19, "query_window": {"context": "import html\ndef xhtml_unescape(data: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n    if isinstance(data, bytes):\n        data = data.decode('utf-8')\n    return html.unescape(data)", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "import html\n\ndef xhtml_unescape(data: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"\n    if isinstance(data, bytes):\n        data = data.decode('utf-8')\n    return html.unescape(data)", "task_id": "tornado/id19", "start_line_no": 0, "end_line_no": 6, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n    value = utf8(value)\n    version = _get_version(value)\n\n    if version < min_version:\n        return None\n    if version == 1:\n        assert not isinstance(secret, dict)\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None\n\n\ndef _decode_signed_value_v1(\n    secret: Union[str, bytes],\n    name: str,\n    value: bytes,\n    max_age_days: float,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3460, "start_line_no": 3450, "end_line_no": 3470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2682926829268293}, {"context": "            if isinstance(f, (unicode_type, bytes)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result\n\n    def embedded_css(self) -> str:\n        return \"\\n\".join(self._get_resources(\"embedded_css\"))\n\n    def css_files(self) -> Iterable[str]:\n        result = []\n        for f in self._get_resources(\"css_files\"):\n            if isinstance(f, (unicode_type, bytes)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result\n\n    def html_head(self) -> str:\n        return \"\".join(self._get_resources(\"html_head\"))", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3310, "start_line_no": 3300, "end_line_no": 3320, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25842696629213485}, {"context": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25263157894736843}, {"context": "\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 717, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23711340206185566}, {"context": "        frame += data\n        self._wire_bytes_out += len(frame)\n        return self.stream.write(frame)\n\n    def write_message(\n        self, message: Union[str, bytes], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\"\"\"\n        if binary:\n            opcode = 0x2\n        else:\n            opcode = 0x1\n        message = tornado.escape.utf8(message)\n        assert isinstance(message, bytes)\n        self._message_bytes_out += len(message)\n        flags = 0\n        if self._compressor:\n            message = self._compressor.compress(message)\n            flags |= self.RSV1\n        # For historical reasons, write methods in Tornado operate in a semi-synchronous", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1080, "start_line_no": 1070, "end_line_no": 1090, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23478260869565218}, {"context": "            self.regex.pattern,\n            self.handler_class,\n            self.kwargs,\n            self.name,\n        )\n\n\n@overload\ndef _unquote_or_none(s: str) -> bytes:\n    pass\n\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23333333333333334}, {"context": "        result = []\n        for f in self._get_resources(\"css_files\"):\n            if isinstance(f, (unicode_type, bytes)):\n                result.append(f)\n            else:\n                result.extend(f)\n        return result\n\n    def html_head(self) -> str:\n        return \"\".join(self._get_resources(\"html_head\"))\n\n    def html_body(self) -> str:\n        return \"\".join(self._get_resources(\"html_body\"))\n\n\nclass _UIModuleNamespace(object):\n    \"\"\"Lazy namespace which creates UIModule proxies bound to a handler.\"\"\"\n\n    def __init__(\n        self, handler: RequestHandler, ui_modules: Dict[str, Type[UIModule]]", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3320, "start_line_no": 3310, "end_line_no": 3330, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23214285714285715}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23148148148148148}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def add_callback_from_signal(\n#         self, callback: Callable, *args: Any, **kwargs: Any\n#     ) -> None:\n#         \"\"\"Calls the given callback on the next I/O loop iteration.\n# \n#         Safe for use from a Python signal handler; should not be used\n#         otherwise.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n#         \"\"\"Calls the given callback on the next IOLoop iteration.\n# \n#         As of Tornado 6.0, this method is equivalent to `add_callback`.\n# \n#         .. versionadded:: 4.0\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     out = [key]\n#     # Sort the parameters just to make it easy to test.\n#     for k, v in sorted(pdict.items()):\n#         if v is None:\n#             out.append(k)\n#         else:\n#             # TODO: quote if necessary.\n#             out.append(\"%s=%s\" % (k, v))\n#     return \"; \".join(out)\n# \n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n#     ) -> Any:\n#         \"\"\"Returns the old value of the named argument without replacing it.\n# \n#         Returns ``default`` if the argument is not present.\n#         \"\"\"\n#         if self.arg_pos is not None and len(args) > self.arg_pos:\n#             return args[self.arg_pos]\n#         else:\n#             return kwargs.get(self.name, default)\n# \n#     def replace(\n#         self, new_value: Any, args: Sequence[Any], kwargs: Dict[str, Any]\n#     ) -> Tuple[Any, Sequence[Any], Dict[str, Any]]:\n#         \"\"\"Replace the named argument in ``args, kwargs`` with ``new_value``.\n# \n#         Returns ``(old_value, args, kwargs)``.  The returned ``args`` and\n#         ``kwargs`` objects may not be the same as the input objects, or\n#         the input objects may be mutated.\n# \n#         If the named argument was not found, ``new_value`` will be added\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httpclient.py\n# --------------------------------------------------\n# \n# HTTPError = HTTPClientError\n# \n# \n# class _RequestProxy(object):\n#     \"\"\"Combines an object with a dictionary of defaults.\n# \n#     Used internally by AsyncHTTPClient implementations.\n#     \"\"\"\n# \n#     def __init__(\n#         self, request: HTTPRequest, defaults: Optional[Dict[str, Any]]\n#     ) -> None:\n#         self.request = request\n#         self.defaults = defaults\n# \n#     def __getattr__(self, name: str) -> Any:\n#         request_attr = getattr(self.request, name)\n#         if request_attr is not None:\n#             return request_attr\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def get_secure_cookie_key_version(\n#         self, name: str, value: Optional[str] = None\n#     ) -> Optional[int]:\n#         \"\"\"Returns the signing key version of the secure cookie.\n# \n#         The version is returned as int.\n#         \"\"\"\n#         self.require_setting(\"cookie_secret\", \"secure cookies\")\n#         if value is None:\n#             value = self.get_cookie(name)\n#         if value is None:\n#             return None\n#         return get_signature_key_version(value)\n# \n#     def redirect(\n#         self, url: str, permanent: bool = False, status: Optional[int] = None\n#     ) -> None:\n#         \"\"\"Sends a redirect to the given (optionally relative) URL.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# def import_object(name: str) -> Any:\n#     \"\"\"Imports an object by name.\n# \n#     ``import_object('x')`` is equivalent to ``import x``.\n#     ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n# \n#     >>> import tornado.escape\n#     >>> import_object('tornado.escape') is tornado.escape\n#     True\n#     >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n#     True\n#     >>> import_object('tornado') is tornado\n#     True\n#     >>> import_object('tornado.missing_module')\n#     Traceback (most recent call last):\n#         ...\n#     ImportError: No module named missing_module\n#     \"\"\"\n#     if name.count(\".\") == 0:\n#         return __import__(name)\n# --------------------------------------------------\n\ndef json_encode(value: Any) -> str:\n    \"\"\"JSON-encodes the given Python object.\"\"\"\n", "metadata": {"task_id": "tornado/id20", "ground_truth": "def json_encode(value: Any) -> str:\n    \"\"\"JSON-encodes the given Python object.\"\"\"\n    # JSON permits but does not require forward slashes to be escaped.\n    # This is useful when json data is emitted in a <script> tag\n    # in HTML, as it prevents </script> tags from prematurely terminating\n    # the JavaScript.  Some json libraries do this escaping by default,\n    # although python's standard library does not, so we do it here.\n    # http://stackoverflow.com/questions/1580647/json-why-are-forward-slashes-escaped\n    return json.dumps(value).replace(\"</\", \"<\\\\/\")", "fpath_tuple": ["tornado", "escape.py"], "function_name": "json_encode", "lineno": 0, "context_start_lineno": 0, "_id": 20, "query_window": {"context": "import json\nfrom typing import Any\ndef json_encode(value: Any) -> str:\n    \"\"\"Encodes the given Python object to a JSON-formatted string.\n    Args:\n        value (Any): The Python object to encode.\n    Returns:\n        str: A JSON-formatted string representation of the input object.\n    Raises:\n        TypeError: If the object is not serializable to JSON.", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "import json\nfrom typing import Any\n\ndef json_encode(value: Any) -> str:\n    \"\"\"Encodes the given Python object to a JSON-formatted string.\n    \n    Args:\n        value (Any): The Python object to encode.\n\n    Returns:\n        str: A JSON-formatted string representation of the input object.\n\n    Raises:\n        TypeError: If the object is not serializable to JSON.\n    \"\"\"\n    try:\n        return json.dumps(value)\n    except TypeError as e:\n        raise TypeError(f\"Object of type {type(value).__name__} is not JSON serializable\") from e", "task_id": "tornado/id20", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20952380952380953}, {"context": "\n    def get_secure_cookie_key_version(\n        self, name: str, value: Optional[str] = None\n    ) -> Optional[int]:\n        \"\"\"Returns the signing key version of the secure cookie.\n\n        The version is returned as int.\n        \"\"\"\n        self.require_setting(\"cookie_secret\", \"secure cookies\")\n        if value is None:\n            value = self.get_cookie(name)\n        if value is None:\n            return None\n        return get_signature_key_version(value)\n\n    def redirect(\n        self, url: str, permanent: bool = False, status: Optional[int] = None\n    ) -> None:\n        \"\"\"Sends a redirect to the given (optionally relative) URL.\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 790, "start_line_no": 780, "end_line_no": 800, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1891891891891892}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18487394957983194}, {"context": "\nHTTPError = HTTPClientError\n\n\nclass _RequestProxy(object):\n    \"\"\"Combines an object with a dictionary of defaults.\n\n    Used internally by AsyncHTTPClient implementations.\n    \"\"\"\n\n    def __init__(\n        self, request: HTTPRequest, defaults: Optional[Dict[str, Any]]\n    ) -> None:\n        self.request = request\n        self.defaults = defaults\n\n    def __getattr__(self, name: str) -> Any:\n        request_attr = getattr(self.request, name)\n        if request_attr is not None:\n            return request_attr", "metadata": [{"fpath_tuple": ["tornado", "httpclient.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18269230769230768}, {"context": "\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1792452830188679}, {"context": "    ) -> Any:\n        \"\"\"Returns the old value of the named argument without replacing it.\n\n        Returns ``default`` if the argument is not present.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            return args[self.arg_pos]\n        else:\n            return kwargs.get(self.name, default)\n\n    def replace(\n        self, new_value: Any, args: Sequence[Any], kwargs: Dict[str, Any]\n    ) -> Tuple[Any, Sequence[Any], Dict[str, Any]]:\n        \"\"\"Replace the named argument in ``args, kwargs`` with ``new_value``.\n\n        Returns ``(old_value, args, kwargs)``.  The returned ``args`` and\n        ``kwargs`` objects may not be the same as the input objects, or\n        the input objects may be mutated.\n\n        If the named argument was not found, ``new_value`` will be added", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17886178861788618}, {"context": "    out = [key]\n    # Sort the parameters just to make it easy to test.\n    for k, v in sorted(pdict.items()):\n        if v is None:\n            out.append(k)\n        else:\n            # TODO: quote if necessary.\n            out.append(\"%s=%s\" % (k, v))\n    return \"; \".join(out)\n\n\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1000, "start_line_no": 990, "end_line_no": 1010, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17829457364341086}, {"context": "        \"\"\"\n        raise NotImplementedError()\n\n    def add_callback_from_signal(\n        self, callback: Callable, *args: Any, **kwargs: Any\n    ) -> None:\n        \"\"\"Calls the given callback on the next I/O loop iteration.\n\n        Safe for use from a Python signal handler; should not be used\n        otherwise.\n        \"\"\"\n        raise NotImplementedError()\n\n    def spawn_callback(self, callback: Callable, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Calls the given callback on the next IOLoop iteration.\n\n        As of Tornado 6.0, this method is equivalent to `add_callback`.\n\n        .. versionadded:: 4.0\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 650, "start_line_no": 640, "end_line_no": 660, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17796610169491525}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         if isinstance(secret, dict):\n#             if self.application.settings.get(\"key_version\") is None:\n#                 raise Exception(\"key_version setting must be used for secret_key dicts\")\n#             key_version = self.application.settings[\"key_version\"]\n# \n#         return create_signed_value(\n#             secret, name, value, version=version, key_version=key_version\n#         )\n# \n#     def get_secure_cookie(\n#         self,\n#         name: str,\n#         value: Optional[str] = None,\n#         max_age_days: float = 31,\n#         min_version: Optional[int] = None,\n#     ) -> Optional[bytes]:\n#         \"\"\"Returns the given signed cookie if it validates, or None.\n# \n#         The decoded cookie value is returned as a byte string (unlike\n#         `get_cookie`).\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         self._size = 0\n# \n#     def __len__(self) -> int:\n#         return self._size\n# \n#     # Data above this size will be appended separately instead\n#     # of extending an existing bytearray\n#     _large_buf_threshold = 2048\n# \n#     def append(self, data: Union[bytes, bytearray, memoryview]) -> None:\n#         \"\"\"\n#         Append the given piece of data (should be a buffer-compatible object).\n#         \"\"\"\n#         size = len(data)\n#         if size > self._large_buf_threshold:\n#             if not isinstance(data, memoryview):\n#                 data = memoryview(data)\n#             self._buffers.append((True, data))\n#         elif size > 0:\n#             if self._buffers:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         last value.\n# \n#         This method searches both the query and body arguments.\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.arguments, strip)\n# \n#     def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         This method searches both the query and body arguments.\n#         \"\"\"\n# \n#         # Make sure `get_arguments` isn't accidentally being called with a\n#         # positional argument that's assumed to be a default (like in\n#         # `get_argument`.)\n#         assert isinstance(strip, bool)\n# \n#         return self._get_arguments(name, self.request.arguments, strip)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         frame += data\n#         self._wire_bytes_out += len(frame)\n#         return self.stream.write(frame)\n# \n#     def write_message(\n#         self, message: Union[str, bytes], binary: bool = False\n#     ) -> \"Future[None]\":\n#         \"\"\"Sends the given message to the client of this Web Socket.\"\"\"\n#         if binary:\n#             opcode = 0x2\n#         else:\n#             opcode = 0x1\n#         message = tornado.escape.utf8(message)\n#         assert isinstance(message, bytes)\n#         self._message_bytes_out += len(message)\n#         flags = 0\n#         if self._compressor:\n#             message = self._compressor.compress(message)\n#             flags |= self.RSV1\n#         # For historical reasons, write methods in Tornado operate in a semi-synchronous\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# \n#     def flush(self) -> bytes:\n#         \"\"\"Return any remaining buffered data not yet returned by decompress.\n# \n#         Also checks for errors such as truncated input.\n#         No other methods may be called on this object after `flush`.\n#         \"\"\"\n#         return self.decompressobj.flush()\n# \n# \n# def import_object(name: str) -> Any:\n#     \"\"\"Imports an object by name.\n# \n#     ``import_object('x')`` is equivalent to ``import x``.\n#     ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n# \n#     >>> import tornado.escape\n#     >>> import_object('tornado.escape') is tornado.escape\n#     True\n#     >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         # not generally be used by application code.\n# \n#         # .. versionadded:: 4.0\n#         # \"\"\"\n#         if isinstance(fd, int):\n#             return fd, fd\n#         return fd.fileno(), fd\n# \n#     def close_fd(self, fd: Union[int, _Selectable]) -> None:\n#         # \"\"\"Utility method to close an ``fd``.\n# \n#         # If ``fd`` is a file-like object, we close it directly; otherwise\n#         # we use `os.close`.\n# \n#         # This method is provided for use by `IOLoop` subclasses (in\n#         # implementations of ``IOLoop.close(all_fds=True)`` and should\n#         # not generally be used by application code.\n# \n#         # .. versionadded:: 4.0\n#         # \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: None, strip: bool = True\n#     ) -> Optional[str]:\n#         pass\n# \n#     def get_argument(  # noqa: F811\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the request more than once, we return the\n# --------------------------------------------------\n\ndef json_decode(value: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id21", "ground_truth": "def json_decode(value: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n    return json.loads(to_basestring(value))", "fpath_tuple": ["tornado", "escape.py"], "function_name": "json_decode", "lineno": 0, "context_start_lineno": 0, "_id": 21, "query_window": {"context": "import json\nfrom typing import Union, Any\ndef json_decode(data: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n    if isinstance(data, bytes):\n        # If the input is bytes, decode it to a string\n        data = data.decode('utf-8')\n    # Use json.loads to decode the JSON string into a Python object", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "import json\nfrom typing import Union, Any\n\ndef json_decode(data: Union[str, bytes]) -> Any:\n    \"\"\"Returns Python objects for the given JSON string.\n\n    Supports both `str` and `bytes` inputs.\n    \"\"\"\n    if isinstance(data, bytes):\n        # If the input is bytes, decode it to a string\n        data = data.decode('utf-8')\n\n    # Use json.loads to decode the JSON string into a Python object\n    return json.loads(data)", "task_id": "tornado/id21", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: None, strip: bool = True\n    ) -> Optional[str]:\n        pass\n\n    def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23529411764705882}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.225}, {"context": "        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        if isinstance(fd, int):\n            return fd, fd\n        return fd.fileno(), fd\n\n    def close_fd(self, fd: Union[int, _Selectable]) -> None:\n        # \"\"\"Utility method to close an ``fd``.\n\n        # If ``fd`` is a file-like object, we close it directly; otherwise\n        # we use `os.close`.\n\n        # This method is provided for use by `IOLoop` subclasses (in\n        # implementations of ``IOLoop.close(all_fds=True)`` and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 790, "start_line_no": 780, "end_line_no": 800, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2204724409448819}, {"context": "\n    def flush(self) -> bytes:\n        \"\"\"Return any remaining buffered data not yet returned by decompress.\n\n        Also checks for errors such as truncated input.\n        No other methods may be called on this object after `flush`.\n        \"\"\"\n        return self.decompressobj.flush()\n\n\ndef import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21951219512195122}, {"context": "        frame += data\n        self._wire_bytes_out += len(frame)\n        return self.stream.write(frame)\n\n    def write_message(\n        self, message: Union[str, bytes], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\"\"\"\n        if binary:\n            opcode = 0x2\n        else:\n            opcode = 0x1\n        message = tornado.escape.utf8(message)\n        assert isinstance(message, bytes)\n        self._message_bytes_out += len(message)\n        flags = 0\n        if self._compressor:\n            message = self._compressor.compress(message)\n            flags |= self.RSV1\n        # For historical reasons, write methods in Tornado operate in a semi-synchronous", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1080, "start_line_no": 1070, "end_line_no": 1090, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21875}, {"context": "        last value.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n        return self._get_argument(name, default, self.request.arguments, strip)\n\n    def get_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        This method searches both the query and body arguments.\n        \"\"\"\n\n        # Make sure `get_arguments` isn't accidentally being called with a\n        # positional argument that's assumed to be a default (like in\n        # `get_argument`.)\n        assert isinstance(strip, bool)\n\n        return self._get_arguments(name, self.request.arguments, strip)", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2184873949579832}, {"context": "        self._size = 0\n\n    def __len__(self) -> int:\n        return self._size\n\n    # Data above this size will be appended separately instead\n    # of extending an existing bytearray\n    _large_buf_threshold = 2048\n\n    def append(self, data: Union[bytes, bytearray, memoryview]) -> None:\n        \"\"\"\n        Append the given piece of data (should be a buffer-compatible object).\n        \"\"\"\n        size = len(data)\n        if size > self._large_buf_threshold:\n            if not isinstance(data, memoryview):\n                data = memoryview(data)\n            self._buffers.append((True, data))\n        elif size > 0:\n            if self._buffers:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21774193548387097}, {"context": "        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n\n        return create_signed_value(\n            secret, name, value, version=version, key_version=key_version\n        )\n\n    def get_secure_cookie(\n        self,\n        name: str,\n        value: Optional[str] = None,\n        max_age_days: float = 31,\n        min_version: Optional[int] = None,\n    ) -> Optional[bytes]:\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21428571428571427}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/util.py\n# --------------------------------------------------\n#     \"\"\"\n#     try:\n#         subTest = test.subTest  # py34+\n#     except AttributeError:\n#         subTest = contextlib.contextmanager(lambda *a, **kw: (yield))\n#     return subTest(*args, **kwargs)\n# \n# \n# @contextlib.contextmanager\n# def ignore_deprecation():\n#     \"\"\"Context manager to ignore deprecation warnings.\"\"\"\n#     with warnings.catch_warnings():\n#         warnings.simplefilter(\"ignore\", DeprecationWarning)\n#         yield\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# def _re_unescape_replacement(match: Match[str]) -> str:\n#     group = match.group(1)\n#     if group[0] in _alphanum:\n#         raise ValueError(\"cannot unescape '\\\\\\\\%s'\" % group[0])\n#     return group\n# \n# \n# _re_unescape_pattern = re.compile(r\"\\\\(.)\", re.DOTALL)\n# \n# \n# def re_unescape(s: str) -> str:\n#     r\"\"\"Unescape a string escaped by `re.escape`.\n# \n#     May raise ``ValueError`` for regular expressions which could not\n#     have been produced by `re.escape` (for example, strings containing\n#     ``\\d`` cannot be unescaped).\n# \n#     .. versionadded:: 4.4\n#     \"\"\"\n#     return _re_unescape_pattern.sub(_re_unescape_replacement, s)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n#     @classmethod\n#     def configurable_base(cls):\n#         # type: () -> Type[Configurable]\n#         \"\"\"Returns the base class of a configurable hierarchy.\n# \n#         This will normally return the class in which it is defined.\n#         (which is *not* necessarily the same as the ``cls`` classmethod\n#         parameter).\n# \n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     @classmethod\n#     def configurable_default(cls):\n#         # type: () -> Type[Configurable]\n#         \"\"\"Returns the implementation class to be used if none is configured.\"\"\"\n#         raise NotImplementedError()\n# \n#     def _initialize(self) -> None:\n#         pass\n# --------------------------------------------------\n# the below code fragment can be found in:\n# queues.py\n# --------------------------------------------------\n# \n#         1\n#         2\n#         3\n#     \"\"\"\n# \n#     def _init(self) -> None:\n#         self._queue = []\n# \n#     def _put(self, item: _T) -> None:\n#         self._queue.append(item)\n# \n#     def _get(self) -> _T:\n#         return self._queue.pop()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n#     def parse_line(self, line: str) -> None:\n#         \"\"\"Updates the dictionary with a single header line.\n# \n#         >>> h = HTTPHeaders()\n#         >>> h.parse_line(\"Content-Type: text/html\")\n#         >>> h.get('content-type')\n#         'text/html'\n#         \"\"\"\n#         if line[0].isspace():\n#             # continuation of a multi-line header\n#             if self._last_key is None:\n#                 raise HTTPInputError(\"first header line cannot start with whitespace\")\n#             new_part = \" \" + line.lstrip()\n#             self._as_list[self._last_key][-1] += new_part\n#             self._dict[self._last_key] += new_part\n#         else:\n#             try:\n#                 name, value = line.split(\":\", 1)\n#             except ValueError:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# \n#     def reset(self) -> None:\n#         \"\"\"Resets the cache of compiled templates.\"\"\"\n#         with self.lock:\n#             self.templates = {}\n# \n#     def resolve_path(self, name: str, parent_path: Optional[str] = None) -> str:\n#         \"\"\"Converts a possibly-relative path to absolute (used internally).\"\"\"\n#         raise NotImplementedError()\n# \n#     def load(self, name: str, parent_path: Optional[str] = None) -> Template:\n#         \"\"\"Loads a template.\"\"\"\n#         name = self.resolve_path(name, parent_path=parent_path)\n#         with self.lock:\n#             if name not in self.templates:\n#                 self.templates[name] = self._create_template(name)\n#             return self.templates[name]\n# \n#     def _create_template(self, name: str) -> Template:\n#         raise NotImplementedError()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     args: Optional[List[str]] = None, final: bool = True\n# ) -> List[str]:\n#     \"\"\"Parses global options from the command line.\n# \n#     See `OptionParser.parse_command_line`.\n#     \"\"\"\n#     return options.parse_command_line(args, final=final)\n# \n# \n# def parse_config_file(path: str, final: bool = True) -> None:\n#     \"\"\"Parses global options from a config file.\n# \n#     See `OptionParser.parse_config_file`.\n#     \"\"\"\n#     return options.parse_config_file(path, final=final)\n# \n# \n# def print_help(file: Optional[TextIO] = None) -> None:\n#     \"\"\"Prints all the command line options to stderr (or another file).\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n#     pass\n# \n# \n# _UNSET = _UnsetMarker()\n# \n# \n# def filter_whitespace(mode: str, text: str) -> str:\n#     \"\"\"Transform whitespace in ``text`` according to ``mode``.\n# \n#     Available modes are:\n# \n#     * ``all``: Return all whitespace unmodified.\n#     * ``single``: Collapse consecutive whitespace with a single whitespace\n#       character, preserving newlines.\n#     * ``oneline``: Collapse all runs of whitespace into a single space\n#       character, removing all newlines in the process.\n# \n#     .. versionadded:: 4.3\n#     \"\"\"\n#     if mode == \"all\":\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# \n#     * ``all``: Return all whitespace unmodified.\n#     * ``single``: Collapse consecutive whitespace with a single whitespace\n#       character, preserving newlines.\n#     * ``oneline``: Collapse all runs of whitespace into a single space\n#       character, removing all newlines in the process.\n# \n#     .. versionadded:: 4.3\n#     \"\"\"\n#     if mode == \"all\":\n#         return text\n#     elif mode == \"single\":\n#         text = re.sub(r\"([\\t ]+)\", \" \", text)\n#         text = re.sub(r\"(\\s*\\n\\s*)\", \"\\n\", text)\n#         return text\n#     elif mode == \"oneline\":\n#         return re.sub(r\"(\\s+)\", \" \", text)\n#     else:\n#         raise Exception(\"invalid whitespace mode %s\" % mode)\n# --------------------------------------------------\n\ndef squeeze(value: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n", "metadata": {"task_id": "tornado/id22", "ground_truth": "def squeeze(value: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n    return re.sub(r\"[\\x00-\\x20]+\", \" \", value).strip()", "fpath_tuple": ["tornado", "escape.py"], "function_name": "squeeze", "lineno": 0, "context_start_lineno": 0, "_id": 22, "query_window": {"context": "import re\ndef squeeze(s: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n    return re.sub(r'\\s+', ' ', s).strip()", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "import re\n\ndef squeeze(s: str) -> str:\n    \"\"\"Replace all sequences of whitespace chars with a single space.\"\"\"\n    return re.sub(r'\\s+', ' ', s).strip()", "task_id": "tornado/id22", "start_line_no": 0, "end_line_no": 4, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n      character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n      character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n    if mode == \"all\":\n        return text\n    elif mode == \"single\":\n        text = re.sub(r\"([\\t ]+)\", \" \", text)\n        text = re.sub(r\"(\\s*\\n\\s*)\", \"\\n\", text)\n        return text\n    elif mode == \"oneline\":\n        return re.sub(r\"(\\s+)\", \" \", text)\n    else:\n        raise Exception(\"invalid whitespace mode %s\" % mode)\n", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20588235294117646}, {"context": "    pass\n\n\n_UNSET = _UnsetMarker()\n\n\ndef filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n      character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n      character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n    if mode == \"all\":", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19}, {"context": "    args: Optional[List[str]] = None, final: bool = True\n) -> List[str]:\n    \"\"\"Parses global options from the command line.\n\n    See `OptionParser.parse_command_line`.\n    \"\"\"\n    return options.parse_command_line(args, final=final)\n\n\ndef parse_config_file(path: str, final: bool = True) -> None:\n    \"\"\"Parses global options from a config file.\n\n    See `OptionParser.parse_config_file`.\n    \"\"\"\n    return options.parse_config_file(path, final=final)\n\n\ndef print_help(file: Optional[TextIO] = None) -> None:\n    \"\"\"Prints all the command line options to stderr (or another file).\n", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 720, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16842105263157894}, {"context": "\n    def reset(self) -> None:\n        \"\"\"Resets the cache of compiled templates.\"\"\"\n        with self.lock:\n            self.templates = {}\n\n    def resolve_path(self, name: str, parent_path: Optional[str] = None) -> str:\n        \"\"\"Converts a possibly-relative path to absolute (used internally).\"\"\"\n        raise NotImplementedError()\n\n    def load(self, name: str, parent_path: Optional[str] = None) -> Template:\n        \"\"\"Loads a template.\"\"\"\n        name = self.resolve_path(name, parent_path=parent_path)\n        with self.lock:\n            if name not in self.templates:\n                self.templates[name] = self._create_template(name)\n            return self.templates[name]\n\n    def _create_template(self, name: str) -> Template:\n        raise NotImplementedError()", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1619047619047619}, {"context": "\n    def parse_line(self, line: str) -> None:\n        \"\"\"Updates the dictionary with a single header line.\n\n        >>> h = HTTPHeaders()\n        >>> h.parse_line(\"Content-Type: text/html\")\n        >>> h.get('content-type')\n        'text/html'\n        \"\"\"\n        if line[0].isspace():\n            # continuation of a multi-line header\n            if self._last_key is None:\n                raise HTTPInputError(\"first header line cannot start with whitespace\")\n            new_part = \" \" + line.lstrip()\n            self._as_list[self._last_key][-1] += new_part\n            self._dict[self._last_key] += new_part\n        else:\n            try:\n                name, value = line.split(\":\", 1)\n            except ValueError:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15702479338842976}, {"context": "\n        1\n        2\n        3\n    \"\"\"\n\n    def _init(self) -> None:\n        self._queue = []\n\n    def _put(self, item: _T) -> None:\n        self._queue.append(item)\n\n    def _get(self) -> _T:\n        return self._queue.pop()", "metadata": [{"fpath_tuple": ["tornado", "queues.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 414, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15625}, {"context": "    @classmethod\n    def configurable_base(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the base class of a configurable hierarchy.\n\n        This will normally return the class in which it is defined.\n        (which is *not* necessarily the same as the ``cls`` classmethod\n        parameter).\n\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def configurable_default(cls):\n        # type: () -> Type[Configurable]\n        \"\"\"Returns the implementation class to be used if none is configured.\"\"\"\n        raise NotImplementedError()\n\n    def _initialize(self) -> None:\n        pass", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15384615384615385}, {"context": "def _re_unescape_replacement(match: Match[str]) -> str:\n    group = match.group(1)\n    if group[0] in _alphanum:\n        raise ValueError(\"cannot unescape '\\\\\\\\%s'\" % group[0])\n    return group\n\n\n_re_unescape_pattern = re.compile(r\"\\\\(.)\", re.DOTALL)\n\n\ndef re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n    return _re_unescape_pattern.sub(_re_unescape_replacement, s)", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15384615384615385}, {"context": "    \"\"\"\n    try:\n        subTest = test.subTest  # py34+\n    except AttributeError:\n        subTest = contextlib.contextmanager(lambda *a, **kw: (yield))\n    return subTest(*args, **kwargs)\n\n\n@contextlib.contextmanager\ndef ignore_deprecation():\n    \"\"\"Context manager to ignore deprecation warnings.\"\"\"\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", DeprecationWarning)\n        yield", "metadata": [{"fpath_tuple": ["tornado", "test", "util.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 114, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.14736842105263157}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         return self.request.cookies\n# \n#     def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n#         \"\"\"Returns the value of the request cookie with the given name.\n# \n#         If the named cookie is not present, returns ``default``.\n# \n#         This method only returns cookies that were present in the request.\n#         It does not see the outgoing cookies set by `set_cookie` in this\n#         handler.\n#         \"\"\"\n#         if self.request.cookies is not None and name in self.request.cookies:\n#             return self.request.cookies[name].value\n#         return default\n# \n#     def set_cookie(\n#         self,\n#         name: str,\n#         value: Union[str, bytes],\n#         domain: Optional[str] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def get_body_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request body.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.body_arguments, strip)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request query string.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         .. versionchanged:: 4.5\n# \n#            ``on_message`` can be a coroutine.\n#         \"\"\"\n#         raise NotImplementedError\n# \n#     def ping(self, data: Union[str, bytes] = b\"\") -> None:\n#         \"\"\"Send ping frame to the remote end.\n# \n#         The data argument allows a small amount of data (up to 125\n#         bytes) to be sent as a part of the ping message. Note that not\n#         all websocket implementations expose this data to\n#         applications.\n# \n#         Consider using the ``websocket_ping_interval`` application\n#         setting instead of sending pings manually.\n# \n#         .. versionchanged:: 5.1\n# \n#            The data argument is now optional.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.body_arguments, strip)\n# \n#     def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the body arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.body_arguments, strip)\n# \n#     def get_query_argument(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         .. versionchanged:: 3.2.1\n# \n#            Added the ``version`` argument.  Introduced cookie version 2\n#            and made it the default.\n#         \"\"\"\n#         self.set_cookie(\n#             name,\n#             self.create_signed_value(name, value, version=version),\n#             expires_days=expires_days,\n#             **kwargs\n#         )\n# \n#     def create_signed_value(\n#         self, name: str, value: Union[str, bytes], version: Optional[int] = None\n#     ) -> bytes:\n#         \"\"\"Signs and timestamps a string so it cannot be forged.\n# \n#         Normally used via set_secure_cookie, but provided as a separate\n#         method for non-cookie uses.  To decode a value not stored\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#                     chunk_size = remaining\n#                 chunk = file.read(chunk_size)\n#                 if chunk:\n#                     if remaining is not None:\n#                         remaining -= len(chunk)\n#                     yield chunk\n#                 else:\n#                     if remaining is not None:\n#                         assert remaining == 0\n#                     return\n# \n#     @classmethod\n#     def get_content_version(cls, abspath: str) -> str:\n#         \"\"\"Returns a version string for the resource at the given path.\n# \n#         This class method may be overridden by subclasses.  The\n#         default implementation is a SHA-512 hash of the file's contents.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n# --------------------------------------------------\n\ndef url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "metadata": {"task_id": "tornado/id23", "ground_truth": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n        The ``plus`` argument\n    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))", "fpath_tuple": ["tornado", "escape.py"], "function_name": "url_escape", "lineno": 0, "context_start_lineno": 0, "_id": 23, "query_window": {"context": "from urllib.parse import quote\ndef url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n    If ``plus`` is true (the default, spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "from urllib.parse import quote\n\ndef url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default, spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n\n    if isinstance(value, bytes):\n        value = value.decode('utf-8')  # Decode bytes to string if necessary\n\n    # Use urllib quote to perform the URL encoding\n    encoded_value = quote(value, safe='')\n\n    if plus:\n        return encoded_value.replace('%20', '+')  # Convert %20 to +\n    else:\n        return encoded_value  # Keep %20 for spaces\n\n# Example usage:\n# print(url_escape('Hello World'))  # Outputs: Hello+World\n# print(url_escape('Hello World', plus=False))  # Outputs: Hello%20World", "task_id": "tornado/id23", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2809917355371901}, {"context": "                    chunk_size = remaining\n                chunk = file.read(chunk_size)\n                if chunk:\n                    if remaining is not None:\n                        remaining -= len(chunk)\n                    yield chunk\n                else:\n                    if remaining is not None:\n                        assert remaining == 0\n                    return\n\n    @classmethod\n    def get_content_version(cls, abspath: str) -> str:\n        \"\"\"Returns a version string for the resource at the given path.\n\n        This class method may be overridden by subclasses.  The\n        default implementation is a SHA-512 hash of the file's contents.\n\n        .. versionadded:: 3.1\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2820, "start_line_no": 2810, "end_line_no": 2830, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2518518518518518}, {"context": "\n        .. versionchanged:: 3.2.1\n\n           Added the ``version`` argument.  Introduced cookie version 2\n           and made it the default.\n        \"\"\"\n        self.set_cookie(\n            name,\n            self.create_signed_value(name, value, version=version),\n            expires_days=expires_days,\n            **kwargs\n        )\n\n    def create_signed_value(\n        self, name: str, value: Union[str, bytes], version: Optional[int] = None\n    ) -> bytes:\n        \"\"\"Signs and timestamps a string so it cannot be forged.\n\n        Normally used via set_secure_cookie, but provided as a separate\n        method for non-cookie uses.  To decode a value not stored", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2482758620689655}, {"context": "        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)\n\n    def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n\n    def get_query_argument(", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24817518248175183}, {"context": "        .. versionchanged:: 4.5\n\n           ``on_message`` can be a coroutine.\n        \"\"\"\n        raise NotImplementedError\n\n    def ping(self, data: Union[str, bytes] = b\"\") -> None:\n        \"\"\"Send ping frame to the remote end.\n\n        The data argument allows a small amount of data (up to 125\n        bytes) to be sent as a part of the ping message. Note that not\n        all websocket implementations expose this data to\n        applications.\n\n        Consider using the ``websocket_ping_interval`` application\n        setting instead of sending pings manually.\n\n        .. versionchanged:: 5.1\n\n           The data argument is now optional.", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2465753424657534}, {"context": "        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2465753424657534}, {"context": "\n    def get_body_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24647887323943662}, {"context": "        return self.request.cookies\n\n    def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n        \"\"\"Returns the value of the request cookie with the given name.\n\n        If the named cookie is not present, returns ``default``.\n\n        This method only returns cookies that were present in the request.\n        It does not see the outgoing cookies set by `set_cookie` in this\n        handler.\n        \"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default\n\n    def set_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        domain: Optional[str] = None,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24615384615384617}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def write_message(\n#         self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n#     ) -> \"Future[None]\":\n#         \"\"\"Sends the given message to the client of this Web Socket.\n# \n#         The message may be either a string or a dict (which will be\n#         encoded as json).  If the ``binary`` argument is false, the\n#         message will be sent as utf8; in binary mode any byte string\n#         is allowed.\n# \n#         If the connection is already closed, raises `WebSocketClosedError`.\n#         Returns a `.Future` which can be used for flow control.\n# \n#         .. versionchanged:: 3.2\n#            `WebSocketClosedError` was added (previously a closed connection\n#            would raise an `AttributeError`)\n# \n#         .. versionchanged:: 4.3\n#            Returns a `.Future` which can be used for flow control.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n#             self.regex.pattern,\n#             self.handler_class,\n#             self.kwargs,\n#             self.name,\n#         )\n# \n# \n# @overload\n# def _unquote_or_none(s: str) -> bytes:\n#     pass\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# testing.py\n# --------------------------------------------------\n# \n# \n# @typing.overload\n# def gen_test(\n#     *, timeout: Optional[float] = None\n# ) -> Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]]:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def gen_test(func: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n#     pass\n# \n# \n# def gen_test(  # noqa: F811\n#     func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n#     timeout: Optional[float] = None,\n# ) -> Union[\n#     Callable[..., None],\n#     Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# def future_add_done_callback(\n#     future: \"Future[_T]\", callback: Callable[[\"Future[_T]\"], None]\n# ) -> None:\n#     pass\n# \n# \n# def future_add_done_callback(  # noqa: F811\n#     future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n# ) -> None:\n#     \"\"\"Arrange to call ``callback`` when ``future`` is complete.\n# \n#     ``callback`` is invoked with one argument, the ``future``.\n# \n#     If ``future`` is already done, ``callback`` is invoked immediately.\n#     This may differ from the behavior of ``Future.add_done_callback``,\n#     which makes no such guarantee.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if future.done():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         \"\"\"Maximum allowed message size.\n# \n#         If the remote peer sends a message larger than this, the connection\n#         will be closed.\n# \n#         Default is 10MiB.\n#         \"\"\"\n#         return self.settings.get(\n#             \"websocket_max_message_size\", _default_max_message_size\n#         )\n# \n#     def write_message(\n#         self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n#     ) -> \"Future[None]\":\n#         \"\"\"Sends the given message to the client of this Web Socket.\n# \n#         The message may be either a string or a dict (which will be\n#         encoded as json).  If the ``binary`` argument is false, the\n#         message will be sent as utf8; in binary mode any byte string\n#         is allowed.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# \n#     Note that args are passed as bytes so the handler can decide what\n#     encoding to use.\n#     \"\"\"\n#     if s is None:\n#         return s\n#     return url_unescape(s, encoding=None, plus=False)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: None, strip: bool = True\n#     ) -> Optional[str]:\n#         pass\n# \n#     def get_argument(  # noqa: F811\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the request more than once, we return the\n# --------------------------------------------------\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n", "metadata": {"task_id": "tornado/id24", "ground_truth": "def url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)", "fpath_tuple": ["tornado", "escape.py"], "function_name": "url_unescape", "lineno": 0, "context_start_lineno": 0, "_id": 24, "query_window": {"context": "import urllib.parse\nfrom typing import Union, Optional\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Dees the given value from a URL.\n    The argument may be either a byte or unicode string.\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n    If ``plus`` is true (the default), plus signs will be interpreted", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "import urllib.parse\nfrom typing import Union, Optional\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Dees the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n    The ``plus`` argument\n    \"\"\"\n    \n    if isinstance(value, bytes):\n        value = value.decode(encoding or 'utf-8')\n\n    # Use urllib.parse.unquote to decode the URL\n    if plus:\n        return urllib.parse.unquote_plus(value, encoding)\n    else:\n        return urllib.parse.unquote(value, encoding)\n\n# Example usage:\n# url_unescaped = url_unescape(\"Hello%20World%21\")\n# print(url_unescaped)  # Outputs: Hello World!", "task_id": "tornado/id24", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: None, strip: bool = True\n    ) -> Optional[str]:\n        pass\n\n    def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2748091603053435}, {"context": "\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 717, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26229508196721313}, {"context": "        \"\"\"Maximum allowed message size.\n\n        If the remote peer sends a message larger than this, the connection\n        will be closed.\n\n        Default is 10MiB.\n        \"\"\"\n        return self.settings.get(\n            \"websocket_max_message_size\", _default_max_message_size\n        )\n\n    def write_message(\n        self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\n\n        The message may be either a string or a dict (which will be\n        encoded as json).  If the ``binary`` argument is false, the\n        message will be sent as utf8; in binary mode any byte string\n        is allowed.", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2585034013605442}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2556390977443609}, {"context": "def future_add_done_callback(\n    future: \"Future[_T]\", callback: Callable[[\"Future[_T]\"], None]\n) -> None:\n    pass\n\n\ndef future_add_done_callback(  # noqa: F811\n    future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n) -> None:\n    \"\"\"Arrange to call ``callback`` when ``future`` is complete.\n\n    ``callback`` is invoked with one argument, the ``future``.\n\n    If ``future`` is already done, ``callback`` is invoked immediately.\n    This may differ from the behavior of ``Future.add_done_callback``,\n    which makes no such guarantee.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if future.done():", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24242424242424243}, {"context": "\n\n@typing.overload\ndef gen_test(\n    *, timeout: Optional[float] = None\n) -> Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]]:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef gen_test(func: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n    pass\n\n\ndef gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],", "metadata": [{"fpath_tuple": ["tornado", "testing.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24074074074074073}, {"context": "            self.regex.pattern,\n            self.handler_class,\n            self.kwargs,\n            self.name,\n        )\n\n\n@overload\ndef _unquote_or_none(s: str) -> bytes:\n    pass\n\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23931623931623933}, {"context": "\n    def write_message(\n        self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\n\n        The message may be either a string or a dict (which will be\n        encoded as json).  If the ``binary`` argument is false, the\n        message will be sent as utf8; in binary mode any byte string\n        is allowed.\n\n        If the connection is already closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 3.2\n           `WebSocketClosedError` was added (previously a closed connection\n           would raise an `AttributeError`)\n\n        .. versionchanged:: 4.3\n           Returns a `.Future` which can be used for flow control.", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2389937106918239}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the body arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.body_arguments, strip)\n# \n#     def get_query_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request query string.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n#     if isinstance(val, unicode_type):\n#         val = val.encode(\"utf-8\")\n#     return urllib.parse.quote(val, safe=\"~\")\n# \n# \n# def _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n#     # I can't find an officially-defined encoding for oauth responses and\n#     # have never seen anyone use non-ascii.  Leave the response in a byte\n#     # string for python 2, and use utf8 on python 3.\n#     body_str = escape.native_str(body)\n#     p = urllib.parse.parse_qs(body_str, keep_blank_values=False)\n#     token = dict(key=p[\"oauth_token\"][0], secret=p[\"oauth_token_secret\"][0])\n# \n#     # Add the extra parameters the Provider included to the token\n#     special = (\"oauth_token\", \"oauth_token_secret\")\n#     token.update((k, p[k][0]) for k in p if k not in special)\n#     return token\n# --------------------------------------------------\n# the below code fragment can be found in:\n# wsgi.py\n# --------------------------------------------------\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Type  # noqa: F401\n#     from wsgiref.types import WSGIApplication as WSGIAppType  # noqa: F401\n# \n# \n# # PEP 3333 specifies that WSGI on python 3 generally deals with byte strings\n# # that are smuggled inside objects of type unicode (via the latin1 encoding).\n# # This function is like those in the tornado.escape module, but defined\n# # here to minimize the temptation to use it in non-wsgi contexts.\n# def to_wsgi_str(s: bytes) -> str:\n#     assert isinstance(s, bytes)\n#     return s.decode(\"latin1\")\n# \n# \n# class WSGIContainer(object):\n#     r\"\"\"Makes a WSGI-compatible function runnable on Tornado's HTTP server.\n# \n#     .. warning::\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     args: Optional[List[str]] = None, final: bool = True\n# ) -> List[str]:\n#     \"\"\"Parses global options from the command line.\n# \n#     See `OptionParser.parse_command_line`.\n#     \"\"\"\n#     return options.parse_command_line(args, final=final)\n# \n# \n# def parse_config_file(path: str, final: bool = True) -> None:\n#     \"\"\"Parses global options from a config file.\n# \n#     See `OptionParser.parse_config_file`.\n#     \"\"\"\n#     return options.parse_config_file(path, final=final)\n# \n# \n# def print_help(file: Optional[TextIO] = None) -> None:\n#     \"\"\"Prints all the command line options to stderr (or another file).\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request query string.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def _get_arguments(\n#         self, name: str, source: Dict[str, List[bytes]], strip: bool = True\n#     ) -> List[str]:\n#         values = []\n#         for v in source.get(name, []):\n#             s = self.decode_argument(v, name=name)\n#             if isinstance(s, unicode_type):\n#                 # Get rid of any weird control chars (unless decoding gave\n#                 # us bytes, in which case leave it alone)\n#                 s = RequestHandler._remove_control_chars_regex.sub(\" \", s)\n#             if strip:\n#                 s = s.strip()\n#             values.append(s)\n#         return values\n# \n#     def decode_argument(self, value: bytes, name: Optional[str] = None) -> str:\n#         \"\"\"Decodes an argument from the request.\n# \n#         The argument has been percent-decoded and is now a byte string.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# \n# def parse_multipart_form_data(\n#     boundary: bytes,\n#     data: bytes,\n#     arguments: Dict[str, List[bytes]],\n#     files: Dict[str, List[HTTPFile]],\n# ) -> None:\n#     \"\"\"Parses a ``multipart/form-data`` body.\n# \n#     The ``boundary`` and ``data`` parameters are both byte strings.\n#     The dictionaries given in the arguments and files parameters\n#     will be updated with the contents of the body.\n# \n#     .. versionchanged:: 5.1\n# \n#        Now recognizes non-ASCII filenames in RFC 2231/5987\n#        (``filename*=``) format.\n#     \"\"\"\n#     # The standard allows for the boundary to be quoted in the header,\n# --------------------------------------------------\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id25", "ground_truth": "def parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n    # This is gross, but python3 doesn't give us another way.\n    # Latin1 is the universal donor of character encodings.\n    if isinstance(qs, bytes):\n        qs = qs.decode(\"latin1\")\n    result = urllib.parse.parse_qs(\n        qs, keep_blank_values, strict_parsing, encoding=\"latin1\", errors=\"strict\"\n    )\n    encoded = {}\n    for k, v in result.items():\n        encoded[k] = [i.encode(\"latin1\") for i in v]\n    return encoded", "fpath_tuple": ["tornado", "escape.py"], "function_name": "parse_qs_bytes", "lineno": 0, "context_start_lineno": 0, "_id": 25, "query_window": {"context": "from typing import Dict, List, Union\ndef _bytes(query: Union[str, bytes]) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n    from urllib.parse import parse_qs\n    # If the input is of type bytes, decode it to a string", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "from typing import Dict, List, Union\n\ndef _bytes(query: Union[str, bytes]) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,\n    but takes bytes and returns the values as byte strings.\n\n    Keys still become type str (interpreted as latin1 in python3!)\n    because it's too painful to keep them as byte strings in\n    python3 and in practice they're nearly always ascii anyway.\n    \"\"\"\n    from urllib.parse import parse_qs\n\n    # If the input is of type bytes, decode it to a string\n    if isinstance(query, bytes):\n        query = query.decode('latin1')\n\n    # Use urllib's parse_qs to parse the query string\n    parsed_result = parse_qs(query, keep_blank_values=True)\n\n    # Convert the values to list of bytes\n    for key in parsed_result:\n        parsed_result[key] = [value.encode('latin1') for value in parsed_result[key]]\n\n    return parsed_result", "task_id": "tornado/id25", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n\ndef parse_multipart_form_data(\n    boundary: bytes,\n    data: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n) -> None:\n    \"\"\"Parses a ``multipart/form-data`` body.\n\n    The ``boundary`` and ``data`` parameters are both byte strings.\n    The dictionaries given in the arguments and files parameters\n    will be updated with the contents of the body.\n\n    .. versionchanged:: 5.1\n\n       Now recognizes non-ASCII filenames in RFC 2231/5987\n       (``filename*=``) format.\n    \"\"\"\n    # The standard allows for the boundary to be quoted in the header,", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 800, "start_line_no": 790, "end_line_no": 810, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2214765100671141}, {"context": "\n    def _get_arguments(\n        self, name: str, source: Dict[str, List[bytes]], strip: bool = True\n    ) -> List[str]:\n        values = []\n        for v in source.get(name, []):\n            s = self.decode_argument(v, name=name)\n            if isinstance(s, unicode_type):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)\n                s = RequestHandler._remove_control_chars_regex.sub(\" \", s)\n            if strip:\n                s = s.strip()\n            values.append(s)\n        return values\n\n    def decode_argument(self, value: bytes, name: Optional[str] = None) -> str:\n        \"\"\"Decodes an argument from the request.\n\n        The argument has been percent-decoded and is now a byte string.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 550, "start_line_no": 540, "end_line_no": 560, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21084337349397592}, {"context": "        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20394736842105263}, {"context": "    args: Optional[List[str]] = None, final: bool = True\n) -> List[str]:\n    \"\"\"Parses global options from the command line.\n\n    See `OptionParser.parse_command_line`.\n    \"\"\"\n    return options.parse_command_line(args, final=final)\n\n\ndef parse_config_file(path: str, final: bool = True) -> None:\n    \"\"\"Parses global options from a config file.\n\n    See `OptionParser.parse_config_file`.\n    \"\"\"\n    return options.parse_config_file(path, final=final)\n\n\ndef print_help(file: Optional[TextIO] = None) -> None:\n    \"\"\"Prints all the command line options to stderr (or another file).\n", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 720, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1984732824427481}, {"context": "\nif typing.TYPE_CHECKING:\n    from typing import Type  # noqa: F401\n    from wsgiref.types import WSGIApplication as WSGIAppType  # noqa: F401\n\n\n# PEP 3333 specifies that WSGI on python 3 generally deals with byte strings\n# that are smuggled inside objects of type unicode (via the latin1 encoding).\n# This function is like those in the tornado.escape module, but defined\n# here to minimize the temptation to use it in non-wsgi contexts.\ndef to_wsgi_str(s: bytes) -> str:\n    assert isinstance(s, bytes)\n    return s.decode(\"latin1\")\n\n\nclass WSGIContainer(object):\n    r\"\"\"Makes a WSGI-compatible function runnable on Tornado's HTTP server.\n\n    .. warning::\n", "metadata": [{"fpath_tuple": ["tornado", "wsgi.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1977401129943503}, {"context": "    if isinstance(val, unicode_type):\n        val = val.encode(\"utf-8\")\n    return urllib.parse.quote(val, safe=\"~\")\n\n\ndef _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n    # I can't find an officially-defined encoding for oauth responses and\n    # have never seen anyone use non-ascii.  Leave the response in a byte\n    # string for python 2, and use utf8 on python 3.\n    body_str = escape.native_str(body)\n    p = urllib.parse.parse_qs(body_str, keep_blank_values=False)\n    token = dict(key=p[\"oauth_token\"][0], secret=p[\"oauth_token_secret\"][0])\n\n    # Add the extra parameters the Provider included to the token\n    special = (\"oauth_token\", \"oauth_token_secret\")\n    token.update((k, p[k][0]) for k in p if k not in special)\n    return token", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 1180, "start_line_no": 1170, "end_line_no": 1187, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1977401129943503}, {"context": "    def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n\n    def get_query_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19736842105263158}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         as returned by _find_read_pos.\n#         \"\"\"\n#         self._read_bytes = self._read_delimiter = self._read_regex = None\n#         self._read_partial = False\n#         self._finish_read(pos, False)\n# \n#     def _find_read_pos(self) -> Optional[int]:\n#         \"\"\"Attempts to find a position in the read buffer that satisfies\n#         the currently-pending read.\n# \n#         Returns a position in the buffer if the current read can be satisfied,\n#         or None if it cannot.\n#         \"\"\"\n#         if self._read_bytes is not None and (\n#             self._read_buffer_size >= self._read_bytes\n#             or (self._read_partial and self._read_buffer_size > 0)\n#         ):\n#             num_bytes = min(self._read_bytes, self._read_buffer_size)\n#             return num_bytes\n#         elif self._read_delimiter is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     timestamp = int(timestamp_bytes)\n#     if timestamp < clock() - max_age_days * 86400:\n#         # The signature has expired.\n#         return None\n#     try:\n#         return base64.b64decode(value_field)\n#     except Exception:\n#         return None\n# \n# \n# def get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n#     value = utf8(value)\n#     version = _get_version(value)\n#     if version < 2:\n#         return None\n#     try:\n#         key_version, _, _, _, _ = _decode_fields_v2(value)\n#     except ValueError:\n#         return None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#                 version, token, timestamp = self._decode_xsrf_token(cookie)\n#             else:\n#                 version, token, timestamp = None, None, None\n#             if token is None:\n#                 version = None\n#                 token = os.urandom(16)\n#                 timestamp = time.time()\n#             assert token is not None\n#             assert timestamp is not None\n#             self._raw_xsrf_token = (version, token, timestamp)\n#         return self._raw_xsrf_token\n# \n#     def _decode_xsrf_token(\n#         self, cookie: str\n#     ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n#         \"\"\"Convert a cookie string into a the tuple form returned by\n#         _get_raw_xsrf_token.\n#         \"\"\"\n# \n#         try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# \n#     Note that args are passed as bytes so the handler can decide what\n#     encoding to use.\n#     \"\"\"\n#     if s is None:\n#         return s\n#     return url_unescape(s, encoding=None, plus=False)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     value = utf8(value)\n#     version = _get_version(value)\n# \n#     if version < min_version:\n#         return None\n#     if version == 1:\n#         assert not isinstance(secret, dict)\n#         return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n#     elif version == 2:\n#         return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n#     else:\n#         return None\n# \n# \n# def _decode_signed_value_v1(\n#     secret: Union[str, bytes],\n#     name: str,\n#     value: bytes,\n#     max_age_days: float,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: None, strip: bool = True\n#     ) -> Optional[str]:\n#         pass\n# \n#     def get_argument(  # noqa: F811\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the request more than once, we return the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         if isinstance(secret, dict):\n#             if self.application.settings.get(\"key_version\") is None:\n#                 raise Exception(\"key_version setting must be used for secret_key dicts\")\n#             key_version = self.application.settings[\"key_version\"]\n# \n#         return create_signed_value(\n#             secret, name, value, version=version, key_version=key_version\n#         )\n# \n#     def get_secure_cookie(\n#         self,\n#         name: str,\n#         value: Optional[str] = None,\n#         max_age_days: float = 31,\n#         min_version: Optional[int] = None,\n#     ) -> Optional[bytes]:\n#         \"\"\"Returns the given signed cookie if it validates, or None.\n# \n#         The decoded cookie value is returned as a byte string (unlike\n#         `get_cookie`).\n# --------------------------------------------------\n\ndef utf8(value: Union[None, str, bytes]) -> Optional[bytes]:\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id26", "ground_truth": "def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise it must be a unicode string and is encoded as utf8.\n    \"\"\"\n    if isinstance(value, _UTF8_TYPES):\n        return value\n    if not isinstance(value, unicode_type):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.encode(\"utf-8\")", "fpath_tuple": ["tornado", "escape.py"], "function_name": "utf8", "lineno": 0, "context_start_lineno": 0, "_id": 26, "query_window": {"context": "from typing import Union, Optional\ndef utf8(value: Union[None, str, bytes]) -> Optional[bytes]:\n    \"\"\"Converts a string argument to a byte string.\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise, it must be a unicode string and is encoded as utf8.\n    \"\"\"\n    if value is None:\n        return None\n    if isinstance(value, bytes):\n        return value", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "from typing import Union, Optional\n\ndef utf8(value: Union[None, str, bytes]) -> Optional[bytes]:\n    \"\"\"Converts a string argument to a byte string.\n\n    If the argument is already a byte string or None, it is returned unchanged.\n    Otherwise, it must be a unicode string and is encoded as utf8.\n    \"\"\"\n    if value is None:\n        return None\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    raise TypeError(\"Expected a string or bytes, got: {}\".format(type(value)))", "task_id": "tornado/id26", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n\n        return create_signed_value(\n            secret, name, value, version=version, key_version=key_version\n        )\n\n    def get_secure_cookie(\n        self,\n        name: str,\n        value: Optional[str] = None,\n        max_age_days: float = 31,\n        min_version: Optional[int] = None,\n    ) -> Optional[bytes]:\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2807017543859649}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26126126126126126}, {"context": "        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: None, strip: bool = True\n    ) -> Optional[str]:\n        pass\n\n    def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26126126126126126}, {"context": "\n    value = utf8(value)\n    version = _get_version(value)\n\n    if version < min_version:\n        return None\n    if version == 1:\n        assert not isinstance(secret, dict)\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None\n\n\ndef _decode_signed_value_v1(\n    secret: Union[str, bytes],\n    name: str,\n    value: bytes,\n    max_age_days: float,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3460, "start_line_no": 3450, "end_line_no": 3470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24719101123595505}, {"context": "\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 717, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24509803921568626}, {"context": "                version, token, timestamp = self._decode_xsrf_token(cookie)\n            else:\n                version, token, timestamp = None, None, None\n            if token is None:\n                version = None\n                token = os.urandom(16)\n                timestamp = time.time()\n            assert token is not None\n            assert timestamp is not None\n            self._raw_xsrf_token = (version, token, timestamp)\n        return self._raw_xsrf_token\n\n    def _decode_xsrf_token(\n        self, cookie: str\n    ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n\n        try:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1450, "start_line_no": 1440, "end_line_no": 1460, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24509803921568626}, {"context": "    timestamp = int(timestamp_bytes)\n    if timestamp < clock() - max_age_days * 86400:\n        # The signature has expired.\n        return None\n    try:\n        return base64.b64decode(value_field)\n    except Exception:\n        return None\n\n\ndef get_signature_key_version(value: Union[str, bytes]) -> Optional[int]:\n    value = utf8(value)\n    version = _get_version(value)\n    if version < 2:\n        return None\n    try:\n        key_version, _, _, _, _ = _decode_fields_v2(value)\n    except ValueError:\n        return None\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3560, "start_line_no": 3550, "end_line_no": 3570, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24271844660194175}, {"context": "        as returned by _find_read_pos.\n        \"\"\"\n        self._read_bytes = self._read_delimiter = self._read_regex = None\n        self._read_partial = False\n        self._finish_read(pos, False)\n\n    def _find_read_pos(self) -> Optional[int]:\n        \"\"\"Attempts to find a position in the read buffer that satisfies\n        the currently-pending read.\n\n        Returns a position in the buffer if the current read can be satisfied,\n        or None if it cannot.\n        \"\"\"\n        if self._read_bytes is not None and (\n            self._read_buffer_size >= self._read_bytes\n            or (self._read_partial and self._read_buffer_size > 0)\n        ):\n            num_bytes = min(self._read_bytes, self._read_buffer_size)\n            return num_bytes\n        elif self._read_delimiter is not None:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 910, "start_line_no": 900, "end_line_no": 920, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24074074074074073}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         is given it will be called with the future when it is\n#         ready.\n#         \"\"\"\n# \n#         awaitable = self.read_queue.get()\n#         if callback is not None:\n#             self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n#         return awaitable\n# \n#     def on_message(self, message: Union[str, bytes]) -> Optional[Awaitable[None]]:\n#         return self._on_message(message)\n# \n#     def _on_message(\n#         self, message: Union[None, str, bytes]\n#     ) -> Optional[Awaitable[None]]:\n#         if self._on_message_callback:\n#             self._on_message_callback(message)\n#             return None\n#         else:\n#             return self.read_queue.put(message)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#                 s = RequestHandler._remove_control_chars_regex.sub(\" \", s)\n#             if strip:\n#                 s = s.strip()\n#             values.append(s)\n#         return values\n# \n#     def decode_argument(self, value: bytes, name: Optional[str] = None) -> str:\n#         \"\"\"Decodes an argument from the request.\n# \n#         The argument has been percent-decoded and is now a byte string.\n#         By default, this method decodes the argument as utf-8 and returns\n#         a unicode string, but this may be overridden in subclasses.\n# \n#         This method is used as a filter for both `get_argument()` and for\n#         values extracted from the url and passed to `get()`/`post()`/etc.\n# \n#         The name of the argument is provided if known, but may be None\n#         (e.g. for unnamed groups in the url regex).\n#         \"\"\"\n#         try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         as returned by _find_read_pos.\n#         \"\"\"\n#         self._read_bytes = self._read_delimiter = self._read_regex = None\n#         self._read_partial = False\n#         self._finish_read(pos, False)\n# \n#     def _find_read_pos(self) -> Optional[int]:\n#         \"\"\"Attempts to find a position in the read buffer that satisfies\n#         the currently-pending read.\n# \n#         Returns a position in the buffer if the current read can be satisfied,\n#         or None if it cannot.\n#         \"\"\"\n#         if self._read_bytes is not None and (\n#             self._read_buffer_size >= self._read_bytes\n#             or (self._read_partial and self._read_buffer_size > 0)\n#         ):\n#             num_bytes = min(self._read_bytes, self._read_buffer_size)\n#             return num_bytes\n#         elif self._read_delimiter is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         \"\"\"\n#         return None\n# \n#     def html_body(self) -> Optional[str]:\n#         \"\"\"Override to return an HTML string that will be put at the end of\n#         the <body/> element.\n#         \"\"\"\n#         return None\n# \n#     def render_string(self, path: str, **kwargs: Any) -> bytes:\n#         \"\"\"Renders a template and returns it as a string.\"\"\"\n#         return self.handler.render_string(path, **kwargs)\n# \n# \n# class _linkify(UIModule):\n#     def render(self, text: str, **kwargs: Any) -> str:  # type: ignore\n#         return escape.linkify(text, **kwargs)\n# \n# \n# class _xsrf_form_html(UIModule):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         pass\n# \n#     @overload\n#     def get_argument(  # noqa: F811\n#         self, name: str, default: None, strip: bool = True\n#     ) -> Optional[str]:\n#         pass\n# \n#     def get_argument(  # noqa: F811\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the request more than once, we return the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     value = utf8(value)\n#     version = _get_version(value)\n# \n#     if version < min_version:\n#         return None\n#     if version == 1:\n#         assert not isinstance(secret, dict)\n#         return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n#     elif version == 2:\n#         return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n#     else:\n#         return None\n# \n# \n# def _decode_signed_value_v1(\n#     secret: Union[str, bytes],\n#     name: str,\n#     value: bytes,\n#     max_age_days: float,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         if isinstance(secret, dict):\n#             if self.application.settings.get(\"key_version\") is None:\n#                 raise Exception(\"key_version setting must be used for secret_key dicts\")\n#             key_version = self.application.settings[\"key_version\"]\n# \n#         return create_signed_value(\n#             secret, name, value, version=version, key_version=key_version\n#         )\n# \n#     def get_secure_cookie(\n#         self,\n#         name: str,\n#         value: Optional[str] = None,\n#         max_age_days: float = 31,\n#         min_version: Optional[int] = None,\n#     ) -> Optional[bytes]:\n#         \"\"\"Returns the given signed cookie if it validates, or None.\n# \n#         The decoded cookie value is returned as a byte string (unlike\n#         `get_cookie`).\n# --------------------------------------------------\n\ndef to_unicode(value: Union[None, str, bytes]) -> Optional[str]:\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id27", "ground_truth": "def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:  # noqa: F811\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise it must be a byte string and is decoded as utf8.\n    \"\"\"\n    if isinstance(value, _TO_UNICODE_TYPES):\n        return value\n    if not isinstance(value, bytes):\n        raise TypeError(\"Expected bytes, unicode, or None; got %r\" % type(value))\n    return value.decode(\"utf-8\")", "fpath_tuple": ["tornado", "escape.py"], "function_name": "to_unicode", "lineno": 0, "context_start_lineno": 0, "_id": 27, "query_window": {"context": "from typing import Optional, Union\ndef to_unicode(value: Union[None, str, bytes]) -> Optional[str]:\n    \"\"\"Converts a string argument to a unicode string.\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise, it must be a byte string and is decoded as utf.\n    \"\"\"\n    if value is None:\n        return None\n    elif isinstance(value, str):\n        return value", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "from typing import Optional, Union\n\ndef to_unicode(value: Union[None, str, bytes]) -> Optional[str]:\n    \"\"\"Converts a string argument to a unicode string.\n\n    If the argument is already a unicode string or None, it is returned\n    unchanged.  Otherwise, it must be a byte string and is decoded as utf.\n    \"\"\"\n    if value is None:\n        return None\n    elif isinstance(value, str):\n        return value\n    elif isinstance(value, bytes):\n        return value.decode('utf-8')\n    else:\n        raise TypeError(\"Expected a string or bytes, but got: {}\".format(type(value)))", "task_id": "tornado/id27", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        if isinstance(secret, dict):\n            if self.application.settings.get(\"key_version\") is None:\n                raise Exception(\"key_version setting must be used for secret_key dicts\")\n            key_version = self.application.settings[\"key_version\"]\n\n        return create_signed_value(\n            secret, name, value, version=version, key_version=key_version\n        )\n\n    def get_secure_cookie(\n        self,\n        name: str,\n        value: Optional[str] = None,\n        max_age_days: float = 31,\n        min_version: Optional[int] = None,\n    ) -> Optional[bytes]:\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.3017241379310345}, {"context": "\n    value = utf8(value)\n    version = _get_version(value)\n\n    if version < min_version:\n        return None\n    if version == 1:\n        assert not isinstance(secret, dict)\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None\n\n\ndef _decode_signed_value_v1(\n    secret: Union[str, bytes],\n    name: str,\n    value: bytes,\n    max_age_days: float,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3460, "start_line_no": 3450, "end_line_no": 3470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.27472527472527475}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2719298245614035}, {"context": "        pass\n\n    @overload\n    def get_argument(  # noqa: F811\n        self, name: str, default: None, strip: bool = True\n    ) -> Optional[str]:\n        pass\n\n    def get_argument(  # noqa: F811\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the request more than once, we return the", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2719298245614035}, {"context": "        \"\"\"\n        return None\n\n    def html_body(self) -> Optional[str]:\n        \"\"\"Override to return an HTML string that will be put at the end of\n        the <body/> element.\n        \"\"\"\n        return None\n\n    def render_string(self, path: str, **kwargs: Any) -> bytes:\n        \"\"\"Renders a template and returns it as a string.\"\"\"\n        return self.handler.render_string(path, **kwargs)\n\n\nclass _linkify(UIModule):\n    def render(self, text: str, **kwargs: Any) -> str:  # type: ignore\n        return escape.linkify(text, **kwargs)\n\n\nclass _xsrf_form_html(UIModule):", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3240, "start_line_no": 3230, "end_line_no": 3250, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25663716814159293}, {"context": "        as returned by _find_read_pos.\n        \"\"\"\n        self._read_bytes = self._read_delimiter = self._read_regex = None\n        self._read_partial = False\n        self._finish_read(pos, False)\n\n    def _find_read_pos(self) -> Optional[int]:\n        \"\"\"Attempts to find a position in the read buffer that satisfies\n        the currently-pending read.\n\n        Returns a position in the buffer if the current read can be satisfied,\n        or None if it cannot.\n        \"\"\"\n        if self._read_bytes is not None and (\n            self._read_buffer_size >= self._read_bytes\n            or (self._read_partial and self._read_buffer_size > 0)\n        ):\n            num_bytes = min(self._read_bytes, self._read_buffer_size)\n            return num_bytes\n        elif self._read_delimiter is not None:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 910, "start_line_no": 900, "end_line_no": 920, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25225225225225223}, {"context": "                s = RequestHandler._remove_control_chars_regex.sub(\" \", s)\n            if strip:\n                s = s.strip()\n            values.append(s)\n        return values\n\n    def decode_argument(self, value: bytes, name: Optional[str] = None) -> str:\n        \"\"\"Decodes an argument from the request.\n\n        The argument has been percent-decoded and is now a byte string.\n        By default, this method decodes the argument as utf-8 and returns\n        a unicode string, but this may be overridden in subclasses.\n\n        This method is used as a filter for both `get_argument()` and for\n        values extracted from the url and passed to `get()`/`post()`/etc.\n\n        The name of the argument is provided if known, but may be None\n        (e.g. for unnamed groups in the url regex).\n        \"\"\"\n        try:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 560, "start_line_no": 550, "end_line_no": 570, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25}, {"context": "        is given it will be called with the future when it is\n        ready.\n        \"\"\"\n\n        awaitable = self.read_queue.get()\n        if callback is not None:\n            self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n        return awaitable\n\n    def on_message(self, message: Union[str, bytes]) -> Optional[Awaitable[None]]:\n        return self._on_message(message)\n\n    def _on_message(\n        self, message: Union[None, str, bytes]\n    ) -> Optional[Awaitable[None]]:\n        if self._on_message_callback:\n            self._on_message_callback(message)\n            return None\n        else:\n            return self.read_queue.put(message)", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1530, "start_line_no": 1520, "end_line_no": 1540, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24528301886792453}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# # responses is unused in this file, but we re-export it to other files.\n# # Reference it so pyflakes doesn't complain.\n# responses\n# \n# import typing\n# from typing import (\n#     Tuple,\n#     Iterable,\n#     List,\n#     Mapping,\n#     Iterator,\n#     Dict,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Generator,\n#     AnyStr,\n# )\n# \n# if typing.TYPE_CHECKING:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         default: Union[None, str, _ArgDefaultMarker],\n#         source: Dict[str, List[bytes]],\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         args = self._get_arguments(name, source, strip=strip)\n#         if not args:\n#             if isinstance(default, _ArgDefaultMarker):\n#                 raise MissingArgumentError(name)\n#             return default\n#         return args[-1]\n# \n#     def _get_arguments(\n#         self, name: str, source: Dict[str, List[bytes]], strip: bool = True\n#     ) -> List[str]:\n#         values = []\n#         for v in source.get(name, []):\n#             s = self.decode_argument(v, name=name)\n#             if isinstance(s, unicode_type):\n#                 # Get rid of any weird control chars (unless decoding gave\n#                 # us bytes, in which case leave it alone)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n#     if isinstance(val, unicode_type):\n#         val = val.encode(\"utf-8\")\n#     return urllib.parse.quote(val, safe=\"~\")\n# \n# \n# def _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n#     # I can't find an officially-defined encoding for oauth responses and\n#     # have never seen anyone use non-ascii.  Leave the response in a byte\n#     # string for python 2, and use utf8 on python 3.\n#     body_str = escape.native_str(body)\n#     p = urllib.parse.parse_qs(body_str, keep_blank_values=False)\n#     token = dict(key=p[\"oauth_token\"][0], secret=p[\"oauth_token_secret\"][0])\n# \n#     # Add the extra parameters the Provider included to the token\n#     special = (\"oauth_token\", \"oauth_token_secret\")\n#     token.update((k, p[k][0]) for k in p if k not in special)\n#     return token\n# --------------------------------------------------\n# the below code fragment can be found in:\n# log.py\n# --------------------------------------------------\n#         if record.exc_text:\n#             # exc_text contains multiple lines.  We need to _safe_unicode\n#             # each line separately so that non-utf8 bytes don't cause\n#             # all the newlines to turn into '\\n'.\n#             lines = [formatted.rstrip()]\n#             lines.extend(_safe_unicode(ln) for ln in record.exc_text.split(\"\\n\"))\n#             formatted = \"\\n\".join(lines)\n#         return formatted.replace(\"\\n\", \"\\n    \")\n# \n# \n# def enable_pretty_logging(\n#     options: Any = None, logger: Optional[logging.Logger] = None\n# ) -> None:\n#     \"\"\"Turns on formatted logging output as configured.\n# \n#     This is called automatically by `tornado.options.parse_command_line`\n#     and `tornado.options.parse_config_file`.\n#     \"\"\"\n#     if options is None:\n#         import tornado.options\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     return int(val)\n# \n# \n# def parse_body_arguments(\n#     content_type: str,\n#     body: bytes,\n#     arguments: Dict[str, List[bytes]],\n#     files: Dict[str, List[HTTPFile]],\n#     headers: Optional[HTTPHeaders] = None,\n# ) -> None:\n#     \"\"\"Parses a form request body.\n# \n#     Supports ``application/x-www-form-urlencoded`` and\n#     ``multipart/form-data``.  The ``content_type`` parameter should be\n#     a string and ``body`` should be a byte string.  The ``arguments``\n#     and ``files`` parameters are dictionaries that will be updated\n#     with the parsed contents.\n#     \"\"\"\n#     if content_type.startswith(\"application/x-www-form-urlencoded\"):\n#         if headers and \"Content-Encoding\" in headers:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n#     json_decode,\n#     json_encode,\n#     squeeze,\n#     recursive_unicode,\n# )\n# from tornado.util import unicode_type\n# \n# from typing import List, Tuple, Union, Dict, Any  # noqa: F401\n# \n# linkify_tests = [\n#     # (input, linkify_kwargs, expected_output)\n#     (\n#         \"hello http://world.com/!\",\n#         {},\n#         u'hello <a href=\"http://world.com/\">http://world.com/</a>!',\n#     ),\n#     (\n#         \"hello http://world.com/with?param=true&stuff=yes\",\n#         {},\n#         u'hello <a href=\"http://world.com/with?param=true&amp;stuff=yes\">http://world.com/with?param=true&amp;stuff=yes</a>',  # noqa: E501\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def encode_username_password(\n#     username: Union[str, bytes], password: Union[str, bytes]\n# ) -> bytes:\n#     \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n# \n#     The return value is a byte string in the form ``username:password``.\n# \n#     .. versionadded:: 5.1\n#     \"\"\"\n#     if isinstance(username, unicode_type):\n#         username = unicodedata.normalize(\"NFC\", username)\n#     if isinstance(password, unicode_type):\n#         password = unicodedata.normalize(\"NFC\", password)\n#     return utf8(username) + b\":\" + utf8(password)\n# \n# \n# def doctests():\n#     # type: () -> unittest.TestSuite\n#     import doctest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import (\n#     utf8,\n#     xhtml_escape,\n#     xhtml_unescape,\n#     url_escape,\n#     url_unescape,\n#     to_unicode,\n#     json_decode,\n#     json_encode,\n#     squeeze,\n#     recursive_unicode,\n# )\n# from tornado.util import unicode_type\n# \n# from typing import List, Tuple, Union, Dict, Any  # noqa: F401\n# \n# linkify_tests = [\n# --------------------------------------------------\n\ndef recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id28", "ground_truth": "def recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n    if isinstance(obj, dict):\n        return dict(\n            (recursive_unicode(k), recursive_unicode(v)) for (k, v) in obj.items()\n        )\n    elif isinstance(obj, list):\n        return list(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, tuple):\n        return tuple(recursive_unicode(i) for i in obj)\n    elif isinstance(obj, bytes):\n        return to_unicode(obj)\n    else:\n        return obj", "fpath_tuple": ["tornado", "escape.py"], "function_name": "recursive_unicode", "lineno": 0, "context_start_lineno": 0, "_id": 28, "query_window": {"context": "from typing import Any, Dict, List, Tuple, Union\ndef recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8', errors='replace')  # Convert bytes to Unicode\n    elif isinstance(obj, list):\n        return [recursive_unicode(item) for item in obj]  # Recursively convert items\n    elif isinstance(obj, tuple):", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "from typing import Any, Dict, List, Tuple, Union\n\ndef recursive_unicode(obj: Any) -> Any:\n    \"\"\"Walks a simple data structure, converting byte strings to unicode.\n\n    Supports lists, tuples, and dictionaries.\n    \"\"\"\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8', errors='replace')  # Convert bytes to Unicode\n    elif isinstance(obj, list):\n        return [recursive_unicode(item) for item in obj]  # Recursively convert items\n    elif isinstance(obj, tuple):\n        return tuple(recursive_unicode(item) for item in obj)  # Recursively convert items\n    elif isinstance(obj, dict):\n        return {recursive_unicode(key): recursive_unicode(value) for key, value in obj.items()}  # Recursively convert keys and values\n    else:\n        return obj  # Return as is if it's unsupported type (e.g., int, float, etc.)\n\n# Example usage:\ndata = {\n    b'key1': b'value1',\n    b'key2': [b'value2a', b'value2b'],\n    b'key3': (b'value3a', b'value3b'),\n    b'key4': {b'subkey1': b'subvalue1', b'subkey2': b'subvalue2'},\n    'key5': 42  # non-UTF-8 value\n}\n\nprint(recursive_unicode(data))", "task_id": "tornado/id28", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "import unittest\n\nimport tornado.escape\nfrom tornado.escape import (\n    utf8,\n    xhtml_escape,\n    xhtml_unescape,\n    url_escape,\n    url_unescape,\n    to_unicode,\n    json_decode,\n    json_encode,\n    squeeze,\n    recursive_unicode,\n)\nfrom tornado.util import unicode_type\n\nfrom typing import List, Tuple, Union, Dict, Any  # noqa: F401\n\nlinkify_tests = [", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24770642201834864}, {"context": "\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)\n\n\ndef doctests():\n    # type: () -> unittest.TestSuite\n    import doctest", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2014388489208633}, {"context": "    json_decode,\n    json_encode,\n    squeeze,\n    recursive_unicode,\n)\nfrom tornado.util import unicode_type\n\nfrom typing import List, Tuple, Union, Dict, Any  # noqa: F401\n\nlinkify_tests = [\n    # (input, linkify_kwargs, expected_output)\n    (\n        \"hello http://world.com/!\",\n        {},\n        u'hello <a href=\"http://world.com/\">http://world.com/</a>!',\n    ),\n    (\n        \"hello http://world.com/with?param=true&stuff=yes\",\n        {},\n        u'hello <a href=\"http://world.com/with?param=true&amp;stuff=yes\">http://world.com/with?param=true&amp;stuff=yes</a>',  # noqa: E501", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19424460431654678}, {"context": "    return int(val)\n\n\ndef parse_body_arguments(\n    content_type: str,\n    body: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n    headers: Optional[HTTPHeaders] = None,\n) -> None:\n    \"\"\"Parses a form request body.\n\n    Supports ``application/x-www-form-urlencoded`` and\n    ``multipart/form-data``.  The ``content_type`` parameter should be\n    a string and ``body`` should be a byte string.  The ``arguments``\n    and ``files`` parameters are dictionaries that will be updated\n    with the parsed contents.\n    \"\"\"\n    if content_type.startswith(\"application/x-www-form-urlencoded\"):\n        if headers and \"Content-Encoding\" in headers:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19205298013245034}, {"context": "        if record.exc_text:\n            # exc_text contains multiple lines.  We need to _safe_unicode\n            # each line separately so that non-utf8 bytes don't cause\n            # all the newlines to turn into '\\n'.\n            lines = [formatted.rstrip()]\n            lines.extend(_safe_unicode(ln) for ln in record.exc_text.split(\"\\n\"))\n            formatted = \"\\n\".join(lines)\n        return formatted.replace(\"\\n\", \"\\n    \")\n\n\ndef enable_pretty_logging(\n    options: Any = None, logger: Optional[logging.Logger] = None\n) -> None:\n    \"\"\"Turns on formatted logging output as configured.\n\n    This is called automatically by `tornado.options.parse_command_line`\n    and `tornado.options.parse_config_file`.\n    \"\"\"\n    if options is None:\n        import tornado.options", "metadata": [{"fpath_tuple": ["tornado", "log.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19047619047619047}, {"context": "    if isinstance(val, unicode_type):\n        val = val.encode(\"utf-8\")\n    return urllib.parse.quote(val, safe=\"~\")\n\n\ndef _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n    # I can't find an officially-defined encoding for oauth responses and\n    # have never seen anyone use non-ascii.  Leave the response in a byte\n    # string for python 2, and use utf8 on python 3.\n    body_str = escape.native_str(body)\n    p = urllib.parse.parse_qs(body_str, keep_blank_values=False)\n    token = dict(key=p[\"oauth_token\"][0], secret=p[\"oauth_token_secret\"][0])\n\n    # Add the extra parameters the Provider included to the token\n    special = (\"oauth_token\", \"oauth_token_secret\")\n    token.update((k, p[k][0]) for k in p if k not in special)\n    return token", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 1180, "start_line_no": 1170, "end_line_no": 1187, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1896551724137931}, {"context": "        default: Union[None, str, _ArgDefaultMarker],\n        source: Dict[str, List[bytes]],\n        strip: bool = True,\n    ) -> Optional[str]:\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if isinstance(default, _ArgDefaultMarker):\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]\n\n    def _get_arguments(\n        self, name: str, source: Dict[str, List[bytes]], strip: bool = True\n    ) -> List[str]:\n        values = []\n        for v in source.get(name, []):\n            s = self.decode_argument(v, name=name)\n            if isinstance(s, unicode_type):\n                # Get rid of any weird control chars (unless decoding gave\n                # us bytes, in which case leave it alone)", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 540, "start_line_no": 530, "end_line_no": 550, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1891891891891892}, {"context": "# responses is unused in this file, but we re-export it to other files.\n# Reference it so pyflakes doesn't complain.\nresponses\n\nimport typing\nfrom typing import (\n    Tuple,\n    Iterable,\n    List,\n    Mapping,\n    Iterator,\n    Dict,\n    Union,\n    Optional,\n    Awaitable,\n    Generator,\n    AnyStr,\n)\n\nif typing.TYPE_CHECKING:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18487394957983194}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     Any,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Tuple,\n#     List,\n#     Callable,\n#     Iterable,\n#     Generator,\n#     Type,\n#     cast,\n#     overload,\n# )\n# from types import TracebackType\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Set  # noqa: F401\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     group: Optional[str] = None,\n#     callback: Optional[Callable[[Any], None]] = None,\n# ) -> None:\n#     \"\"\"Defines an option in the global namespace.\n# \n#     See `OptionParser.define`.\n#     \"\"\"\n#     return options.define(\n#         name,\n#         default=default,\n#         type=type,\n#         help=help,\n#         metavar=metavar,\n#         multiple=multiple,\n#         group=group,\n#         callback=callback,\n#     )\n# \n# \n# def parse_command_line(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#     def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n#         raise NotImplementedError()\n# \n#     @abc.abstractmethod\n#     def is_closing(self) -> bool:\n#         raise NotImplementedError()\n# \n#     @abc.abstractmethod\n#     async def accept_connection(self, handler: WebSocketHandler) -> None:\n#         raise NotImplementedError()\n# \n#     @abc.abstractmethod\n#     def write_message(\n#         self, message: Union[str, bytes], binary: bool = False\n#     ) -> \"Future[None]\":\n#         raise NotImplementedError()\n# \n#     @property\n#     @abc.abstractmethod\n#     def selected_subprotocol(self) -> Optional[str]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n# \n# @typing.overload\n# def future_add_done_callback(\n#     future: \"futures.Future[_T]\", callback: Callable[[\"futures.Future[_T]\"], None]\n# ) -> None:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def future_add_done_callback(\n#     future: \"Future[_T]\", callback: Callable[[\"Future[_T]\"], None]\n# ) -> None:\n#     pass\n# \n# \n# def future_add_done_callback(  # noqa: F811\n#     future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n# ) -> None:\n#     \"\"\"Arrange to call ``callback`` when ``future`` is complete.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Tuple, ContextManager  # noqa: F401\n# \n# _DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n# \n# \n# class _UnsetMarker:\n#     pass\n# \n# \n# _UNSET = _UnsetMarker()\n# \n# \n# def filter_whitespace(mode: str, text: str) -> str:\n#     \"\"\"Transform whitespace in ``text`` according to ``mode``.\n# \n#     Available modes are:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n# def _fake_ctx_run(f: Callable[..., _T], *args: Any, **kw: Any) -> _T:\n#     return f(*args, **kw)\n# \n# \n# @overload\n# def coroutine(\n#     func: Callable[..., \"Generator[Any, Any, _T]\"]\n# ) -> Callable[..., \"Future[_T]\"]:\n#     ...\n# \n# \n# @overload\n# def coroutine(func: Callable[..., _T]) -> Callable[..., \"Future[_T]\"]:\n#     ...\n# \n# \n# def coroutine(\n#     func: Union[Callable[..., \"Generator[Any, Any, _T]\"], Callable[..., _T]]\n# ) -> Callable[..., \"Future[_T]\"]:\n#     \"\"\"Decorator for asynchronous generators.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     return key_version\n# \n# \n# def _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n#     hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n#     for part in parts:\n#         hash.update(utf8(part))\n#     return utf8(hash.hexdigest())\n# \n# \n# def _create_signature_v2(secret: Union[str, bytes], s: bytes) -> bytes:\n#     hash = hmac.new(utf8(secret), digestmod=hashlib.sha256)\n#     hash.update(utf8(s))\n#     return utf8(hash.hexdigest())\n# \n# \n# def is_absolute(path: str) -> bool:\n#     return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# \"\"\"\n# \n# \n# def define(\n#     name: str,\n#     default: Any = None,\n#     type: Optional[type] = None,\n#     help: Optional[str] = None,\n#     metavar: Optional[str] = None,\n#     multiple: bool = False,\n#     group: Optional[str] = None,\n#     callback: Optional[Callable[[Any], None]] = None,\n# ) -> None:\n#     \"\"\"Defines an option in the global namespace.\n# \n#     See `OptionParser.define`.\n#     \"\"\"\n#     return options.define(\n#         name,\n#         default=default,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# testing.py\n# --------------------------------------------------\n# \n# \n# @typing.overload\n# def gen_test(\n#     *, timeout: Optional[float] = None\n# ) -> Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]]:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def gen_test(func: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n#     pass\n# \n# \n# def gen_test(  # noqa: F811\n#     func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n#     timeout: Optional[float] = None,\n# ) -> Union[\n#     Callable[..., None],\n#     Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],\n# --------------------------------------------------\n\ndef linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n    taking the link as an argument and returning the extra text\n    e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n    or::\n\n    def extra_params_cb(url):\n    if url.startswith(\"http://example.com\"):\n    return 'class=\"internal\"'\n    else:\n    return 'class=\"external\" rel=\"nofollow\"'\n    linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n    this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n    linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n    \"mailto\"])``. It is very unsafe to include protocols such as\n    ``javascript``.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id29", "ground_truth": "def linkify(\n    text: Union[str, bytes],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into HTML with links.\n\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n\n    * ``shorten``: Long urls will be shortened for display.\n\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n      taking the link as an argument and returning the extra text\n      e.g. ``linkify(text, extra_params='rel=\"nofollow\" class=\"external\"')``,\n      or::\n\n          def extra_params_cb(url):\n              if url.startswith(\"http://example.com\"):\n                  return 'class=\"internal\"'\n              else:\n                  return 'class=\"external\" rel=\"nofollow\"'\n          linkify(text, extra_params=extra_params_cb)\n\n    * ``require_protocol``: Only linkify urls which include a protocol. If\n      this is False, urls such as www.facebook.com will also be linkified.\n\n    * ``permitted_protocols``: List (or set) of protocols which should be\n      linkified, e.g. ``linkify(text, permitted_protocols=[\"http\", \"ftp\",\n      \"mailto\"])``. It is very unsafe to include protocols such as\n      ``javascript``.\n    \"\"\"\n    if extra_params and not callable(extra_params):\n        extra_params = \" \" + extra_params.strip()\n\n    def make_link(m: typing.Match) -> str:\n        url = m.group(1)\n        proto = m.group(2)\n        if require_protocol and not proto:\n            return url  # not protocol, no linkify\n\n        if proto and proto not in permitted_protocols:\n            return url  # bad protocol, no linkify\n\n        href = m.group(1)\n        if not proto:\n            href = \"http://\" + href  # no proto specified, use http\n\n        if callable(extra_params):\n            params = \" \" + extra_params(href).strip()\n        else:\n            params = extra_params\n\n        # clip long urls. max_len is just an approximation\n        max_len = 30\n        if shorten and len(url) > max_len:\n            before_clip = url\n            if proto:\n                proto_len = len(proto) + 1 + len(m.group(3) or \"\")  # +1 for :\n            else:\n                proto_len = 0\n\n            parts = url[proto_len:].split(\"/\")\n            if len(parts) > 1:\n                # Grab the whole host part plus the first bit of the path\n                # The path is usually not that interesting once shortened\n                # (no more slug, etc), so it really just provides a little\n                # extra indication of shortening.\n                url = (\n                    url[:proto_len]\n                    + parts[0]\n                    + \"/\"\n                    + parts[1][:8].split(\"?\")[0].split(\".\")[0]\n                )\n\n            if len(url) > max_len * 1.5:  # still too long\n                url = url[:max_len]\n\n            if url != before_clip:\n                amp = url.rfind(\"&\")\n                # avoid splitting html char entities\n                if amp > max_len - 5:\n                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return u'<a href=\"%s\"%s>%s</a>' % (href, params, url)\n\n    # First HTML-escape so that our strings are all safe.\n    # The regex is modified to avoid character entites other than &amp; so\n    # that we won't pick up &quot;, etc.\n    text = _unicode(xhtml_escape(text))\n    return _URL_RE.sub(make_link, text)", "fpath_tuple": ["tornado", "escape.py"], "function_name": "linkify", "lineno": 0, "context_start_lineno": 0, "_id": 29, "query_window": {"context": "import re\nfrom typing import Union, Callable, List\ndef linkify(\n    text: Union[str, List[str]],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into links.", "metadata": {"fpath_tuple": ["tornado", "escape.py"], "line_no": 0, "prediction": "import re\nfrom typing import Union, Callable, List\n\ndef linkify(\n    text: Union[str, List[str]],\n    shorten: bool = False,\n    extra_params: Union[str, Callable[[str], str]] = \"\",\n    require_protocol: bool = False,\n    permitted_protocols: List[str] = [\"http\", \"https\"],\n) -> str:\n    \"\"\"Converts plain text into links.\n    For example: ``linkify(\"Hello http://tornadoweb.org!\")`` would return\n    ``Hello <a href=\"http://tornadoweb.org\">http://tornadoweb.org</a>!``\n\n    Parameters:\n    * ``shorten``: Long urls will be shortened for display.\n    * ``extra_params``: Extra text to include in the link tag, or a callable\n                          taking the link as an argument and returning the extra text.\n    * ``require_protocol``: Only linkify urls which include a protocol. \n    * ``permitted_protocols``: List of protocols which should be linkified.\n    \"\"\"\n\n    if isinstance(text, list):\n        text = ' '.join(text)\n\n    # Shortening function\n    def shorten_url(long_url: str) -> str:\n        return f\"{long_url[:30]}...\" if len(long_url) > 30 else long_url\n\n    # Regular expression to find links in the text\n    url_regex = r'(?:(?P<protocol>{protocol})://|(?P<no_protocol>www\\.))(?P<url>[^ \\n\\r]+)'\n    protocol_patterns = '|'.join(permitted_protocols)\n    full_regex = url_regex.format(protocol=protocol_patterns)\n\n    def link_replacer(match):\n        protocol = match.group('protocol') or 'http'\n        url = match.group('url')\n        if match.group('no_protocol'):\n            url = f\"{protocol}://{url}\"  # Add protocol if missing and it's not required\n        \n        if require_protocol and not match.group('protocol'):\n            return match.group(0)  # Return the original text if no protocol is found\n        \n        if extra_params and callable(extra_params):\n            params = extra_params(url)\n        else:\n            params = extra_params\n    \n        url_display = shorten_url(url) if shorten else url\n        return f'<a href=\"{url}\" {params}>{url_display}</a>'\n\n    # Substitute found URLs in the text\n    result = re.sub(full_regex, link_replacer, text)\n    \n    return result", "task_id": "tornado/id29", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n\n@typing.overload\ndef gen_test(\n    *, timeout: Optional[float] = None\n) -> Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]]:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef gen_test(func: Callable[..., Union[Generator, \"Coroutine\"]]) -> Callable[..., None]:\n    pass\n\n\ndef gen_test(  # noqa: F811\n    func: Optional[Callable[..., Union[Generator, \"Coroutine\"]]] = None,\n    timeout: Optional[float] = None,\n) -> Union[\n    Callable[..., None],\n    Callable[[Callable[..., Union[Generator, \"Coroutine\"]]], Callable[..., None]],", "metadata": [{"fpath_tuple": ["tornado", "testing.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23809523809523808}, {"context": "\"\"\"\n\n\ndef define(\n    name: str,\n    default: Any = None,\n    type: Optional[type] = None,\n    help: Optional[str] = None,\n    metavar: Optional[str] = None,\n    multiple: bool = False,\n    group: Optional[str] = None,\n    callback: Optional[Callable[[Any], None]] = None,\n) -> None:\n    \"\"\"Defines an option in the global namespace.\n\n    See `OptionParser.define`.\n    \"\"\"\n    return options.define(\n        name,\n        default=default,", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23333333333333334}, {"context": "    return key_version\n\n\ndef _create_signature_v1(secret: Union[str, bytes], *parts: Union[str, bytes]) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha1)\n    for part in parts:\n        hash.update(utf8(part))\n    return utf8(hash.hexdigest())\n\n\ndef _create_signature_v2(secret: Union[str, bytes], s: bytes) -> bytes:\n    hash = hmac.new(utf8(secret), digestmod=hashlib.sha256)\n    hash.update(utf8(s))\n    return utf8(hash.hexdigest())\n\n\ndef is_absolute(path: str) -> bool:\n    return any(path.startswith(x) for x in [\"/\", \"http:\", \"https:\"])", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3580, "start_line_no": 3570, "end_line_no": 3588, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21296296296296297}, {"context": "def _fake_ctx_run(f: Callable[..., _T], *args: Any, **kw: Any) -> _T:\n    return f(*args, **kw)\n\n\n@overload\ndef coroutine(\n    func: Callable[..., \"Generator[Any, Any, _T]\"]\n) -> Callable[..., \"Future[_T]\"]:\n    ...\n\n\n@overload\ndef coroutine(func: Callable[..., _T]) -> Callable[..., \"Future[_T]\"]:\n    ...\n\n\ndef coroutine(\n    func: Union[Callable[..., \"Generator[Any, Any, _T]\"], Callable[..., _T]]\n) -> Callable[..., \"Future[_T]\"]:\n    \"\"\"Decorator for asynchronous generators.", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2087912087912088}, {"context": "from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Tuple, ContextManager  # noqa: F401\n\n_DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n\n\nclass _UnsetMarker:\n    pass\n\n\n_UNSET = _UnsetMarker()\n\n\ndef filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20535714285714285}, {"context": "\n\n@typing.overload\ndef future_add_done_callback(\n    future: \"futures.Future[_T]\", callback: Callable[[\"futures.Future[_T]\"], None]\n) -> None:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef future_add_done_callback(\n    future: \"Future[_T]\", callback: Callable[[\"Future[_T]\"], None]\n) -> None:\n    pass\n\n\ndef future_add_done_callback(  # noqa: F811\n    future: \"Union[futures.Future[_T], Future[_T]]\", callback: Callable[..., None]\n) -> None:\n    \"\"\"Arrange to call ``callback`` when ``future`` is complete.", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20430107526881722}, {"context": "    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def is_closing(self) -> bool:\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    async def accept_connection(self, handler: WebSocketHandler) -> None:\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def write_message(\n        self, message: Union[str, bytes], binary: bool = False\n    ) -> \"Future[None]\":\n        raise NotImplementedError()\n\n    @property\n    @abc.abstractmethod\n    def selected_subprotocol(self) -> Optional[str]:", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20408163265306123}, {"context": "    group: Optional[str] = None,\n    callback: Optional[Callable[[Any], None]] = None,\n) -> None:\n    \"\"\"Defines an option in the global namespace.\n\n    See `OptionParser.define`.\n    \"\"\"\n    return options.define(\n        name,\n        default=default,\n        type=type,\n        help=help,\n        metavar=metavar,\n        multiple=multiple,\n        group=group,\n        callback=callback,\n    )\n\n\ndef parse_command_line(", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 690, "start_line_no": 680, "end_line_no": 700, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19791666666666666}, {"context": "    Any,\n    Union,\n    Optional,\n    Awaitable,\n    Tuple,\n    List,\n    Callable,\n    Iterable,\n    Generator,\n    Type,\n    cast,\n    overload,\n)\nfrom types import TracebackType\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Set  # noqa: F401\n\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1875}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# simple_httpclient.py\n# --------------------------------------------------\n# \n#     def _connection_class(self) -> type:\n#         return _HTTPConnection\n# \n#     def _handle_request(\n#         self,\n#         request: HTTPRequest,\n#         release_callback: Callable[[], None],\n#         final_callback: Callable[[HTTPResponse], None],\n#     ) -> None:\n#         self._connection_class()(\n#             self,\n#             request,\n#             release_callback,\n#             final_callback,\n#             self.max_buffer_size,\n#             self.tcp_client,\n#             self.max_header_size,\n#             self.max_body_size,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     which reference a global instance.\n#     \"\"\"\n# \n#     def __init__(self) -> None:\n#         # we have to use self.__dict__ because we override setattr.\n#         self.__dict__[\"_options\"] = {}\n#         self.__dict__[\"_parse_callbacks\"] = []\n#         self.define(\n#             \"help\",\n#             type=bool,\n#             help=\"show this help information\",\n#             callback=self._help_callback,\n#         )\n# \n#     def _normalize_name(self, name: str) -> str:\n#         return name.replace(\"_\", \"-\")\n# \n#     def __getattr__(self, name: str) -> Any:\n#         name = self._normalize_name(name)\n#         if isinstance(self._options.get(name), _Option):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def get_status(self) -> int:\n#         \"\"\"Returns the status code for our response.\"\"\"\n#         return self._status_code\n# \n#     def set_header(self, name: str, value: _HeaderTypes) -> None:\n#         \"\"\"Sets the given response header name and value.\n# \n#         All header values are converted to strings (`datetime` objects\n#         are formatted according to the HTTP specification for the\n#         ``Date`` header).\n# \n#         \"\"\"\n#         self._headers[name] = self._convert_header_value(value)\n# \n#     def add_header(self, name: str, value: _HeaderTypes) -> None:\n#         \"\"\"Adds the given response header and value.\n# \n#         Unlike `set_header`, `add_header` may be called multiple times\n#         to return multiple values for the same header.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# \n# \n# @typing.overload\n# def utf8(value: bytes) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def utf8(value: str) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def utf8(value: None) -> None:\n#     pass\n# \n# \n# def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"Converts a string argument to a byte string.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         ``Date`` header).\n# \n#         \"\"\"\n#         self._headers[name] = self._convert_header_value(value)\n# \n#     def add_header(self, name: str, value: _HeaderTypes) -> None:\n#         \"\"\"Adds the given response header and value.\n# \n#         Unlike `set_header`, `add_header` may be called multiple times\n#         to return multiple values for the same header.\n#         \"\"\"\n#         self._headers.add(name, self._convert_header_value(value))\n# \n#     def clear_header(self, name: str) -> None:\n#         \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n# \n#         Note that this method does not apply to multi-valued headers\n#         set by `add_header`.\n#         \"\"\"\n#         if name in self._headers:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# _TO_UNICODE_TYPES = (unicode_type, type(None))\n# \n# \n# @typing.overload\n# def to_unicode(value: str) -> str:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def to_unicode(value: bytes) -> str:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def to_unicode(value: None) -> None:\n#     pass\n# \n# \n# def to_unicode(value: Union[None, str, bytes]) -> Optional[str]:  # noqa: F811\n#     \"\"\"Converts a string argument to a unicode string.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n#             self.regex.pattern,\n#             self.handler_class,\n#             self.kwargs,\n#             self.name,\n#         )\n# \n# \n# @overload\n# def _unquote_or_none(s: str) -> bytes:\n#     pass\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# queues.py\n# --------------------------------------------------\n#         q.put((10, 'low-priority item'))\n# \n#         print(q.get_nowait())\n#         print(q.get_nowait())\n#         print(q.get_nowait())\n# \n#     .. testoutput::\n# \n#         (0, 'high-priority item')\n#         (1, 'medium-priority item')\n#         (10, 'low-priority item')\n#     \"\"\"\n# \n#     def _init(self) -> None:\n#         self._queue = []\n# \n#     def _put(self, item: _T) -> None:\n#         heapq.heappush(self._queue, item)\n# \n#     def _get(self) -> _T:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# def import_object(name: str) -> Any:\n#     \"\"\"Imports an object by name.\n# \n#     ``import_object('x')`` is equivalent to ``import x``.\n#     ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n# \n#     >>> import tornado.escape\n#     >>> import_object('tornado.escape') is tornado.escape\n#     True\n#     >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n#     True\n#     >>> import_object('tornado') is tornado\n#     True\n#     >>> import_object('tornado.missing_module')\n#     Traceback (most recent call last):\n#         ...\n#     ImportError: No module named missing_module\n#     \"\"\"\n#     if name.count(\".\") == 0:\n#         return __import__(name)\n# --------------------------------------------------\n\ndef _normalize_header(name: str) -> str:\n    \"\"\"Map a header name to Http-Header-Case.\n\n    >>> _normalize_header(\"coNtent-TYPE\")\n    'Content-Type'\n    \"\"\"\n", "metadata": {"task_id": "tornado/id30", "ground_truth": "def _normalize_header(name: str) -> str:\n    \"\"\"Map a header name to Http-Header-Case.\n\n    >>> _normalize_header(\"coNtent-TYPE\")\n    'Content-Type'\n    \"\"\"\n    return \"-\".join([w.capitalize() for w in name.split(\"-\")])", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "_normalize_header", "lineno": 0, "context_start_lineno": 0, "_id": 30, "query_window": {"context": "def _normalize_header(name: str) -> str:\n    \"\"\"Map a header to HTTP-Header-Case.\n    >>> _normalize_header('coNtentTYPE')\n    'Content-Type'\n    >>> _normalize_header('x-custom-header')\n    'X-Custom-Header'\n    >>> _normalize_header('content-type')\n    'Content-Type'\n    >>> _normalize_header('Authorization')\n    'Authorization'", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "def _normalize_header(name: str) -> str:\n    \"\"\"Map a header to HTTP-Header-Case.\n\n    >>> _normalize_header('coNtentTYPE')\n    'Content-Type'\n    >>> _normalize_header('x-custom-header')\n    'X-Custom-Header'\n    >>> _normalize_header('content-type')\n    'Content-Type'\n    >>> _normalize_header('Authorization')\n    'Authorization'\n    \"\"\"\n    return '-'.join(part.capitalize() for part in name.lower().split('-'))\n\n# Example usage\nprint(_normalize_header(\"coNtentTYPE\"))  # Output: 'Content-Type'\nprint(_normalize_header(\"x-custom-header\"))  # Output: 'X-Custom-Header'\nprint(_normalize_header(\"content-type\"))  # Output: 'Content-Type'\nprint(_normalize_header(\"Authorization\"))  # Output: 'Authorization'", "task_id": "tornado/id30", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17346938775510204}, {"context": "        q.put((10, 'low-priority item'))\n\n        print(q.get_nowait())\n        print(q.get_nowait())\n        print(q.get_nowait())\n\n    .. testoutput::\n\n        (0, 'high-priority item')\n        (1, 'medium-priority item')\n        (10, 'low-priority item')\n    \"\"\"\n\n    def _init(self) -> None:\n        self._queue = []\n\n    def _put(self, item: _T) -> None:\n        heapq.heappush(self._queue, item)\n\n    def _get(self) -> _T:", "metadata": [{"fpath_tuple": ["tornado", "queues.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16666666666666666}, {"context": "            self.regex.pattern,\n            self.handler_class,\n            self.kwargs,\n            self.name,\n        )\n\n\n@overload\ndef _unquote_or_none(s: str) -> bytes:\n    pass\n\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16304347826086957}, {"context": "_TO_UNICODE_TYPES = (unicode_type, type(None))\n\n\n@typing.overload\ndef to_unicode(value: str) -> str:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef to_unicode(value: bytes) -> str:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef to_unicode(value: None) -> None:\n    pass\n\n\ndef to_unicode(value: Union[None, str, bytes]) -> Optional[str]:  # noqa: F811\n    \"\"\"Converts a string argument to a unicode string.", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16091954022988506}, {"context": "        ``Date`` header).\n\n        \"\"\"\n        self._headers[name] = self._convert_header_value(value)\n\n    def add_header(self, name: str, value: _HeaderTypes) -> None:\n        \"\"\"Adds the given response header and value.\n\n        Unlike `set_header`, `add_header` may be called multiple times\n        to return multiple values for the same header.\n        \"\"\"\n        self._headers.add(name, self._convert_header_value(value))\n\n    def clear_header(self, name: str) -> None:\n        \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n\n        Note that this method does not apply to multi-valued headers\n        set by `add_header`.\n        \"\"\"\n        if name in self._headers:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16071428571428573}, {"context": "\n\n@typing.overload\ndef utf8(value: bytes) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef utf8(value: str) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef utf8(value: None) -> None:\n    pass\n\n\ndef utf8(value: Union[None, str, bytes]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"Converts a string argument to a byte string.\n", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15789473684210525}, {"context": "\n    def get_status(self) -> int:\n        \"\"\"Returns the status code for our response.\"\"\"\n        return self._status_code\n\n    def set_header(self, name: str, value: _HeaderTypes) -> None:\n        \"\"\"Sets the given response header name and value.\n\n        All header values are converted to strings (`datetime` objects\n        are formatted according to the HTTP specification for the\n        ``Date`` header).\n\n        \"\"\"\n        self._headers[name] = self._convert_header_value(value)\n\n    def add_header(self, name: str, value: _HeaderTypes) -> None:\n        \"\"\"Adds the given response header and value.\n\n        Unlike `set_header`, `add_header` may be called multiple times\n        to return multiple values for the same header.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15315315315315314}, {"context": "    which reference a global instance.\n    \"\"\"\n\n    def __init__(self) -> None:\n        # we have to use self.__dict__ because we override setattr.\n        self.__dict__[\"_options\"] = {}\n        self.__dict__[\"_parse_callbacks\"] = []\n        self.define(\n            \"help\",\n            type=bool,\n            help=\"show this help information\",\n            callback=self._help_callback,\n        )\n\n    def _normalize_name(self, name: str) -> str:\n        return name.replace(\"_\", \"-\")\n\n    def __getattr__(self, name: str) -> Any:\n        name = self._normalize_name(name)\n        if isinstance(self._options.get(name), _Option):", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.14953271028037382}, {"context": "\n    def _connection_class(self) -> type:\n        return _HTTPConnection\n\n    def _handle_request(\n        self,\n        request: HTTPRequest,\n        release_callback: Callable[[], None],\n        final_callback: Callable[[HTTPResponse], None],\n    ) -> None:\n        self._connection_class()(\n            self,\n            request,\n            release_callback,\n            final_callback,\n            self.max_buffer_size,\n            self.tcp_client,\n            self.max_header_size,\n            self.max_body_size,\n        )", "metadata": [{"fpath_tuple": ["tornado", "simple_httpclient.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.14457831325301204}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         type=type,\n#         help=help,\n#         metavar=metavar,\n#         multiple=multiple,\n#         group=group,\n#         callback=callback,\n#     )\n# \n# \n# def parse_command_line(\n#     args: Optional[List[str]] = None, final: bool = True\n# ) -> List[str]:\n#     \"\"\"Parses global options from the command line.\n# \n#     See `OptionParser.parse_command_line`.\n#     \"\"\"\n#     return options.parse_command_line(args, final=final)\n# \n# \n# def parse_config_file(path: str, final: bool = True) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n# from tornado.web import RequestHandler\n# \n# from typing import List, Any, Dict, cast, Iterable, Union, Optional\n# \n# \n# class AuthError(Exception):\n#     pass\n# \n# \n# class OpenIdMixin(object):\n#     \"\"\"Abstract implementation of OpenID and Attribute Exchange.\n# \n#     Class attributes:\n# \n#     * ``_OPENID_ENDPOINT``: the identity provider's URI.\n#     \"\"\"\n# \n#     def authenticate_redirect(\n#         self,\n#         callback_uri: Optional[str] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n# import hashlib\n# import hmac\n# import time\n# import urllib.parse\n# import uuid\n# \n# from tornado import httpclient\n# from tornado import escape\n# from tornado.httputil import url_concat\n# from tornado.util import unicode_type\n# from tornado.web import RequestHandler\n# \n# from typing import List, Any, Dict, cast, Iterable, Union, Optional\n# \n# \n# class AuthError(Exception):\n#     pass\n# \n# \n# class OpenIdMixin(object):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n#         client_id: Optional[str] = None,\n#         client_secret: Optional[str] = None,\n#         code: Optional[str] = None,\n#         extra_params: Optional[Dict[str, Any]] = None,\n#     ) -> str:\n#         url = self._OAUTH_ACCESS_TOKEN_URL  # type: ignore\n#         args = {}  # type: Dict[str, str]\n#         if redirect_uri is not None:\n#             args[\"redirect_uri\"] = redirect_uri\n#         if code is not None:\n#             args[\"code\"] = code\n#         if client_id is not None:\n#             args[\"client_id\"] = client_id\n#         if client_secret is not None:\n#             args[\"client_secret\"] = client_secret\n#         if extra_params:\n#             args.update(extra_params)\n#         return url_concat(url, args)\n# \n#     async def oauth2_request(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import (\n#     utf8,\n#     xhtml_escape,\n#     xhtml_unescape,\n#     url_escape,\n#     url_unescape,\n#     to_unicode,\n#     json_decode,\n#     json_encode,\n#     squeeze,\n#     recursive_unicode,\n# )\n# from tornado.util import unicode_type\n# \n# from typing import List, Tuple, Union, Dict, Any  # noqa: F401\n# \n# linkify_tests = [\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# \n#     mypy insists on type annotations for dict literals, so this lets us avoid\n#     the verbose types throughout this test.\n#     \"\"\"\n#     return {}, {}\n# \n# \n# class TestUrlConcat(unittest.TestCase):\n#     def test_url_concat_no_query_params(self):\n#         url = url_concat(\"https://localhost/path\", [(\"y\", \"y\"), (\"z\", \"z\")])\n#         self.assertEqual(url, \"https://localhost/path?y=y&z=z\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n#         return urllib.parse.unquote_to_bytes(value)\n#     else:\n#         unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n#         return unquote(to_basestring(value), encoding=encoding)\n# \n# \n# def parse_qs_bytes(\n#     qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n# ) -> Dict[str, List[bytes]]:\n#     \"\"\"Parses a query string like urlparse.parse_qs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#     HTTPFile,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado.log import gen_log\n# from tornado.testing import ExpectLog\n# \n# import copy\n# import datetime\n# import logging\n# import pickle\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n# --------------------------------------------------\n\ndef url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n", "metadata": {"task_id": "tornado/id31", "ground_truth": "def url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n    if args is None:\n        return url\n    parsed_url = urlparse(url)\n    if isinstance(args, dict):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args.items())\n    elif isinstance(args, list) or isinstance(args, tuple):\n        parsed_query = parse_qsl(parsed_url.query, keep_blank_values=True)\n        parsed_query.extend(args)\n    else:\n        err = \"'args' parameter should be dict, list or tuple. Not {0}\".format(\n            type(args)\n        )\n        raise TypeError(err)\n    final_query = urlencode(parsed_query)\n    url = urlunparse(\n        (\n            parsed_url[0],\n            parsed_url[1],\n            parsed_url[2],\n            parsed_url[3],\n            final_query,\n            parsed_url[5],\n        )\n    )\n    return url", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "url_concat", "lineno": 0, "context_start_lineno": 0, "_id": 31, "query_window": {"context": "from typing import Union, Dict, List, Tuple\nfrom urllib.parse import urlencode, urlparse, parse_qs, urlunparse\ndef url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Union, Dict, List, Tuple\nfrom urllib.parse import urlencode, urlparse, parse_qs, urlunparse\n\ndef url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key).\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n    # Parse the original URL\n    parsed_url = urlparse(url)\n    \n    # Start with existing query parameters\n    query_params = parse_qs(parsed_url.query)\n    \n    # Process new arguments\n    if args:\n        if isinstance(args, dict):\n            for key, value in args.items():\n                query_params.setdefault(key, []).append(value)\n        elif isinstance(args, list):\n            for key, value in args:\n                query_params.setdefault(key, []).append(value)\n        elif isinstance(args, tuple):\n            for key, value in args:\n                query_params.setdefault(key, []).append(value)\n    \n    # Encode query parameters back to a query string\n    new_query = urlencode({k: v if len(v) == 1 else v for k, v in query_params.items()}, doseq=True)\n\n    # Construct the new URL\n    new_url = urlunparse(parsed_url._replace(query=new_query))\n    \n    return new_url", "task_id": "tornado/id31", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.26373626373626374}, {"context": "    HTTPFile,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado.log import gen_log\nfrom tornado.testing import ExpectLog\n\nimport copy\nimport datetime\nimport logging\nimport pickle\nimport time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2549019607843137}, {"context": "    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)\n\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23134328358208955}, {"context": "import time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n\n    mypy insists on type annotations for dict literals, so this lets us avoid\n    the verbose types throughout this test.\n    \"\"\"\n    return {}, {}\n\n\nclass TestUrlConcat(unittest.TestCase):\n    def test_url_concat_no_query_params(self):\n        url = url_concat(\"https://localhost/path\", [(\"y\", \"y\"), (\"z\", \"z\")])\n        self.assertEqual(url, \"https://localhost/path?y=y&z=z\")", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22535211267605634}, {"context": "import unittest\n\nimport tornado.escape\nfrom tornado.escape import (\n    utf8,\n    xhtml_escape,\n    xhtml_unescape,\n    url_escape,\n    url_unescape,\n    to_unicode,\n    json_decode,\n    json_encode,\n    squeeze,\n    recursive_unicode,\n)\nfrom tornado.util import unicode_type\n\nfrom typing import List, Tuple, Union, Dict, Any  # noqa: F401\n\nlinkify_tests = [", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2247191011235955}, {"context": "        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n        code: Optional[str] = None,\n        extra_params: Optional[Dict[str, Any]] = None,\n    ) -> str:\n        url = self._OAUTH_ACCESS_TOKEN_URL  # type: ignore\n        args = {}  # type: Dict[str, str]\n        if redirect_uri is not None:\n            args[\"redirect_uri\"] = redirect_uri\n        if code is not None:\n            args[\"code\"] = code\n        if client_id is not None:\n            args[\"client_id\"] = client_id\n        if client_secret is not None:\n            args[\"client_secret\"] = client_secret\n        if extra_params:\n            args.update(extra_params)\n        return url_concat(url, args)\n\n    async def oauth2_request(", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 600, "start_line_no": 590, "end_line_no": 610, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21359223300970873}, {"context": "import hashlib\nimport hmac\nimport time\nimport urllib.parse\nimport uuid\n\nfrom tornado import httpclient\nfrom tornado import escape\nfrom tornado.httputil import url_concat\nfrom tornado.util import unicode_type\nfrom tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional\n\n\nclass AuthError(Exception):\n    pass\n\n\nclass OpenIdMixin(object):", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2127659574468085}, {"context": "from tornado.web import RequestHandler\n\nfrom typing import List, Any, Dict, cast, Iterable, Union, Optional\n\n\nclass AuthError(Exception):\n    pass\n\n\nclass OpenIdMixin(object):\n    \"\"\"Abstract implementation of OpenID and Attribute Exchange.\n\n    Class attributes:\n\n    * ``_OPENID_ENDPOINT``: the identity provider's URI.\n    \"\"\"\n\n    def authenticate_redirect(\n        self,\n        callback_uri: Optional[str] = None,", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20754716981132076}, {"context": "        type=type,\n        help=help,\n        metavar=metavar,\n        multiple=multiple,\n        group=group,\n        callback=callback,\n    )\n\n\ndef parse_command_line(\n    args: Optional[List[str]] = None, final: bool = True\n) -> List[str]:\n    \"\"\"Parses global options from the command line.\n\n    See `OptionParser.parse_command_line`.\n    \"\"\"\n    return options.parse_command_line(args, final=final)\n\n\ndef parse_config_file(path: str, final: bool = True) -> None:", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19607843137254902}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#     HTTPFile,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado.log import gen_log\n# from tornado.testing import ExpectLog\n# \n# import copy\n# import datetime\n# import logging\n# import pickle\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker],\n#         source: Dict[str, List[bytes]],\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         args = self._get_arguments(name, source, strip=strip)\n#         if not args:\n#             if isinstance(default, _ArgDefaultMarker):\n#                 raise MissingArgumentError(name)\n#             return default\n#         return args[-1]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         return self._raw_xsrf_token\n# \n#     def _decode_xsrf_token(\n#         self, cookie: str\n#     ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n#         \"\"\"Convert a cookie string into a the tuple form returned by\n#         _get_raw_xsrf_token.\n#         \"\"\"\n# \n#         try:\n#             m = _signed_value_version_re.match(utf8(cookie))\n# \n#             if m:\n#                 version = int(m.group(1))\n#                 if version == 2:\n#                     _, mask_str, masked_token, timestamp_str = cookie.split(\"|\")\n# \n#                     mask = binascii.a2b_hex(utf8(mask_str))\n#                     token = _websocket_mask(mask, binascii.a2b_hex(utf8(masked_token)))\n#                     timestamp = int(timestamp_str)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#             Tuple[\n#                 \"Optional[Type[BaseException]]\",\n#                 Optional[BaseException],\n#                 Optional[TracebackType],\n#             ],\n#         ] = False,\n#     ) -> None:\n#         \"\"\"Close this stream.\n# \n#         If ``exc_info`` is true, set the ``error`` attribute to the current\n#         exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n#         use that instead of `sys.exc_info`).\n#         \"\"\"\n#         if not self.closed():\n#             if exc_info:\n#                 if isinstance(exc_info, tuple):\n#                     self.error = exc_info[1]\n#                 elif isinstance(exc_info, BaseException):\n#                     self.error = exc_info\n#                 else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#                 version, token, timestamp = self._decode_xsrf_token(cookie)\n#             else:\n#                 version, token, timestamp = None, None, None\n#             if token is None:\n#                 version = None\n#                 token = os.urandom(16)\n#                 timestamp = time.time()\n#             assert token is not None\n#             assert timestamp is not None\n#             self._raw_xsrf_token = (version, token, timestamp)\n#         return self._raw_xsrf_token\n# \n#     def _decode_xsrf_token(\n#         self, cookie: str\n#     ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n#         \"\"\"Convert a cookie string into a the tuple form returned by\n#         _get_raw_xsrf_token.\n#         \"\"\"\n# \n#         try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n#         return urllib.parse.unquote_to_bytes(value)\n#     else:\n#         unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n#         return unquote(to_basestring(value), encoding=encoding)\n# \n# \n# def parse_qs_bytes(\n#     qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n# ) -> Dict[str, List[bytes]]:\n#     \"\"\"Parses a query string like urlparse.parse_qs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n#         converted_args = []\n#         for a in args:\n#             if not isinstance(a, (unicode_type, bytes)):\n#                 a = str(a)\n#             converted_args.append(url_escape(utf8(a), plus=False))\n#         return self._path % tuple(converted_args)\n# \n#     def _find_groups(self) -> Tuple[Optional[str], Optional[int]]:\n#         \"\"\"Returns a tuple (reverse string, group count) for a url.\n# \n#         For example: Given the url pattern /([0-9]{4})/([a-z-]+)/, this method\n#         would return ('/%s/%s/', 2).\n#         \"\"\"\n#         pattern = self.regex.pattern\n#         if pattern.startswith(\"^\"):\n#             pattern = pattern[1:]\n#         if pattern.endswith(\"$\"):\n#             pattern = pattern[:-1]\n# \n#         if self.regex.groups != pattern.count(\"(\"):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         ``Date`` header).\n# \n#         \"\"\"\n#         self._headers[name] = self._convert_header_value(value)\n# \n#     def add_header(self, name: str, value: _HeaderTypes) -> None:\n#         \"\"\"Adds the given response header and value.\n# \n#         Unlike `set_header`, `add_header` may be called multiple times\n#         to return multiple values for the same header.\n#         \"\"\"\n#         self._headers.add(name, self._convert_header_value(value))\n# \n#     def clear_header(self, name: str) -> None:\n#         \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n# \n#         Note that this method does not apply to multi-valued headers\n#         set by `add_header`.\n#         \"\"\"\n#         if name in self._headers:\n# --------------------------------------------------\n\ndef _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n", "metadata": {"task_id": "tornado/id32", "ground_truth": "def _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n    unit, _, value = range_header.partition(\"=\")\n    unit, value = unit.strip(), value.strip()\n    if unit != \"bytes\":\n        return None\n    start_b, _, end_b = value.partition(\"-\")\n    try:\n        start = _int_or_none(start_b)\n        end = _int_or_none(end_b)\n    except ValueError:\n        return None\n    if end is not None:\n        if start is None:\n            if end != 0:\n                start = -end\n                end = None\n        else:\n            end += 1\n    return (start, end)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "_parse_request_range", "lineno": 0, "context_start_lineno": 0, "_id": 32, "query_window": {"context": "from typing import Optional, Tuple\ndef _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Optional, Tuple\n\ndef _parse_request_range(\n    range_header: str,\n) -> Optional[Tuple[Optional[int], Optional[int]]]:\n    \"\"\"Parses a Range header.\n\n    Returns either ``None`` or tuple ``(start, end)``.\n    Note that while the HTTP headers use inclusive byte positions,\n    this method returns indexes suitable for use in slices.\n\n    >>> start, end = _parse_request_range(\"bytes=1-2\")\n    >>> start, end\n    (1, 3)\n    >>> [0, 1, 2, 3, 4][start:end]\n    [1, 2]\n    >>> _parse_request_range(\"bytes=6-\")\n    (6, None)\n    >>> _parse_request_range(\"bytes=-6\")\n    (-6, None)\n    >>> _parse_request_range(\"bytes=-0\")\n    (None, 0)\n    >>> _parse_request_range(\"bytes=\")\n    (None, None)\n    >>> _parse_request_range(\"foo=42\")\n    >>> _parse_request_range(\"bytes=1-2,6-10\")\n\n    Note: only supports one range (ex, ``bytes=1-2,6-10`` is not allowed).\n\n    See [0] for the details of the range header.\n\n    [0]: http://greenbytes.de/tech/webdav/draft-ietf-httpbis-p5-range-latest.html#byte.ranges\n    \"\"\"\n    if not range_header.startswith(\"bytes=\"):\n        return None  # Not a bytes range request\n\n    try:\n        # Get the portion after \"bytes=\"\n        range_part = range_header[len(\"bytes=\"):]\n        if ',' in range_part:\n            # Only supports one range\n            return None\n        \n        # Split the part into start and end\n        if '-' in range_part:\n            start, end = range_part.split('-', 1)\n            start = int(start) if start else None\n            end = int(end) + 1 if end else None  # Inclusive to exclusive\n        else:\n            return None\n        \n        # Convert '-' to None appropriately for slices\n        if start is not None and start < 0:\n            end = None if end is None else max(end, 0)\n        return (start, end)\n    \n    except ValueError:\n        return None  # If conversion fails, return None", "task_id": "tornado/id32", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        ``Date`` header).\n\n        \"\"\"\n        self._headers[name] = self._convert_header_value(value)\n\n    def add_header(self, name: str, value: _HeaderTypes) -> None:\n        \"\"\"Adds the given response header and value.\n\n        Unlike `set_header`, `add_header` may be called multiple times\n        to return multiple values for the same header.\n        \"\"\"\n        self._headers.add(name, self._convert_header_value(value))\n\n    def clear_header(self, name: str) -> None:\n        \"\"\"Clears an outgoing header, undoing a previous `set_header` call.\n\n        Note that this method does not apply to multi-valued headers\n        set by `add_header`.\n        \"\"\"\n        if name in self._headers:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2196969696969697}, {"context": "        converted_args = []\n        for a in args:\n            if not isinstance(a, (unicode_type, bytes)):\n                a = str(a)\n            converted_args.append(url_escape(utf8(a), plus=False))\n        return self._path % tuple(converted_args)\n\n    def _find_groups(self) -> Tuple[Optional[str], Optional[int]]:\n        \"\"\"Returns a tuple (reverse string, group count) for a url.\n\n        For example: Given the url pattern /([0-9]{4})/([a-z-]+)/, this method\n        would return ('/%s/%s/', 2).\n        \"\"\"\n        pattern = self.regex.pattern\n        if pattern.startswith(\"^\"):\n            pattern = pattern[1:]\n        if pattern.endswith(\"$\"):\n            pattern = pattern[:-1]\n\n        if self.regex.groups != pattern.count(\"(\"):", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21019108280254778}, {"context": "    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)\n\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20915032679738563}, {"context": "                version, token, timestamp = self._decode_xsrf_token(cookie)\n            else:\n                version, token, timestamp = None, None, None\n            if token is None:\n                version = None\n                token = os.urandom(16)\n                timestamp = time.time()\n            assert token is not None\n            assert timestamp is not None\n            self._raw_xsrf_token = (version, token, timestamp)\n        return self._raw_xsrf_token\n\n    def _decode_xsrf_token(\n        self, cookie: str\n    ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n\n        try:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1450, "start_line_no": 1440, "end_line_no": 1460, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20491803278688525}, {"context": "            Tuple[\n                \"Optional[Type[BaseException]]\",\n                Optional[BaseException],\n                Optional[TracebackType],\n            ],\n        ] = False,\n    ) -> None:\n        \"\"\"Close this stream.\n\n        If ``exc_info`` is true, set the ``error`` attribute to the current\n        exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n        use that instead of `sys.exc_info`).\n        \"\"\"\n        if not self.closed():\n            if exc_info:\n                if isinstance(exc_info, tuple):\n                    self.error = exc_info[1]\n                elif isinstance(exc_info, BaseException):\n                    self.error = exc_info\n                else:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 580, "start_line_no": 570, "end_line_no": 590, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.203125}, {"context": "        return self._raw_xsrf_token\n\n    def _decode_xsrf_token(\n        self, cookie: str\n    ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n\n        try:\n            m = _signed_value_version_re.match(utf8(cookie))\n\n            if m:\n                version = int(m.group(1))\n                if version == 2:\n                    _, mask_str, masked_token, timestamp_str = cookie.split(\"|\")\n\n                    mask = binascii.a2b_hex(utf8(mask_str))\n                    token = _websocket_mask(mask, binascii.a2b_hex(utf8(masked_token)))\n                    timestamp = int(timestamp_str)", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1460, "start_line_no": 1450, "end_line_no": 1470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20279720279720279}, {"context": "\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker],\n        source: Dict[str, List[bytes]],\n        strip: bool = True,\n    ) -> Optional[str]:\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if isinstance(default, _ArgDefaultMarker):\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20155038759689922}, {"context": "    HTTPFile,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado.log import gen_log\nfrom tornado.testing import ExpectLog\n\nimport copy\nimport datetime\nimport logging\nimport pickle\nimport time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1935483870967742}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# locale.py\n# --------------------------------------------------\n#     ) -> str:\n#         if plural_message is not None:\n#             assert count is not None\n#             if count != 1:\n#                 message = plural_message\n#                 message_dict = self.translations.get(\"plural\", {})\n#             else:\n#                 message_dict = self.translations.get(\"singular\", {})\n#         else:\n#             message_dict = self.translations.get(\"unknown\", {})\n#         return message_dict.get(message, message)\n# \n#     def pgettext(\n#         self,\n#         context: str,\n#         message: str,\n#         plural_message: Optional[str] = None,\n#         count: Optional[int] = None,\n#     ) -> str:\n#         if self.translations:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker],\n#         source: Dict[str, List[bytes]],\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         args = self._get_arguments(name, source, strip=strip)\n#         if not args:\n#             if isinstance(default, _ArgDefaultMarker):\n#                 raise MissingArgumentError(name)\n#             return default\n#         return args[-1]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# \n# \n# @typing.overload\n# def utf8(value: bytes) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def utf8(value: str) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def utf8(value: None) -> None:\n#     pass\n# \n# \n# def utf8(value: Union[None, str, bytes]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"Converts a string argument to a byte string.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n#         assert start >= 0, start\n#         pos = self.pos\n#         start += pos\n#         if end is None:\n#             index = self.text.find(needle, start)\n#         else:\n#             end += pos\n#             assert end >= start\n#             index = self.text.find(needle, start, end)\n#         if index != -1:\n#             index -= pos\n#         return index\n# \n#     def consume(self, count: Optional[int] = None) -> str:\n#         if count is None:\n#             count = len(self.text) - self.pos\n#         newpos = self.pos + count\n#         self.line += self.text.count(\"\\n\", self.pos, newpos)\n#         s = self.text[self.pos : newpos]\n#         self.pos = newpos\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#             # refuses to play audio if it gets an HTTP 206 in response to\n#             # ``Range: bytes=0-``.\n#             if size != (end or size) - (start or 0):\n#                 self.set_status(206)  # Partial Content\n#                 self.set_header(\n#                     \"Content-Range\", httputil._get_content_range(start, end, size)\n#                 )\n#         else:\n#             start = end = None\n# \n#         if start is not None and end is not None:\n#             content_length = end - start\n#         elif end is not None:\n#             content_length = end\n#         elif start is not None:\n#             content_length = size - start\n#         else:\n#             content_length = size\n#         self.set_header(\"Content-Length\", content_length)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# queues.py\n# --------------------------------------------------\n#         q = LifoQueue()\n#         q.put(3)\n#         q.put(2)\n#         q.put(1)\n# \n#         print(q.get_nowait())\n#         print(q.get_nowait())\n#         print(q.get_nowait())\n# \n#     .. testoutput::\n# \n#         1\n#         2\n#         3\n#     \"\"\"\n# \n#     def _init(self) -> None:\n#         self._queue = []\n# \n#     def _put(self, item: _T) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     value = utf8(value)\n#     version = _get_version(value)\n# \n#     if version < min_version:\n#         return None\n#     if version == 1:\n#         assert not isinstance(secret, dict)\n#         return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n#     elif version == 2:\n#         return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n#     else:\n#         return None\n# \n# \n# def _decode_signed_value_v1(\n#     secret: Union[str, bytes],\n#     name: str,\n#     value: bytes,\n#     max_age_days: float,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# \n# class _TemplateReader(object):\n#     def __init__(self, name: str, text: str, whitespace: str) -> None:\n#         self.name = name\n#         self.text = text\n#         self.whitespace = whitespace\n#         self.line = 1\n#         self.pos = 0\n# \n#     def find(self, needle: str, start: int = 0, end: Optional[int] = None) -> int:\n#         assert start >= 0, start\n#         pos = self.pos\n#         start += pos\n#         if end is None:\n#             index = self.text.find(needle, start)\n#         else:\n#             end += pos\n#             assert end >= start\n#             index = self.text.find(needle, start, end)\n#         if index != -1:\n# --------------------------------------------------\n\ndef _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n", "metadata": {"task_id": "tornado/id33", "ground_truth": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n    start = start or 0\n    end = (end or total) - 1\n    return \"bytes %s-%s/%s\" % (start, end, total)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "_get_content_range", "lineno": 0, "context_start_lineno": 0, "_id": 33, "query_window": {"context": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n    if start is None and end is None:", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n    if start is None and end is None:\n        # If both start and end are None, return range for full content\n        start = 0\n        end = total - 1\n    elif start is None:\n        # If start is None, we calculate start based on end\n        start = total - (end + 1)\n    elif end is None:\n        # If end is None, we assume it's the last byte in the range\n        end = total - 1\n\n    return f\"bytes {start}-{end}/{total}\"", "task_id": "tornado/id33", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\nclass _TemplateReader(object):\n    def __init__(self, name: str, text: str, whitespace: str) -> None:\n        self.name = name\n        self.text = text\n        self.whitespace = whitespace\n        self.line = 1\n        self.pos = 0\n\n    def find(self, needle: str, start: int = 0, end: Optional[int] = None) -> int:\n        assert start >= 0, start\n        pos = self.pos\n        start += pos\n        if end is None:\n            index = self.text.find(needle, start)\n        else:\n            end += pos\n            assert end >= start\n            index = self.text.find(needle, start, end)\n        if index != -1:", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 790, "start_line_no": 780, "end_line_no": 800, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23076923076923078}, {"context": "\n    value = utf8(value)\n    version = _get_version(value)\n\n    if version < min_version:\n        return None\n    if version == 1:\n        assert not isinstance(secret, dict)\n        return _decode_signed_value_v1(secret, name, value, max_age_days, clock)\n    elif version == 2:\n        return _decode_signed_value_v2(secret, name, value, max_age_days, clock)\n    else:\n        return None\n\n\ndef _decode_signed_value_v1(\n    secret: Union[str, bytes],\n    name: str,\n    value: bytes,\n    max_age_days: float,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3460, "start_line_no": 3450, "end_line_no": 3470, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22988505747126436}, {"context": "        q = LifoQueue()\n        q.put(3)\n        q.put(2)\n        q.put(1)\n\n        print(q.get_nowait())\n        print(q.get_nowait())\n        print(q.get_nowait())\n\n    .. testoutput::\n\n        1\n        2\n        3\n    \"\"\"\n\n    def _init(self) -> None:\n        self._queue = []\n\n    def _put(self, item: _T) -> None:", "metadata": [{"fpath_tuple": ["tornado", "queues.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22784810126582278}, {"context": "            # refuses to play audio if it gets an HTTP 206 in response to\n            # ``Range: bytes=0-``.\n            if size != (end or size) - (start or 0):\n                self.set_status(206)  # Partial Content\n                self.set_header(\n                    \"Content-Range\", httputil._get_content_range(start, end, size)\n                )\n        else:\n            start = end = None\n\n        if start is not None and end is not None:\n            content_length = end - start\n        elif end is not None:\n            content_length = end\n        elif start is not None:\n            content_length = size - start\n        else:\n            content_length = size\n        self.set_header(\"Content-Length\", content_length)\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2630, "start_line_no": 2620, "end_line_no": 2640, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21359223300970873}, {"context": "    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20652173913043478}, {"context": "        assert start >= 0, start\n        pos = self.pos\n        start += pos\n        if end is None:\n            index = self.text.find(needle, start)\n        else:\n            end += pos\n            assert end >= start\n            index = self.text.find(needle, start, end)\n        if index != -1:\n            index -= pos\n        return index\n\n    def consume(self, count: Optional[int] = None) -> str:\n        if count is None:\n            count = len(self.text) - self.pos\n        newpos = self.pos + count\n        self.line += self.text.count(\"\\n\", self.pos, newpos)\n        s = self.text[self.pos : newpos]\n        self.pos = newpos", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 800, "start_line_no": 790, "end_line_no": 810, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20454545454545456}, {"context": "\n\n@typing.overload\ndef utf8(value: bytes) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef utf8(value: str) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef utf8(value: None) -> None:\n    pass\n\n\ndef utf8(value: Union[None, str, bytes]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"Converts a string argument to a byte string.\n", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20253164556962025}, {"context": "\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker],\n        source: Dict[str, List[bytes]],\n        strip: bool = True,\n    ) -> Optional[str]:\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if isinstance(default, _ArgDefaultMarker):\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2018348623853211}, {"context": "    ) -> str:\n        if plural_message is not None:\n            assert count is not None\n            if count != 1:\n                message = plural_message\n                message_dict = self.translations.get(\"plural\", {})\n            else:\n                message_dict = self.translations.get(\"singular\", {})\n        else:\n            message_dict = self.translations.get(\"unknown\", {})\n        return message_dict.get(message, message)\n\n    def pgettext(\n        self,\n        context: str,\n        message: str,\n        plural_message: Optional[str] = None,\n        count: Optional[int] = None,\n    ) -> str:\n        if self.translations:", "metadata": [{"fpath_tuple": ["tornado", "locale.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# queues.py\n# --------------------------------------------------\n# \n# _T = TypeVar(\"_T\")\n# \n# __all__ = [\"Queue\", \"PriorityQueue\", \"LifoQueue\", \"QueueFull\", \"QueueEmpty\"]\n# \n# \n# class QueueEmpty(Exception):\n#     \"\"\"Raised by `.Queue.get_nowait` when the queue has no items.\"\"\"\n# \n#     pass\n# \n# \n# class QueueFull(Exception):\n#     \"\"\"Raised by `.Queue.put_nowait` when a queue is at its maximum size.\"\"\"\n# \n#     pass\n# \n# \n# def _set_timeout(\n#     future: Future, timeout: Union[None, float, datetime.timedelta]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#                 version, token, timestamp = self._decode_xsrf_token(cookie)\n#             else:\n#                 version, token, timestamp = None, None, None\n#             if token is None:\n#                 version = None\n#                 token = os.urandom(16)\n#                 timestamp = time.time()\n#             assert token is not None\n#             assert timestamp is not None\n#             self._raw_xsrf_token = (version, token, timestamp)\n#         return self._raw_xsrf_token\n# \n#     def _decode_xsrf_token(\n#         self, cookie: str\n#     ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n#         \"\"\"Convert a cookie string into a the tuple form returned by\n#         _get_raw_xsrf_token.\n#         \"\"\"\n# \n#         try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         expires may be a numeric timestamp as returned by `time.time`,\n#         a time tuple as returned by `time.gmtime`, or a\n#         `datetime.datetime` object.\n# \n#         Additional keyword arguments are set on the cookies.Morsel\n#         directly.\n#         See https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel\n#         for available attributes.\n#         \"\"\"\n#         # The cookie library only accepts type str, in both python 2 and 3\n#         name = escape.native_str(name)\n#         value = escape.native_str(value)\n#         if re.search(r\"[\\x00-\\x20]\", name + value):\n#             # Don't let us accidentally inject bad stuff\n#             raise ValueError(\"Invalid cookie %r: %r\" % (name, value))\n#         if not hasattr(self, \"_new_cookie\"):\n#             self._new_cookie = (\n#                 http.cookies.SimpleCookie()\n#             )  # type: http.cookies.SimpleCookie\n#         if name in self._new_cookie:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# queues.py\n# --------------------------------------------------\n#             raise QueueFull\n#         else:\n#             self.__put_internal(item)\n# \n#     def get(\n#         self, timeout: Optional[Union[float, datetime.timedelta]] = None\n#     ) -> Awaitable[_T]:\n#         \"\"\"Remove and return an item from the queue.\n# \n#         Returns an awaitable which resolves once an item is available, or raises\n#         `tornado.util.TimeoutError` after a timeout.\n# \n#         ``timeout`` may be a number denoting a time (on the same\n#         scale as `tornado.ioloop.IOLoop.time`, normally `time.time`), or a\n#         `datetime.timedelta` object for a deadline relative to the\n#         current time.\n# \n#         .. note::\n# \n#            The ``timeout`` argument of this method differs from that\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n#         to ``kwargs`` and None will be returned as ``old_value``.\n#         \"\"\"\n#         if self.arg_pos is not None and len(args) > self.arg_pos:\n#             # The arg to replace is passed positionally\n#             old_value = args[self.arg_pos]\n#             args = list(args)  # *args is normally a tuple\n#             args[self.arg_pos] = new_value\n#         else:\n#             # The arg to replace is either omitted or passed by keyword.\n#             old_value = kwargs.get(self.name)\n#             kwargs[self.name] = new_value\n#         return old_value, args, kwargs\n# \n# \n# def timedelta_to_seconds(td):\n#     # type: (datetime.timedelta) -> float\n#     \"\"\"Equivalent to ``td.total_seconds()`` (introduced in Python 2.7).\"\"\"\n#     return td.total_seconds()\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# \n#     def time(self) -> float:\n#         \"\"\"Returns the current time according to the `IOLoop`'s clock.\n# \n#         The return value is a floating-point number relative to an\n#         unspecified time in the past.\n# \n#         Historically, the IOLoop could be customized to use e.g.\n#         `time.monotonic` instead of `time.time`, but this is not\n#         currently supported and so this method is equivalent to\n#         `time.time`.\n# \n#         \"\"\"\n#         return time.time()\n# \n#     def add_timeout(\n#         self,\n#         deadline: Union[float, datetime.timedelta],\n#         callback: Callable[..., None],\n#         *args: Any,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         `time.time`.\n# \n#         \"\"\"\n#         return time.time()\n# \n#     def add_timeout(\n#         self,\n#         deadline: Union[float, datetime.timedelta],\n#         callback: Callable[..., None],\n#         *args: Any,\n#         **kwargs: Any\n#     ) -> object:\n#         \"\"\"Runs the ``callback`` at the time ``deadline`` from the I/O loop.\n# \n#         Returns an opaque handle that may be passed to\n#         `remove_timeout` to cancel.\n# \n#         ``deadline`` may be a number denoting a time (on the same\n#         scale as `IOLoop.time`, normally `time.time`), or a\n#         `datetime.timedelta` object for a deadline relative to the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         expires: Optional[Union[float, Tuple, datetime.datetime]] = None,\n#         path: str = \"/\",\n#         expires_days: Optional[float] = None,\n#         **kwargs: Any\n#     ) -> None:\n#         \"\"\"Sets an outgoing cookie name/value with the given options.\n# \n#         Newly-set cookies are not immediately visible via `get_cookie`;\n#         they are not present until the next request.\n# \n#         expires may be a numeric timestamp as returned by `time.time`,\n#         a time tuple as returned by `time.gmtime`, or a\n#         `datetime.datetime` object.\n# \n#         Additional keyword arguments are set on the cookies.Morsel\n#         directly.\n#         See https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel\n#         for available attributes.\n#         \"\"\"\n#         # The cookie library only accepts type str, in both python 2 and 3\n# --------------------------------------------------\n\ndef format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n", "metadata": {"task_id": "tornado/id34", "ground_truth": "def format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n    if isinstance(ts, (int, float)):\n        time_num = ts\n    elif isinstance(ts, (tuple, time.struct_time)):\n        time_num = calendar.timegm(ts)\n    elif isinstance(ts, datetime.datetime):\n        time_num = calendar.timegm(ts.utctimetuple())\n    else:\n        raise TypeError(\"unknown timestamp type: %r\" % ts)\n    return email.utils.formatdate(time_num, usegmt=True)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "format_timestamp", "lineno": 0, "context_start_lineno": 0, "_id": 34, "query_window": {"context": "import time\nimport datetime\nfrom typing import Union\ndef format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "import time\nimport datetime\nfrom typing import Union\n\ndef format_timestamp(\n    ts: Union[int, float, tuple, time.struct_time, datetime.datetime]\n) -> str:\n    \"\"\"Formats a timestamp in the format used by HTTP.\n\n    The argument may be a numeric timestamp as returned by `time.time`,\n    a time tuple as returned by `time.gmtime`, or a `datetime.datetime`\n    object.\n\n    >>> format_timestamp(1359312200)\n    'Sun, 27 Jan 2013 18:43:20 GMT'\n    \"\"\"\n    if isinstance(ts, (int, float)):\n        dt = datetime.datetime.utcfromtimestamp(ts)\n    elif isinstance(ts, tuple):\n        dt = datetime.datetime(*ts[:6])  # Construct datetime from tuple\n    elif isinstance(ts, time.struct_time):\n        dt = datetime.datetime(*ts[:6])  # Construct datetime from struct_time\n    elif isinstance(ts, datetime.datetime):\n        dt = ts\n    else:\n        raise ValueError(\"Invalid input type for timestamp\")\n\n    # Format datetime in RFC 1123 format\n    return dt.strftime('%a, %d %b %Y %H:%M:%S GMT')", "task_id": "tornado/id34", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        expires: Optional[Union[float, Tuple, datetime.datetime]] = None,\n        path: str = \"/\",\n        expires_days: Optional[float] = None,\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Sets an outgoing cookie name/value with the given options.\n\n        Newly-set cookies are not immediately visible via `get_cookie`;\n        they are not present until the next request.\n\n        expires may be a numeric timestamp as returned by `time.time`,\n        a time tuple as returned by `time.gmtime`, or a\n        `datetime.datetime` object.\n\n        Additional keyword arguments are set on the cookies.Morsel\n        directly.\n        See https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel\n        for available attributes.\n        \"\"\"\n        # The cookie library only accepts type str, in both python 2 and 3", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25}, {"context": "        `time.time`.\n\n        \"\"\"\n        return time.time()\n\n    def add_timeout(\n        self,\n        deadline: Union[float, datetime.timedelta],\n        callback: Callable[..., None],\n        *args: Any,\n        **kwargs: Any\n    ) -> object:\n        \"\"\"Runs the ``callback`` at the time ``deadline`` from the I/O loop.\n\n        Returns an opaque handle that may be passed to\n        `remove_timeout` to cancel.\n\n        ``deadline`` may be a number denoting a time (on the same\n        scale as `IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 550, "start_line_no": 540, "end_line_no": 560, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23478260869565218}, {"context": "\n    def time(self) -> float:\n        \"\"\"Returns the current time according to the `IOLoop`'s clock.\n\n        The return value is a floating-point number relative to an\n        unspecified time in the past.\n\n        Historically, the IOLoop could be customized to use e.g.\n        `time.monotonic` instead of `time.time`, but this is not\n        currently supported and so this method is equivalent to\n        `time.time`.\n\n        \"\"\"\n        return time.time()\n\n    def add_timeout(\n        self,\n        deadline: Union[float, datetime.timedelta],\n        callback: Callable[..., None],\n        *args: Any,", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 540, "start_line_no": 530, "end_line_no": 550, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22033898305084745}, {"context": "        to ``kwargs`` and None will be returned as ``old_value``.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            # The arg to replace is passed positionally\n            old_value = args[self.arg_pos]\n            args = list(args)  # *args is normally a tuple\n            args[self.arg_pos] = new_value\n        else:\n            # The arg to replace is either omitted or passed by keyword.\n            old_value = kwargs.get(self.name)\n            kwargs[self.name] = new_value\n        return old_value, args, kwargs\n\n\ndef timedelta_to_seconds(td):\n    # type: (datetime.timedelta) -> float\n    \"\"\"Equivalent to ``td.total_seconds()`` (introduced in Python 2.7).\"\"\"\n    return td.total_seconds()\n\n", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21666666666666667}, {"context": "            raise QueueFull\n        else:\n            self.__put_internal(item)\n\n    def get(\n        self, timeout: Optional[Union[float, datetime.timedelta]] = None\n    ) -> Awaitable[_T]:\n        \"\"\"Remove and return an item from the queue.\n\n        Returns an awaitable which resolves once an item is available, or raises\n        `tornado.util.TimeoutError` after a timeout.\n\n        ``timeout`` may be a number denoting a time (on the same\n        scale as `tornado.ioloop.IOLoop.time`, normally `time.time`), or a\n        `datetime.timedelta` object for a deadline relative to the\n        current time.\n\n        .. note::\n\n           The ``timeout`` argument of this method differs from that", "metadata": [{"fpath_tuple": ["tornado", "queues.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21323529411764705}, {"context": "        expires may be a numeric timestamp as returned by `time.time`,\n        a time tuple as returned by `time.gmtime`, or a\n        `datetime.datetime` object.\n\n        Additional keyword arguments are set on the cookies.Morsel\n        directly.\n        See https://docs.python.org/3/library/http.cookies.html#http.cookies.Morsel\n        for available attributes.\n        \"\"\"\n        # The cookie library only accepts type str, in both python 2 and 3\n        name = escape.native_str(name)\n        value = escape.native_str(value)\n        if re.search(r\"[\\x00-\\x20]\", name + value):\n            # Don't let us accidentally inject bad stuff\n            raise ValueError(\"Invalid cookie %r: %r\" % (name, value))\n        if not hasattr(self, \"_new_cookie\"):\n            self._new_cookie = (\n                http.cookies.SimpleCookie()\n            )  # type: http.cookies.SimpleCookie\n        if name in self._new_cookie:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 620, "start_line_no": 610, "end_line_no": 630, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2119205298013245}, {"context": "                version, token, timestamp = self._decode_xsrf_token(cookie)\n            else:\n                version, token, timestamp = None, None, None\n            if token is None:\n                version = None\n                token = os.urandom(16)\n                timestamp = time.time()\n            assert token is not None\n            assert timestamp is not None\n            self._raw_xsrf_token = (version, token, timestamp)\n        return self._raw_xsrf_token\n\n    def _decode_xsrf_token(\n        self, cookie: str\n    ) -> Tuple[Optional[int], Optional[bytes], Optional[float]]:\n        \"\"\"Convert a cookie string into a the tuple form returned by\n        _get_raw_xsrf_token.\n        \"\"\"\n\n        try:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1450, "start_line_no": 1440, "end_line_no": 1460, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21153846153846154}, {"context": "\n_T = TypeVar(\"_T\")\n\n__all__ = [\"Queue\", \"PriorityQueue\", \"LifoQueue\", \"QueueFull\", \"QueueEmpty\"]\n\n\nclass QueueEmpty(Exception):\n    \"\"\"Raised by `.Queue.get_nowait` when the queue has no items.\"\"\"\n\n    pass\n\n\nclass QueueFull(Exception):\n    \"\"\"Raised by `.Queue.put_nowait` when a queue is at its maximum size.\"\"\"\n\n    pass\n\n\ndef _set_timeout(\n    future: Future, timeout: Union[None, float, datetime.timedelta]", "metadata": [{"fpath_tuple": ["tornado", "queues.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19444444444444445}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def parse_url_path(self, url_path: str) -> str:\n#         \"\"\"Converts a static URL path into a filesystem path.\n# \n#         ``url_path`` is the path component of the URL with\n#         ``static_url_prefix`` removed.  The return value should be\n#         filesystem path relative to ``static_path``.\n# \n#         This is the inverse of `make_static_url`.\n#         \"\"\"\n#         if os.path.sep != \"/\":\n#             url_path = url_path.replace(\"/\", os.path.sep)\n#         return url_path\n# \n#     @classmethod\n#     def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n#         \"\"\"Generate the version string to be used in static URLs.\n# \n#         ``settings`` is the `Application.settings` dictionary and ``path``\n#         is the relative location of the requested asset on the filesystem.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n# \n#         Overrides the value from `.HTTP1ConnectionParameters`.\n#         \"\"\"\n#         self._max_body_size = max_body_size\n# \n#     def write_headers(\n#         self,\n#         start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n#         headers: httputil.HTTPHeaders,\n#         chunk: Optional[bytes] = None,\n#     ) -> \"Future[None]\":\n#         \"\"\"Implements `.HTTPConnection.write_headers`.\"\"\"\n#         lines = []\n#         if self.is_client:\n#             assert isinstance(start_line, httputil.RequestStartLine)\n#             self._request_start_line = start_line\n#             lines.append(utf8(\"%s %s HTTP/1.1\" % (start_line[0], start_line[1])))\n#             # Client requests with a non-empty body must have either a\n#             # Content-Length or a Transfer-Encoding.\n#             self._chunking_output = (\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n#     ) -> \"Future[None]\":\n#         \"\"\"Implements `.HTTPConnection.write_headers`.\"\"\"\n#         lines = []\n#         if self.is_client:\n#             assert isinstance(start_line, httputil.RequestStartLine)\n#             self._request_start_line = start_line\n#             lines.append(utf8(\"%s %s HTTP/1.1\" % (start_line[0], start_line[1])))\n#             # Client requests with a non-empty body must have either a\n#             # Content-Length or a Transfer-Encoding.\n#             self._chunking_output = (\n#                 start_line.method in (\"POST\", \"PUT\", \"PATCH\")\n#                 and \"Content-Length\" not in headers\n#                 and (\n#                     \"Transfer-Encoding\" not in headers\n#                     or headers[\"Transfer-Encoding\"] == \"chunked\"\n#                 )\n#             )\n#         else:\n#             assert isinstance(start_line, httputil.ResponseStartLine)\n#             assert self._request_start_line is not None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n# \n#     def set_body_timeout(self, timeout: float) -> None:\n#         \"\"\"Sets the body timeout for a single request.\n# \n#         Overrides the value from `.HTTP1ConnectionParameters`.\n#         \"\"\"\n#         self._body_timeout = timeout\n# \n#     def set_max_body_size(self, max_body_size: int) -> None:\n#         \"\"\"Sets the body size limit for a single request.\n# \n#         Overrides the value from `.HTTP1ConnectionParameters`.\n#         \"\"\"\n#         self._max_body_size = max_body_size\n# \n#     def write_headers(\n#         self,\n#         start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n#         headers: httputil.HTTPHeaders,\n#         chunk: Optional[bytes] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n#         if self.params.no_keep_alive:\n#             return False\n#         connection_header = headers.get(\"Connection\")\n#         if connection_header is not None:\n#             connection_header = connection_header.lower()\n#         if start_line.version == \"HTTP/1.1\":\n#             return connection_header != \"close\"\n#         elif (\n#             \"Content-Length\" in headers\n#             or headers.get(\"Transfer-Encoding\", \"\").lower() == \"chunked\"\n#             or getattr(start_line, \"method\", None) in (\"HEAD\", \"GET\")\n#         ):\n#             # start_line may be a request or response start line; only\n#             # the former has a method attribute.\n#             return connection_header == \"keep-alive\"\n#         return False\n# \n#     def _finish_request(self, future: \"Optional[Future[None]]\") -> None:\n#         self._clear_callbacks()\n#         if not self.is_client and self._disconnect_on_finish:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# \n#             from tornado.options import define, parse_command_line, options\n# \n#             define('template_path', group='application')\n#             define('static_path', group='application')\n# \n#             parse_command_line()\n# \n#             application = Application(\n#                 handlers, **options.group_dict('application'))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         \"\"\"\n#         url = settings.get(\"static_url_prefix\", \"/static/\") + path\n#         if not include_version:\n#             return url\n# \n#         version_hash = cls.get_version(settings, path)\n#         if not version_hash:\n#             return url\n# \n#         return \"%s?v=%s\" % (url, version_hash)\n# \n#     def parse_url_path(self, url_path: str) -> str:\n#         \"\"\"Converts a static URL path into a filesystem path.\n# \n#         ``url_path`` is the path component of the URL with\n#         ``static_url_prefix`` removed.  The return value should be\n#         filesystem path relative to ``static_path``.\n# \n#         This is the inverse of `make_static_url`.\n#         \"\"\"\n# --------------------------------------------------\n\ndef parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n", "metadata": {"task_id": "tornado/id35", "ground_truth": "def parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n    try:\n        method, path, version = line.split(\" \")\n    except ValueError:\n        # https://tools.ietf.org/html/rfc7230#section-3.1.1\n        # invalid request-line SHOULD respond with a 400 (Bad Request)\n        raise HTTPInputError(\"Malformed HTTP request line\")\n    if not _http_version_re.match(version):\n        raise HTTPInputError(\n            \"Malformed HTTP version in HTTP Request-Line: %r\" % version\n        )\n    return RequestStartLine(method, path, version)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "parse_request_start_line", "lineno": 0, "context_start_lineno": 0, "_id": 35, "query_window": {"context": "from collections import namedtuple\n# Define the named tuple for the request start line\nRequestStartLine = namedtuple('RequestStartLine', ['method', 'path', 'version'])\ndef parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n    The response is a `collections.namedtuple`.\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n    # Split the line into components by spaces", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from collections import namedtuple\n\n# Define the named tuple for the request start line\nRequestStartLine = namedtuple('RequestStartLine', ['method', 'path', 'version'])\n\ndef parse_request_start_line(line: str) -> RequestStartLine:\n    \"\"\"Returns a (method, path, version) tuple for an HTTP 1.x request line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_request_start_line(\"GET /foo HTTP/1.1\")\n    RequestStartLine(method='GET', path='/foo', version='HTTP/1.1')\n    \"\"\"\n    # Split the line into components by spaces\n    parts = line.split()\n    \n    # Ensure we have exactly 3 parts\n    if len(parts) != 3:\n        raise ValueError(\"Invalid request line format\")\n    \n    # Unpack the parts into method, path, and version\n    method, path, version = parts\n    \n    # Return the named tuple\n    return RequestStartLine(method=method, path=path, version=version)", "task_id": "tornado/id35", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        \"\"\"\n        url = settings.get(\"static_url_prefix\", \"/static/\") + path\n        if not include_version:\n            return url\n\n        version_hash = cls.get_version(settings, path)\n        if not version_hash:\n            return url\n\n        return \"%s?v=%s\" % (url, version_hash)\n\n    def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2950, "start_line_no": 2940, "end_line_no": 2960, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21875}, {"context": "        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::\n\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1956521739130435}, {"context": "        if self.params.no_keep_alive:\n            return False\n        connection_header = headers.get(\"Connection\")\n        if connection_header is not None:\n            connection_header = connection_header.lower()\n        if start_line.version == \"HTTP/1.1\":\n            return connection_header != \"close\"\n        elif (\n            \"Content-Length\" in headers\n            or headers.get(\"Transfer-Encoding\", \"\").lower() == \"chunked\"\n            or getattr(start_line, \"method\", None) in (\"HEAD\", \"GET\")\n        ):\n            # start_line may be a request or response start line; only\n            # the former has a method attribute.\n            return connection_header == \"keep-alive\"\n        return False\n\n    def _finish_request(self, future: \"Optional[Future[None]]\") -> None:\n        self._clear_callbacks()\n        if not self.is_client and self._disconnect_on_finish:", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 560, "start_line_no": 550, "end_line_no": 570, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1935483870967742}, {"context": "\n    def set_body_timeout(self, timeout: float) -> None:\n        \"\"\"Sets the body timeout for a single request.\n\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._body_timeout = timeout\n\n    def set_max_body_size(self, max_body_size: int) -> None:\n        \"\"\"Sets the body size limit for a single request.\n\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._max_body_size = max_body_size\n\n    def write_headers(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n        chunk: Optional[bytes] = None,", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.192}, {"context": "    ) -> \"Future[None]\":\n        \"\"\"Implements `.HTTPConnection.write_headers`.\"\"\"\n        lines = []\n        if self.is_client:\n            assert isinstance(start_line, httputil.RequestStartLine)\n            self._request_start_line = start_line\n            lines.append(utf8(\"%s %s HTTP/1.1\" % (start_line[0], start_line[1])))\n            # Client requests with a non-empty body must have either a\n            # Content-Length or a Transfer-Encoding.\n            self._chunking_output = (\n                start_line.method in (\"POST\", \"PUT\", \"PATCH\")\n                and \"Content-Length\" not in headers\n                and (\n                    \"Transfer-Encoding\" not in headers\n                    or headers[\"Transfer-Encoding\"] == \"chunked\"\n                )\n            )\n        else:\n            assert isinstance(start_line, httputil.ResponseStartLine)\n            assert self._request_start_line is not None", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1875}, {"context": "\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._max_body_size = max_body_size\n\n    def write_headers(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n        chunk: Optional[bytes] = None,\n    ) -> \"Future[None]\":\n        \"\"\"Implements `.HTTPConnection.write_headers`.\"\"\"\n        lines = []\n        if self.is_client:\n            assert isinstance(start_line, httputil.RequestStartLine)\n            self._request_start_line = start_line\n            lines.append(utf8(\"%s %s HTTP/1.1\" % (start_line[0], start_line[1])))\n            # Client requests with a non-empty body must have either a\n            # Content-Length or a Transfer-Encoding.\n            self._chunking_output = (", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18518518518518517}, {"context": "\n    def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"\n        if os.path.sep != \"/\":\n            url_path = url_path.replace(\"/\", os.path.sep)\n        return url_path\n\n    @classmethod\n    def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n        \"\"\"Generate the version string to be used in static URLs.\n\n        ``settings`` is the `Application.settings` dictionary and ``path``\n        is the relative location of the requested asset on the filesystem.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2960, "start_line_no": 2950, "end_line_no": 2970, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1836734693877551}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         pass\n# \n# \n# _T = TypeVar(\"_T\")\n# _S = TypeVar(\"_S\", bound=_Selectable)\n# \n# \n# class IOLoop(Configurable):\n#     \"\"\"An I/O event loop.\n# \n#     As of Tornado 6.0, `IOLoop` is a wrapper around the `asyncio` event\n#     loop.\n# \n#     Example usage for a simple TCP server:\n# \n#     .. testcode::\n# \n#         import errno\n#         import functools\n#         import socket\n# --------------------------------------------------\n# the below code fragment can be found in:\n# wsgi.py\n# --------------------------------------------------\n#             if \"content-length\" not in header_set:\n#                 headers.append((\"Content-Length\", str(len(body))))\n#             if \"content-type\" not in header_set:\n#                 headers.append((\"Content-Type\", \"text/html; charset=UTF-8\"))\n#         if \"server\" not in header_set:\n#             headers.append((\"Server\", \"TornadoServer/%s\" % tornado.version))\n# \n#         start_line = httputil.ResponseStartLine(\"HTTP/1.1\", status_code, reason)\n#         header_obj = httputil.HTTPHeaders()\n#         for key, value in headers:\n#             header_obj.add(key, value)\n#         assert request.connection is not None\n#         request.connection.write_headers(start_line, header_obj, chunk=body)\n#         request.connection.finish()\n#         self._log(status_code, request)\n# \n#     @staticmethod\n#     def environ(request: httputil.HTTPServerRequest) -> Dict[Text, Any]:\n#         \"\"\"Converts a `tornado.httputil.HTTPServerRequest` to a WSGI environment.\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# \n#             from tornado.options import define, parse_command_line, options\n# \n#             define('template_path', group='application')\n#             define('static_path', group='application')\n# \n#             parse_command_line()\n# \n#             application = Application(\n#                 handlers, **options.group_dict('application'))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# def import_object(name: str) -> Any:\n#     \"\"\"Imports an object by name.\n# \n#     ``import_object('x')`` is equivalent to ``import x``.\n#     ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n# \n#     >>> import tornado.escape\n#     >>> import_object('tornado.escape') is tornado.escape\n#     True\n#     >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n#     True\n#     >>> import_object('tornado') is tornado\n#     True\n#     >>> import_object('tornado.missing_module')\n#     Traceback (most recent call last):\n#         ...\n#     ImportError: No module named missing_module\n#     \"\"\"\n#     if name.count(\".\") == 0:\n#         return __import__(name)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#     args: Optional[List[str]] = None, final: bool = True\n# ) -> List[str]:\n#     \"\"\"Parses global options from the command line.\n# \n#     See `OptionParser.parse_command_line`.\n#     \"\"\"\n#     return options.parse_command_line(args, final=final)\n# \n# \n# def parse_config_file(path: str, final: bool = True) -> None:\n#     \"\"\"Parses global options from a config file.\n# \n#     See `OptionParser.parse_config_file`.\n#     \"\"\"\n#     return options.parse_config_file(path, final=final)\n# \n# \n# def print_help(file: Optional[TextIO] = None) -> None:\n#     \"\"\"Prints all the command line options to stderr (or another file).\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n# \n#     def set_body_timeout(self, timeout: float) -> None:\n#         \"\"\"Sets the body timeout for a single request.\n# \n#         Overrides the value from `.HTTP1ConnectionParameters`.\n#         \"\"\"\n#         self._body_timeout = timeout\n# \n#     def set_max_body_size(self, max_body_size: int) -> None:\n#         \"\"\"Sets the body size limit for a single request.\n# \n#         Overrides the value from `.HTTP1ConnectionParameters`.\n#         \"\"\"\n#         self._max_body_size = max_body_size\n# \n#     def write_headers(\n#         self,\n#         start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n#         headers: httputil.HTTPHeaders,\n#         chunk: Optional[bytes] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# simple_httpclient.py\n# --------------------------------------------------\n#         headers: httputil.HTTPHeaders,\n#     ) -> None:\n#         assert isinstance(first_line, httputil.ResponseStartLine)\n#         if self.request.expect_100_continue and first_line.code == 100:\n#             await self._write_body(False)\n#             return\n#         self.code = first_line.code\n#         self.reason = first_line.reason\n#         self.headers = headers\n# \n#         if self._should_follow_redirect():\n#             return\n# \n#         if self.request.header_callback is not None:\n#             # Reassemble the start line.\n#             self.request.header_callback(\"%s %s %s\\r\\n\" % first_line)\n#             for k, v in self.headers.get_all():\n#                 self.request.header_callback(\"%s: %s\\r\\n\" % (k, v))\n#             self.request.header_callback(\"\\r\\n\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         \"\"\"\n#         url = settings.get(\"static_url_prefix\", \"/static/\") + path\n#         if not include_version:\n#             return url\n# \n#         version_hash = cls.get_version(settings, path)\n#         if not version_hash:\n#             return url\n# \n#         return \"%s?v=%s\" % (url, version_hash)\n# \n#     def parse_url_path(self, url_path: str) -> str:\n#         \"\"\"Converts a static URL path into a filesystem path.\n# \n#         ``url_path`` is the path component of the URL with\n#         ``static_url_prefix`` removed.  The return value should be\n#         filesystem path relative to ``static_path``.\n# \n#         This is the inverse of `make_static_url`.\n#         \"\"\"\n# --------------------------------------------------\n\ndef parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an HTTP 1.x response line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n", "metadata": {"task_id": "tornado/id36", "ground_truth": "def parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an HTTP 1.x response line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n    line = native_str(line)\n    match = _http_response_line_re.match(line)\n    if not match:\n        raise HTTPInputError(\"Error parsing response start line\")\n    return ResponseStartLine(match.group(1), int(match.group(2)), match.group(3))", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "parse_response_start_line", "lineno": 0, "context_start_lineno": 0, "_id": 36, "query_window": {"context": "from collections import namedtuple\n# Define the ResponseStartLine named tuple\nResponseStartLine = namedtuple('ResponseStartLine', ['version', 'code', 'reason'])\ndef parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an .x response line.\n    The response is a `collections.namedtuple`.\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n    # Split the line into parts", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from collections import namedtuple\n\n# Define the ResponseStartLine named tuple\nResponseStartLine = namedtuple('ResponseStartLine', ['version', 'code', 'reason'])\n\ndef parse_response_start_line(line: str) -> ResponseStartLine:\n    \"\"\"Returns a (version, code, reason) tuple for an .x response line.\n\n    The response is a `collections.namedtuple`.\n\n    >>> parse_response_start_line(\"HTTP/1.1 200 OK\")\n    ResponseStartLine(version='HTTP/1.1', code=200, reason='OK')\n    \"\"\"\n    # Split the line into parts\n    parts = line.split(' ')\n    \n    # Extract the version, code and reason\n    version = parts[0]  # the first part is the version\n    code = int(parts[1])  # the second part is the status code (convert to int)\n    reason = ' '.join(parts[2:])  # the rest is the reason phrase\n    \n    return ResponseStartLine(version, code, reason)", "task_id": "tornado/id36", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        \"\"\"\n        url = settings.get(\"static_url_prefix\", \"/static/\") + path\n        if not include_version:\n            return url\n\n        version_hash = cls.get_version(settings, path)\n        if not version_hash:\n            return url\n\n        return \"%s?v=%s\" % (url, version_hash)\n\n    def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2950, "start_line_no": 2940, "end_line_no": 2960, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2047244094488189}, {"context": "        headers: httputil.HTTPHeaders,\n    ) -> None:\n        assert isinstance(first_line, httputil.ResponseStartLine)\n        if self.request.expect_100_continue and first_line.code == 100:\n            await self._write_body(False)\n            return\n        self.code = first_line.code\n        self.reason = first_line.reason\n        self.headers = headers\n\n        if self._should_follow_redirect():\n            return\n\n        if self.request.header_callback is not None:\n            # Reassemble the start line.\n            self.request.header_callback(\"%s %s %s\\r\\n\" % first_line)\n            for k, v in self.headers.get_all():\n                self.request.header_callback(\"%s: %s\\r\\n\" % (k, v))\n            self.request.header_callback(\"\\r\\n\")\n", "metadata": [{"fpath_tuple": ["tornado", "simple_httpclient.py"], "line_no": 600, "start_line_no": 590, "end_line_no": 610, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18518518518518517}, {"context": "\n    def set_body_timeout(self, timeout: float) -> None:\n        \"\"\"Sets the body timeout for a single request.\n\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._body_timeout = timeout\n\n    def set_max_body_size(self, max_body_size: int) -> None:\n        \"\"\"Sets the body size limit for a single request.\n\n        Overrides the value from `.HTTP1ConnectionParameters`.\n        \"\"\"\n        self._max_body_size = max_body_size\n\n    def write_headers(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n        chunk: Optional[bytes] = None,", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1774193548387097}, {"context": "    args: Optional[List[str]] = None, final: bool = True\n) -> List[str]:\n    \"\"\"Parses global options from the command line.\n\n    See `OptionParser.parse_command_line`.\n    \"\"\"\n    return options.parse_command_line(args, final=final)\n\n\ndef parse_config_file(path: str, final: bool = True) -> None:\n    \"\"\"Parses global options from a config file.\n\n    See `OptionParser.parse_config_file`.\n    \"\"\"\n    return options.parse_config_file(path, final=final)\n\n\ndef print_help(file: Optional[TextIO] = None) -> None:\n    \"\"\"Prints all the command line options to stderr (or another file).\n", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 720, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1774193548387097}, {"context": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.176}, {"context": "        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::\n\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17391304347826086}, {"context": "            if \"content-length\" not in header_set:\n                headers.append((\"Content-Length\", str(len(body))))\n            if \"content-type\" not in header_set:\n                headers.append((\"Content-Type\", \"text/html; charset=UTF-8\"))\n        if \"server\" not in header_set:\n            headers.append((\"Server\", \"TornadoServer/%s\" % tornado.version))\n\n        start_line = httputil.ResponseStartLine(\"HTTP/1.1\", status_code, reason)\n        header_obj = httputil.HTTPHeaders()\n        for key, value in headers:\n            header_obj.add(key, value)\n        assert request.connection is not None\n        request.connection.write_headers(start_line, header_obj, chunk=body)\n        request.connection.finish()\n        self._log(status_code, request)\n\n    @staticmethod\n    def environ(request: httputil.HTTPServerRequest) -> Dict[Text, Any]:\n        \"\"\"Converts a `tornado.httputil.HTTPServerRequest` to a WSGI environment.\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "wsgi.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17058823529411765}, {"context": "        pass\n\n\n_T = TypeVar(\"_T\")\n_S = TypeVar(\"_S\", bound=_Selectable)\n\n\nclass IOLoop(Configurable):\n    \"\"\"An I/O event loop.\n\n    As of Tornado 6.0, `IOLoop` is a wrapper around the `asyncio` event\n    loop.\n\n    Example usage for a simple TCP server:\n\n    .. testcode::\n\n        import errno\n        import functools\n        import socket", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1693548387096774}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n#         return dict(path_args=path_args, path_kwargs=path_kwargs)\n# \n#     def reverse(self, *args: Any) -> Optional[str]:\n#         if self._path is None:\n#             raise ValueError(\"Cannot reverse url regex \" + self.regex.pattern)\n#         assert len(args) == self._group_count, (\n#             \"required number of arguments \" \"not found\"\n#         )\n#         if not len(args):\n#             return self._path\n#         converted_args = []\n#         for a in args:\n#             if not isinstance(a, (unicode_type, bytes)):\n#                 a = str(a)\n#             converted_args.append(url_escape(utf8(a), plus=False))\n#         return self._path % tuple(converted_args)\n# \n#     def _find_groups(self) -> Tuple[Optional[str], Optional[int]]:\n#         \"\"\"Returns a tuple (reverse string, group count) for a url.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# auth.py\n# --------------------------------------------------\n#     key_elems.append(\n#         escape.utf8(urllib.parse.quote(token[\"secret\"], safe=\"~\") if token else \"\")\n#     )\n#     key = b\"&\".join(key_elems)\n# \n#     hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n#     return binascii.b2a_base64(hash.digest())[:-1]\n# \n# \n# def _oauth_escape(val: Union[str, bytes]) -> str:\n#     if isinstance(val, unicode_type):\n#         val = val.encode(\"utf-8\")\n#     return urllib.parse.quote(val, safe=\"~\")\n# \n# \n# def _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n#     # I can't find an officially-defined encoding for oauth responses and\n#     # have never seen anyone use non-ascii.  Leave the response in a byte\n#     # string for python 2, and use utf8 on python 3.\n#     body_str = escape.native_str(body)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#             data = utf8(str_data.replace(\"\\n\", \"\\r\\n\"))\n#             args, files = form_data_args()\n#             parse_multipart_form_data(b\"1234\", data, args, files)\n#             file = files[\"files\"][0]\n#             self.assertEqual(file[\"filename\"], filename)\n#             self.assertEqual(file[\"body\"], b\"Foo\")\n# \n#     def test_non_ascii_filename(self):\n#         data = b\"\"\"\\\n# --1234\n# Content-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"; filename*=UTF-8''%C3%A1b.txt\n# \n# Foo\n# --1234--\"\"\".replace(\n#             b\"\\n\", b\"\\r\\n\"\n#         )\n#         args, files = form_data_args()\n#         parse_multipart_form_data(b\"1234\", data, args, files)\n#         file = files[\"files\"][0]\n#         self.assertEqual(file[\"filename\"], u\"\u00e1b.txt\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#             str_data = \"\"\"\\\n# --1234\n# Content-Disposition: form-data; name=\"files\"; filename=\"%s\"\n# \n# Foo\n# --1234--\"\"\" % filename.replace(\n#                 \"\\\\\", \"\\\\\\\\\"\n#             ).replace(\n#                 '\"', '\\\\\"'\n#             )\n#             data = utf8(str_data.replace(\"\\n\", \"\\r\\n\"))\n#             args, files = form_data_args()\n#             parse_multipart_form_data(b\"1234\", data, args, files)\n#             file = files[\"files\"][0]\n#             self.assertEqual(file[\"filename\"], filename)\n#             self.assertEqual(file[\"body\"], b\"Foo\")\n# \n#     def test_non_ascii_filename(self):\n#         data = b\"\"\"\\\n# --1234\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n#             (u\"\\u00e9\", \"%C3%A9\"),\n#         ]  # type: List[Tuple[Union[str, bytes], str]]\n#         for unescaped, escaped in tests:\n#             self.assertEqual(url_escape(unescaped), escaped)\n# \n#     def test_url_unescape_unicode(self):\n#         tests = [\n#             (\"%C3%A9\", u\"\\u00e9\", \"utf8\"),\n#             (\"%C3%A9\", u\"\\u00c3\\u00a9\", \"latin1\"),\n#             (\"%C3%A9\", utf8(u\"\\u00e9\"), None),\n#         ]\n#         for escaped, unescaped, encoding in tests:\n#             # input strings to url_unescape should only contain ascii\n#             # characters, but make sure the function accepts both byte\n#             # and unicode strings.\n#             self.assertEqual(url_unescape(to_unicode(escaped), encoding), unescaped)\n#             self.assertEqual(url_unescape(utf8(escaped), encoding), unescaped)\n# \n#     def test_url_escape_quote_plus(self):\n#         unescaped = \"+ #%\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n#         ]\n#         for escaped, unescaped in tests:\n#             self.assertEqual(unescaped, xhtml_unescape(escaped))\n# \n#     def test_url_escape_unicode(self):\n#         tests = [\n#             # byte strings are passed through as-is\n#             (u\"\\u00e9\".encode(\"utf8\"), \"%C3%A9\"),\n#             (u\"\\u00e9\".encode(\"latin1\"), \"%E9\"),\n#             # unicode strings become utf8\n#             (u\"\\u00e9\", \"%C3%A9\"),\n#         ]  # type: List[Tuple[Union[str, bytes], str]]\n#         for unescaped, escaped in tests:\n#             self.assertEqual(url_escape(unescaped), escaped)\n# \n#     def test_url_unescape_unicode(self):\n#         tests = [\n#             (\"%C3%A9\", u\"\\u00e9\", \"utf8\"),\n#             (\"%C3%A9\", u\"\\u00c3\\u00a9\", \"latin1\"),\n#             (\"%C3%A9\", utf8(u\"\\u00e9\"), None),\n# --------------------------------------------------\n\ndef _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n", "metadata": {"task_id": "tornado/id37", "ground_truth": "def _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    r\"\"\"Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n    parts = _parseparam(\";\" + line)\n    key = next(parts)\n    # decode_params treats first argument special, but we already stripped key\n    params = [(\"Dummy\", \"value\")]\n    for p in parts:\n        i = p.find(\"=\")\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i + 1 :].strip()\n            params.append((name, native_str(value)))\n    decoded_params = email.utils.decode_params(params)\n    decoded_params.pop(0)  # get rid of the dummy again\n    pdict = {}\n    for name, decoded_value in decoded_params:\n        value = email.utils.collapse_rfc2231_value(decoded_value)\n        if len(value) >= 2 and value[0] == '\"' and value[-1] == '\"':\n            value = value[1:-1]\n        pdict[name] = value\n    return key, pdict", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "_parse_header", "lineno": 0, "context_start_lineno": 0, "_id": 37, "query_window": {"context": "import re\nfrom typing import Tuple, Dict\ndef _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    \"\"\"Parse a Content-type like header.\n    Return the main content-type and a dictionary of options.\n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "import re\nfrom typing import Tuple, Dict\n\ndef _parse_header(line: str) -> Tuple[str, Dict[str, str]]:\n    \"\"\"Parse a Content-type like header.\n    \n    Return the main content-type and a dictionary of options.\n    \n    >>> d = \"form-data; foo=\\\"b\\\\\\\\a\\\\\\\"r\\\"; file*=utf-8''T%C3%A4st\"\n    >>> ct, d = _parse_header(d)\n    >>> ct\n    'form-data'\n    >>> d['file'] == r'T\\u00e4st'.encode('ascii').decode('unicode_escape')\n    True\n    >>> d['foo']\n    'b\\\\a\"r'\n    \"\"\"\n    # Regex to match the content type and parameters\n    main_type_regex = r'^\\s*([^;\\s]+)'\n    param_regex = r';\\s*([^=\\s]+)\\s*=\\s*(\"([^\"]*)\"|\\'([^\\']*)\\'|([^;\\s]+))'\n    \n    # Find the main content type\n    match = re.match(main_type_regex, line)\n    if not match:\n        raise ValueError(\"Invalid content type header format\")\n    \n    main_type = match.group(1)\n    options = {}\n    \n    # Find all parameters\n    for param_match in re.finditer(param_regex, line):\n        key = param_match.group(1)\n        if param_match.group(3):\n            value = param_match.group(3)\n        elif param_match.group(4):\n            value = param_match.group(4)\n        else:\n            value = param_match.group(5)\n        \n        # Decode any URL-encoded values (e.g., 'file*=utf-8''T%C3%A4st)\n        if key.endswith('*'):\n            encoding, _, encoded_value = value.partition(\"'\")\n            value = encoded_value.encode().decode('unicode_escape')\n            key = key[:-1]  # Remove the '*' from the key\n        \n        # Clean the value by replacing escaped characters\n        value = value.replace(r'\\\\', '\\\\').replace(r'\\\"', '\"')\n        options[key] = value\n\n    return main_type, options\n\n# You can now test the function with the provided docstring examples.", "task_id": "tornado/id37", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        ]\n        for escaped, unescaped in tests:\n            self.assertEqual(unescaped, xhtml_unescape(escaped))\n\n    def test_url_escape_unicode(self):\n        tests = [\n            # byte strings are passed through as-is\n            (u\"\\u00e9\".encode(\"utf8\"), \"%C3%A9\"),\n            (u\"\\u00e9\".encode(\"latin1\"), \"%E9\"),\n            # unicode strings become utf8\n            (u\"\\u00e9\", \"%C3%A9\"),\n        ]  # type: List[Tuple[Union[str, bytes], str]]\n        for unescaped, escaped in tests:\n            self.assertEqual(url_escape(unescaped), escaped)\n\n    def test_url_unescape_unicode(self):\n        tests = [\n            (\"%C3%A9\", u\"\\u00e9\", \"utf8\"),\n            (\"%C3%A9\", u\"\\u00c3\\u00a9\", \"latin1\"),\n            (\"%C3%A9\", utf8(u\"\\u00e9\"), None),", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20625}, {"context": "            (u\"\\u00e9\", \"%C3%A9\"),\n        ]  # type: List[Tuple[Union[str, bytes], str]]\n        for unescaped, escaped in tests:\n            self.assertEqual(url_escape(unescaped), escaped)\n\n    def test_url_unescape_unicode(self):\n        tests = [\n            (\"%C3%A9\", u\"\\u00e9\", \"utf8\"),\n            (\"%C3%A9\", u\"\\u00c3\\u00a9\", \"latin1\"),\n            (\"%C3%A9\", utf8(u\"\\u00e9\"), None),\n        ]\n        for escaped, unescaped, encoding in tests:\n            # input strings to url_unescape should only contain ascii\n            # characters, but make sure the function accepts both byte\n            # and unicode strings.\n            self.assertEqual(url_unescape(to_unicode(escaped), encoding), unescaped)\n            self.assertEqual(url_unescape(utf8(escaped), encoding), unescaped)\n\n    def test_url_escape_quote_plus(self):\n        unescaped = \"+ #%\"", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20118343195266272}, {"context": "            str_data = \"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"%s\"\n\nFoo\n--1234--\"\"\" % filename.replace(\n                \"\\\\\", \"\\\\\\\\\"\n            ).replace(\n                '\"', '\\\\\"'\n            )\n            data = utf8(str_data.replace(\"\\n\", \"\\r\\n\"))\n            args, files = form_data_args()\n            parse_multipart_form_data(b\"1234\", data, args, files)\n            file = files[\"files\"][0]\n            self.assertEqual(file[\"filename\"], filename)\n            self.assertEqual(file[\"body\"], b\"Foo\")\n\n    def test_non_ascii_filename(self):\n        data = b\"\"\"\\\n--1234", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2}, {"context": "            data = utf8(str_data.replace(\"\\n\", \"\\r\\n\"))\n            args, files = form_data_args()\n            parse_multipart_form_data(b\"1234\", data, args, files)\n            file = files[\"files\"][0]\n            self.assertEqual(file[\"filename\"], filename)\n            self.assertEqual(file[\"body\"], b\"Foo\")\n\n    def test_non_ascii_filename(self):\n        data = b\"\"\"\\\n--1234\nContent-Disposition: form-data; name=\"files\"; filename=\"ab.txt\"; filename*=UTF-8''%C3%A1b.txt\n\nFoo\n--1234--\"\"\".replace(\n            b\"\\n\", b\"\\r\\n\"\n        )\n        args, files = form_data_args()\n        parse_multipart_form_data(b\"1234\", data, args, files)\n        file = files[\"files\"][0]\n        self.assertEqual(file[\"filename\"], u\"\u00e1b.txt\")", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19753086419753085}, {"context": "    key_elems.append(\n        escape.utf8(urllib.parse.quote(token[\"secret\"], safe=\"~\") if token else \"\")\n    )\n    key = b\"&\".join(key_elems)\n\n    hash = hmac.new(key, escape.utf8(base_string), hashlib.sha1)\n    return binascii.b2a_base64(hash.digest())[:-1]\n\n\ndef _oauth_escape(val: Union[str, bytes]) -> str:\n    if isinstance(val, unicode_type):\n        val = val.encode(\"utf-8\")\n    return urllib.parse.quote(val, safe=\"~\")\n\n\ndef _oauth_parse_response(body: bytes) -> Dict[str, Any]:\n    # I can't find an officially-defined encoding for oauth responses and\n    # have never seen anyone use non-ascii.  Leave the response in a byte\n    # string for python 2, and use utf8 on python 3.\n    body_str = escape.native_str(body)", "metadata": [{"fpath_tuple": ["tornado", "auth.py"], "line_no": 1170, "start_line_no": 1160, "end_line_no": 1180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19289340101522842}, {"context": "        return dict(path_args=path_args, path_kwargs=path_kwargs)\n\n    def reverse(self, *args: Any) -> Optional[str]:\n        if self._path is None:\n            raise ValueError(\"Cannot reverse url regex \" + self.regex.pattern)\n        assert len(args) == self._group_count, (\n            \"required number of arguments \" \"not found\"\n        )\n        if not len(args):\n            return self._path\n        converted_args = []\n        for a in args:\n            if not isinstance(a, (unicode_type, bytes)):\n                a = str(a)\n            converted_args.append(url_escape(utf8(a), plus=False))\n        return self._path % tuple(converted_args)\n\n    def _find_groups(self) -> Tuple[Optional[str], Optional[int]]:\n        \"\"\"Returns a tuple (reverse string, group count) for a url.\n", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 600, "start_line_no": 590, "end_line_no": 610, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1907514450867052}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         accept = self.compute_accept_value(key)\n#         assert headers[\"Sec-Websocket-Accept\"] == accept\n# \n#         extensions = self._parse_extensions_header(headers)\n#         for ext in extensions:\n#             if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n#                 self._create_compressors(\"client\", ext[1])\n#             else:\n#                 raise ValueError(\"unsupported extension %r\", ext)\n# \n#         self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)\n# \n#     def _get_compressor_options(\n#         self,\n#         side: str,\n#         agreed_parameters: Dict[str, Any],\n#         compression_options: Optional[Dict[str, Any]] = None,\n#     ) -> Dict[str, Any]:\n#         \"\"\"Converts a websocket agreed_parameters set to keyword arguments\n#         for our compressor objects.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         request.url = scheme + sep + rest\n#         request.headers.update(\n#             {\n#                 \"Upgrade\": \"websocket\",\n#                 \"Connection\": \"Upgrade\",\n#                 \"Sec-WebSocket-Key\": self.key,\n#                 \"Sec-WebSocket-Version\": \"13\",\n#             }\n#         )\n#         if subprotocols is not None:\n#             request.headers[\"Sec-WebSocket-Protocol\"] = \",\".join(subprotocols)\n#         if compression_options is not None:\n#             # Always offer to let the server set our max_wbits (and even though\n#             # we don't offer it, we will accept a client_no_context_takeover\n#             # from the server).\n#             # TODO: set server parameters for deflate extension\n#             # if requested in self.compression_options.\n#             request.headers[\n#                 \"Sec-WebSocket-Extensions\"\n#             ] = \"permessage-deflate; client_max_window_bits\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)\n# \n#     def _get_compressor_options(\n#         self,\n#         side: str,\n#         agreed_parameters: Dict[str, Any],\n#         compression_options: Optional[Dict[str, Any]] = None,\n#     ) -> Dict[str, Any]:\n#         \"\"\"Converts a websocket agreed_parameters set to keyword arguments\n#         for our compressor objects.\n#         \"\"\"\n#         options = dict(\n#             persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n#         )  # type: Dict[str, Any]\n#         wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n#         if wbits_header is None:\n#             options[\"max_wbits\"] = zlib.MAX_WBITS\n#         else:\n#             options[\"max_wbits\"] = int(wbits_header)\n#         options[\"compression_options\"] = compression_options\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def _process_server_headers(\n#         self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n#     ) -> None:\n#         \"\"\"Process the headers sent by the server to this client connection.\n# \n#         'key' is the websocket handshake challenge/response key.\n#         \"\"\"\n#         assert headers[\"Upgrade\"].lower() == \"websocket\"\n#         assert headers[\"Connection\"].lower() == \"upgrade\"\n#         accept = self.compute_accept_value(key)\n#         assert headers[\"Sec-Websocket-Accept\"] == accept\n# \n#         extensions = self._parse_extensions_header(headers)\n#         for ext in extensions:\n#             if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n#                 self._create_compressors(\"client\", ext[1])\n#             else:\n#                 raise ValueError(\"unsupported extension %r\", ext)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         \"\"\"\n#         options = dict(\n#             persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n#         )  # type: Dict[str, Any]\n#         wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n#         if wbits_header is None:\n#             options[\"max_wbits\"] = zlib.MAX_WBITS\n#         else:\n#             options[\"max_wbits\"] = int(wbits_header)\n#         options[\"compression_options\"] = compression_options\n#         return options\n# \n#     def _create_compressors(\n#         self,\n#         side: str,\n#         agreed_parameters: Dict[str, Any],\n#         compression_options: Optional[Dict[str, Any]] = None,\n#     ) -> None:\n#         # TODO: handle invalid parameters gracefully\n#         allowed_keys = set(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         return options\n# \n#     def _create_compressors(\n#         self,\n#         side: str,\n#         agreed_parameters: Dict[str, Any],\n#         compression_options: Optional[Dict[str, Any]] = None,\n#     ) -> None:\n#         # TODO: handle invalid parameters gracefully\n#         allowed_keys = set(\n#             [\n#                 \"server_no_context_takeover\",\n#                 \"client_no_context_takeover\",\n#                 \"server_max_window_bits\",\n#                 \"client_max_window_bits\",\n#             ]\n#         )\n#         for key in agreed_parameters:\n#             if key not in allowed_keys:\n#                 raise ValueError(\"unsupported compression parameter %r\" % key)\n# --------------------------------------------------\n\ndef _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n", "metadata": {"task_id": "tornado/id38", "ground_truth": "def _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n    if not pdict:\n        return key\n    out = [key]\n    # Sort the parameters just to make it easy to test.\n    for k, v in sorted(pdict.items()):\n        if v is None:\n            out.append(k)\n        else:\n            # TODO: quote if necessary.\n            out.append(\"%s=%s\" % (k, v))\n    return \"; \".join(out)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "_encode_header", "lineno": 0, "context_start_lineno": 0, "_id": 38, "query_window": {"context": "from typing import Dict\ndef _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n    # Start with the key\n    header = key\n    # Append each key-value pair in pdict", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Dict\n\ndef _encode_header(key: str, pdict: Dict[str, str]) -> str:\n    \"\"\"Inverse of _parse_header.\n\n    >>> _encode_header('permessage-deflate',\n    ...     {'client_max_window_bits': 15, 'client_no_context_takeover': None})\n    'permessage-deflate; client_max_window_bits=15; client_no_context_takeover'\n    \"\"\"\n    # Start with the key\n    header = key\n    \n    # Append each key-value pair in pdict\n    params = []\n    for k, v in pdict.items():\n        if v is None:\n            params.append(k)\n        else:\n            params.append(f\"{k}={v}\")\n    \n    # Join the parameters with '; ' and append to header\n    if params:\n        header += '; ' + '; '.join(params)\n    \n    return header", "task_id": "tornado/id38", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        return options\n\n    def _create_compressors(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        # TODO: handle invalid parameters gracefully\n        allowed_keys = set(\n            [\n                \"server_no_context_takeover\",\n                \"client_no_context_takeover\",\n                \"server_max_window_bits\",\n                \"client_max_window_bits\",\n            ]\n        )\n        for key in agreed_parameters:\n            if key not in allowed_keys:\n                raise ValueError(\"unsupported compression parameter %r\" % key)", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1020, "start_line_no": 1010, "end_line_no": 1030, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20967741935483872}, {"context": "        \"\"\"\n        options = dict(\n            persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n        )  # type: Dict[str, Any]\n        wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n        if wbits_header is None:\n            options[\"max_wbits\"] = zlib.MAX_WBITS\n        else:\n            options[\"max_wbits\"] = int(wbits_header)\n        options[\"compression_options\"] = compression_options\n        return options\n\n    def _create_compressors(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        # TODO: handle invalid parameters gracefully\n        allowed_keys = set(", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1010, "start_line_no": 1000, "end_line_no": 1020, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20300751879699247}, {"context": "\n    def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        \"\"\"Process the headers sent by the server to this client connection.\n\n        'key' is the websocket handshake challenge/response key.\n        \"\"\"\n        assert headers[\"Upgrade\"].lower() == \"websocket\"\n        assert headers[\"Connection\"].lower() == \"upgrade\"\n        accept = self.compute_accept_value(key)\n        assert headers[\"Sec-Websocket-Accept\"] == accept\n\n        extensions = self._parse_extensions_header(headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                self._create_compressors(\"client\", ext[1])\n            else:\n                raise ValueError(\"unsupported extension %r\", ext)\n", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 980, "start_line_no": 970, "end_line_no": 990, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1987179487179487}, {"context": "        self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)\n\n    def _get_compressor_options(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"Converts a websocket agreed_parameters set to keyword arguments\n        for our compressor objects.\n        \"\"\"\n        options = dict(\n            persistent=(side + \"_no_context_takeover\") not in agreed_parameters\n        )  # type: Dict[str, Any]\n        wbits_header = agreed_parameters.get(side + \"_max_window_bits\", None)\n        if wbits_header is None:\n            options[\"max_wbits\"] = zlib.MAX_WBITS\n        else:\n            options[\"max_wbits\"] = int(wbits_header)\n        options[\"compression_options\"] = compression_options", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1000, "start_line_no": 990, "end_line_no": 1010, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19444444444444445}, {"context": "        request.url = scheme + sep + rest\n        request.headers.update(\n            {\n                \"Upgrade\": \"websocket\",\n                \"Connection\": \"Upgrade\",\n                \"Sec-WebSocket-Key\": self.key,\n                \"Sec-WebSocket-Version\": \"13\",\n            }\n        )\n        if subprotocols is not None:\n            request.headers[\"Sec-WebSocket-Protocol\"] = \",\".join(subprotocols)\n        if compression_options is not None:\n            # Always offer to let the server set our max_wbits (and even though\n            # we don't offer it, we will accept a client_no_context_takeover\n            # from the server).\n            # TODO: set server parameters for deflate extension\n            # if requested in self.compression_options.\n            request.headers[\n                \"Sec-WebSocket-Extensions\"\n            ] = \"permessage-deflate; client_max_window_bits\"", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1400, "start_line_no": 1390, "end_line_no": 1410, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18666666666666668}, {"context": "        accept = self.compute_accept_value(key)\n        assert headers[\"Sec-Websocket-Accept\"] == accept\n\n        extensions = self._parse_extensions_header(headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                self._create_compressors(\"client\", ext[1])\n            else:\n                raise ValueError(\"unsupported extension %r\", ext)\n\n        self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)\n\n    def _get_compressor_options(\n        self,\n        side: str,\n        agreed_parameters: Dict[str, Any],\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> Dict[str, Any]:\n        \"\"\"Converts a websocket agreed_parameters set to keyword arguments\n        for our compressor objects.", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 990, "start_line_no": 980, "end_line_no": 1000, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1858974358974359}, {"context": "    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18018018018018017}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#             if self.request.method != \"HEAD\":\n#                 return self.request.connection.write(chunk)\n#             else:\n#                 future = Future()  # type: Future[None]\n#                 future.set_result(None)\n#                 return future\n# \n#     def finish(self, chunk: Optional[Union[str, bytes, dict]] = None) -> \"Future[None]\":\n#         \"\"\"Finishes this response, ending the HTTP request.\n# \n#         Passing a ``chunk`` to ``finish()`` is equivalent to passing that\n#         chunk to ``write()`` and then calling ``finish()`` with no arguments.\n# \n#         Returns a `.Future` which may optionally be awaited to track the sending\n#         of the response to the client. This `.Future` resolves when all the response\n#         data has been sent, and raises an error if the connection is closed before all\n#         data can be sent.\n# \n#         .. versionchanged:: 5.1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         return self.__setattr__(name, value)\n# \n#     def items(self) -> Iterable[Tuple[str, Any]]:\n#         \"\"\"An iterable of (name, value) pairs.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return [(opt.name, opt.value()) for name, opt in self._options.items()]\n# \n#     def groups(self) -> Set[str]:\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# \n# \n# def xhtml_escape(value: Union[str, bytes]) -> str:\n#     \"\"\"Escapes a string so it is valid within HTML or XML.\n# \n#     Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n#     When used in attribute values the escaped strings must be enclosed\n#     in quotes.\n# \n#     .. versionchanged:: 3.2\n# \n#        Added the single quote to the list of escaped characters.\n#     \"\"\"\n#     return _XHTML_ESCAPE_RE.sub(\n#         lambda match: _XHTML_ESCAPE_DICT[match.group(0)], to_basestring(value)\n#     )\n# \n# \n# def xhtml_unescape(value: Union[str, bytes]) -> str:\n#     \"\"\"Un-escapes an XML-escaped string.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n#     \"\"\"Decodes the given value from a URL.\n# \n#     The argument may be either a byte or unicode string.\n# \n#     If encoding is None, the result will be a byte string.  Otherwise,\n#     the result is a unicode string in the specified encoding.\n# \n#     If ``plus`` is true (the default), plus signs will be interpreted\n#     as spaces (literal plus signs must be represented as \"%2B\").  This\n#     is appropriate for query strings and form-encoded values but not\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n#     \"\"\"Returns a URL-encoded version of the given value.\n# \n#     If ``plus`` is true (the default), spaces will be represented\n#     as \"+\" instead of \"%20\".  This is appropriate for query strings\n#     but not for the path component of a URL.  Note that this default\n#     is the reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#         The ``plus`` argument\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         return self.request.cookies\n# \n#     def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n#         \"\"\"Returns the value of the request cookie with the given name.\n# \n#         If the named cookie is not present, returns ``default``.\n# \n#         This method only returns cookies that were present in the request.\n#         It does not see the outgoing cookies set by `set_cookie` in this\n#         handler.\n#         \"\"\"\n#         if self.request.cookies is not None and name in self.request.cookies:\n#             return self.request.cookies[name].value\n#         return default\n# \n#     def set_cookie(\n#         self,\n#         name: str,\n#         value: Union[str, bytes],\n#         domain: Optional[str] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n#         return urllib.parse.unquote_to_bytes(value)\n#     else:\n#         unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n#         return unquote(to_basestring(value), encoding=encoding)\n# \n# \n# def parse_qs_bytes(\n#     qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n# ) -> Dict[str, List[bytes]]:\n#     \"\"\"Parses a query string like urlparse.parse_qs,\n# --------------------------------------------------\n\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n", "metadata": {"task_id": "tornado/id39", "ground_truth": "def encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    if isinstance(username, unicode_type):\n        username = unicodedata.normalize(\"NFC\", username)\n    if isinstance(password, unicode_type):\n        password = unicodedata.normalize(\"NFC\", password)\n    return utf8(username) + b\":\" + utf8(password)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "encode_username_password", "lineno": 0, "context_start_lineno": 0, "_id": 39, "query_window": {"context": "from typing import Union\nimport base64\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n    The return value is a byte string in the form ``username:password``.\n    .. versionadded:: 5.1\n    \"\"\"\n    # Ensure that username and password are of type bytes", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Union\nimport base64\n\ndef encode_username_password(\n    username: Union[str, bytes], password: Union[str, bytes]\n) -> bytes:\n    \"\"\"Encodes a username/password pair in the format used by HTTP auth.\n\n    The return value is a byte string in the form ``username:password``.\n\n    .. versionadded:: 5.1\n    \"\"\"\n    # Ensure that username and password are of type bytes\n    if isinstance(username, str):\n        username = username.encode('utf-8')\n    if isinstance(password, str):\n        password = password.encode('utf-8')\n\n    # Combine username and password into the format 'username:password'\n    combined = username + b':' + password\n\n    # Encode the combined string in base64\n    encoded = base64.b64encode(combined)\n\n    return encoded", "task_id": "tornado/id39", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)\n\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2463768115942029}, {"context": "        return self.request.cookies\n\n    def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n        \"\"\"Returns the value of the request cookie with the given name.\n\n        If the named cookie is not present, returns ``default``.\n\n        This method only returns cookies that were present in the request.\n        It does not see the outgoing cookies set by `set_cookie` in this\n        handler.\n        \"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default\n\n    def set_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        domain: Optional[str] = None,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24324324324324326}, {"context": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n        The ``plus`` argument\n    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23134328358208955}, {"context": "@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:\n    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22962962962962963}, {"context": "\n\ndef xhtml_escape(value: Union[str, bytes]) -> str:\n    \"\"\"Escapes a string so it is valid within HTML or XML.\n\n    Escapes the characters ``<``, ``>``, ``\"``, ``'``, and ``&``.\n    When used in attribute values the escaped strings must be enclosed\n    in quotes.\n\n    .. versionchanged:: 3.2\n\n       Added the single quote to the list of escaped characters.\n    \"\"\"\n    return _XHTML_ESCAPE_RE.sub(\n        lambda match: _XHTML_ESCAPE_DICT[match.group(0)], to_basestring(value)\n    )\n\n\ndef xhtml_unescape(value: Union[str, bytes]) -> str:\n    \"\"\"Un-escapes an XML-escaped string.\"\"\"", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22900763358778625}, {"context": "        return self.__setattr__(name, value)\n\n    def items(self) -> Iterable[Tuple[str, Any]]:\n        \"\"\"An iterable of (name, value) pairs.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return [(opt.name, opt.value()) for name, opt in self._options.items()]\n\n    def groups(self) -> Set[str]:\n        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2288135593220339}, {"context": "            if self.request.method != \"HEAD\":\n                return self.request.connection.write(chunk)\n            else:\n                future = Future()  # type: Future[None]\n                future.set_result(None)\n                return future\n\n    def finish(self, chunk: Optional[Union[str, bytes, dict]] = None) -> \"Future[None]\":\n        \"\"\"Finishes this response, ending the HTTP request.\n\n        Passing a ``chunk`` to ``finish()`` is equivalent to passing that\n        chunk to ``write()`` and then calling ``finish()`` with no arguments.\n\n        Returns a `.Future` which may optionally be awaited to track the sending\n        of the response to the client. This `.Future` resolves when all the response\n        data has been sent, and raises an error if the connection is closed before all\n        data can be sent.\n\n        .. versionchanged:: 5.1\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1110, "start_line_no": 1100, "end_line_no": 1120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2198581560283688}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         .. versionadded:: 4.1\n# \n#         .. versionchanged:: 4.5\n# \n#            Added ``compression_level`` and ``mem_level``.\n#         \"\"\"\n#         # TODO: Add wbits option.\n#         return None\n# \n#     def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n#         \"\"\"Invoked when a new WebSocket is opened.\n# \n#         The arguments to `open` are extracted from the `tornado.web.URLSpec`\n#         regular expression, just like the arguments to\n#         `tornado.web.RequestHandler.get`.\n# \n#         `open` may be a coroutine. `on_message` will not be called until\n#         `open` has returned.\n# \n#         .. versionchanged:: 5.1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         pass\n# \n#     def set_status(self, status_code: int, reason: Optional[str] = None) -> None:\n#         \"\"\"Sets the status code for our response.\n# \n#         :arg int status_code: Response status code.\n#         :arg str reason: Human-readable reason phrase describing the status\n#             code. If ``None``, it will be filled in from\n#             `http.client.responses` or \"Unknown\".\n# \n#         .. versionchanged:: 5.0\n# \n#            No longer validates that the response code is in\n#            `http.client.responses`.\n#         \"\"\"\n#         self._status_code = status_code\n#         if reason is not None:\n#             self._reason = escape.native_str(reason)\n#         else:\n#             self._reason = httputil.responses.get(status_code, \"Unknown\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def get_body_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request body.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.body_arguments, strip)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker],\n#         source: Dict[str, List[bytes]],\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         args = self._get_arguments(name, source, strip=strip)\n#         if not args:\n#             if isinstance(default, _ArgDefaultMarker):\n#                 raise MissingArgumentError(name)\n#             return default\n#         return args[-1]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the body arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.body_arguments, strip)\n# \n#     def get_query_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request query string.\n# \n#         If default is not provided, the argument is considered to be\n#         required, and we raise a `MissingArgumentError` if it is missing.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#     .. versionchanged:: 5.0\n#        The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n#     \"\"\"\n# \n#     def __init__(self, resolver: Optional[Resolver] = None) -> None:\n#         if resolver is not None:\n#             self.resolver = resolver\n#             self._own_resolver = False\n#         else:\n#             self.resolver = Resolver()\n#             self._own_resolver = True\n# \n#     def close(self) -> None:\n#         if self._own_resolver:\n#             self.resolver.close()\n# \n#     async def connect(\n#         self,\n#         host: str,\n#         port: int,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# testing.py\n# --------------------------------------------------\n# \n# def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n#     \"\"\"Binds a server socket to an available port on localhost.\n# \n#     Returns a tuple (socket, port).\n# \n#     .. versionchanged:: 4.4\n#        Always binds to ``127.0.0.1`` without resolving the name\n#        ``localhost``.\n#     \"\"\"\n#     sock = netutil.bind_sockets(\n#         0, \"127.0.0.1\", family=socket.AF_INET, reuse_port=reuse_port\n#     )[0]\n#     port = sock.getsockname()[1]\n#     return sock, port\n# \n# \n# def get_async_test_timeout() -> float:\n#     \"\"\"Get the global timeout setting for async tests.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# testing.py\n# --------------------------------------------------\n#     # when mypy is running and use forward references.\n#     from typing import Coroutine  # noqa: F401\n# \n#     _ExcInfoTuple = Tuple[\n#         Optional[Type[BaseException]], Optional[BaseException], Optional[TracebackType]\n#     ]\n# \n# \n# _NON_OWNED_IOLOOPS = AsyncIOMainLoop\n# \n# \n# def bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n#     \"\"\"Binds a server socket to an available port on localhost.\n# \n#     Returns a tuple (socket, port).\n# \n#     .. versionchanged:: 4.4\n#        Always binds to ``127.0.0.1`` without resolving the name\n#        ``localhost``.\n#     \"\"\"\n# --------------------------------------------------\n\ndef split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n", "metadata": {"task_id": "tornado/id40", "ground_truth": "def split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "split_host_and_port", "lineno": 0, "context_start_lineno": 0, "_id": 40, "query_window": {"context": "from typing import Tuple, Optional\ndef split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n    Returned ``port`` will be ``None`` if not present.\n    .. versionadded:: 4.1\n    \"\"\"\n    if ':' in netloc:\n        host, port_str = netloc.rsplit(':', 1)  # Split from the right\n        return host, int(port_str)  # Convert port to an integer\n    else:", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Tuple, Optional\n\ndef split_host_and_port(netloc: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Returns ``(host, port)`` tuple from ``netloc``.\n\n    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    if ':' in netloc:\n        host, port_str = netloc.rsplit(':', 1)  # Split from the right\n        return host, int(port_str)  # Convert port to an integer\n    else:\n        return netloc, None  # No port, return None", "task_id": "tornado/id40", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    # when mypy is running and use forward references.\n    from typing import Coroutine  # noqa: F401\n\n    _ExcInfoTuple = Tuple[\n        Optional[Type[BaseException]], Optional[BaseException], Optional[TracebackType]\n    ]\n\n\n_NON_OWNED_IOLOOPS = AsyncIOMainLoop\n\n\ndef bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n       Always binds to ``127.0.0.1`` without resolving the name\n       ``localhost``.\n    \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "testing.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2671232876712329}, {"context": "\ndef bind_unused_port(reuse_port: bool = False) -> Tuple[socket.socket, int]:\n    \"\"\"Binds a server socket to an available port on localhost.\n\n    Returns a tuple (socket, port).\n\n    .. versionchanged:: 4.4\n       Always binds to ``127.0.0.1`` without resolving the name\n       ``localhost``.\n    \"\"\"\n    sock = netutil.bind_sockets(\n        0, \"127.0.0.1\", family=socket.AF_INET, reuse_port=reuse_port\n    )[0]\n    port = sock.getsockname()[1]\n    return sock, port\n\n\ndef get_async_test_timeout() -> float:\n    \"\"\"Get the global timeout setting for async tests.\n", "metadata": [{"fpath_tuple": ["tornado", "testing.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25547445255474455}, {"context": "    .. versionchanged:: 5.0\n       The ``io_loop`` argument (deprecated since version 4.1) has been removed.\n    \"\"\"\n\n    def __init__(self, resolver: Optional[Resolver] = None) -> None:\n        if resolver is not None:\n            self.resolver = resolver\n            self._own_resolver = False\n        else:\n            self.resolver = Resolver()\n            self._own_resolver = True\n\n    def close(self) -> None:\n        if self._own_resolver:\n            self.resolver.close()\n\n    async def connect(\n        self,\n        host: str,\n        port: int,", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2543859649122807}, {"context": "    def get_body_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the body arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.body_arguments, strip)\n\n    def get_query_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request query string.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24087591240875914}, {"context": "\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker],\n        source: Dict[str, List[bytes]],\n        strip: bool = True,\n    ) -> Optional[str]:\n        args = self._get_arguments(name, source, strip=strip)\n        if not args:\n            if isinstance(default, _ArgDefaultMarker):\n                raise MissingArgumentError(name)\n            return default\n        return args[-1]", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24}, {"context": "\n    def get_body_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n\n        If default is not provided, the argument is considered to be\n        required, and we raise a `MissingArgumentError` if it is missing.\n\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.body_arguments, strip)\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23880597014925373}, {"context": "        pass\n\n    def set_status(self, status_code: int, reason: Optional[str] = None) -> None:\n        \"\"\"Sets the status code for our response.\n\n        :arg int status_code: Response status code.\n        :arg str reason: Human-readable reason phrase describing the status\n            code. If ``None``, it will be filled in from\n            `http.client.responses` or \"Unknown\".\n\n        .. versionchanged:: 5.0\n\n           No longer validates that the response code is in\n           `http.client.responses`.\n        \"\"\"\n        self._status_code = status_code\n        if reason is not None:\n            self._reason = escape.native_str(reason)\n        else:\n            self._reason = httputil.responses.get(status_code, \"Unknown\")", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23880597014925373}, {"context": "        .. versionadded:: 4.1\n\n        .. versionchanged:: 4.5\n\n           Added ``compression_level`` and ``mem_level``.\n        \"\"\"\n        # TODO: Add wbits option.\n        return None\n\n    def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n        \"\"\"Invoked when a new WebSocket is opened.\n\n        The arguments to `open` are extracted from the `tornado.web.URLSpec`\n        regular expression, just like the arguments to\n        `tornado.web.RequestHandler.get`.\n\n        `open` may be a coroutine. `on_message` will not be called until\n        `open` has returned.\n\n        .. versionchanged:: 5.1", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23404255319148937}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# \n#             from tornado.options import define, parse_command_line, options\n# \n#             define('template_path', group='application')\n#             define('static_path', group='application')\n# \n#             parse_command_line()\n# \n#             application = Application(\n#                 handlers, **options.group_dict('application'))\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return dict(\n#             (opt.name, opt.value())\n#             for name, opt in self._options.items()\n#             if not group or group == opt.group_name\n#         )\n# \n#     def as_dict(self) -> Dict[str, Any]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n# \n# def future_set_result_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n# ) -> None:\n#     \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n# \n#     Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n#     a cancelled `asyncio.Future`.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if not future.cancelled():\n#         future.set_result(value)\n# \n# \n# def future_set_exception_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n# ) -> None:\n#     \"\"\"Set the given ``exc`` as the `Future`'s exception.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         \"\"\"The names and values of all options.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return dict((opt.name, opt.value()) for name, opt in self._options.items())\n# \n#     def define(\n#         self,\n#         name: str,\n#         default: Any = None,\n#         type: Optional[type] = None,\n#         help: Optional[str] = None,\n#         metavar: Optional[str] = None,\n#         multiple: bool = False,\n#         group: Optional[str] = None,\n#         callback: Optional[Callable[[Any], None]] = None,\n#     ) -> None:\n#         \"\"\"Defines a new command line option.\n# \n#         ``type`` can be any of `str`, `int`, `float`, `bool`,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# \n#             from tornado.options import define, parse_command_line, options\n# \n#             define('template_path', group='application')\n#             define('static_path', group='application')\n# \n#             parse_command_line()\n# \n#             application = Application(\n#                 handlers, **options.group_dict('application'))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n#         return urllib.parse.unquote_to_bytes(value)\n#     else:\n#         unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n#         return unquote(to_basestring(value), encoding=encoding)\n# \n# \n# def parse_qs_bytes(\n#     qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n# ) -> Dict[str, List[bytes]]:\n#     \"\"\"Parses a query string like urlparse.parse_qs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return dict(\n#             (opt.name, opt.value())\n#             for name, opt in self._options.items()\n#             if not group or group == opt.group_name\n#         )\n# \n#     def as_dict(self) -> Dict[str, Any]:\n#         \"\"\"The names and values of all options.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return dict((opt.name, opt.value()) for name, opt in self._options.items())\n# \n#     def define(\n#         self,\n#         name: str,\n#         default: Any = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         return (opt.name for opt in self._options.values())\n# \n#     def __contains__(self, name: str) -> bool:\n#         name = self._normalize_name(name)\n#         return name in self._options\n# \n#     def __getitem__(self, name: str) -> Any:\n#         return self.__getattr__(name)\n# \n#     def __setitem__(self, name: str, value: Any) -> None:\n#         return self.__setattr__(name, value)\n# \n#     def items(self) -> Iterable[Tuple[str, Any]]:\n#         \"\"\"An iterable of (name, value) pairs.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return [(opt.name, opt.value()) for name, opt in self._options.items()]\n# \n#     def groups(self) -> Set[str]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         return self.__setattr__(name, value)\n# \n#     def items(self) -> Iterable[Tuple[str, Any]]:\n#         \"\"\"An iterable of (name, value) pairs.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return [(opt.name, opt.value()) for name, opt in self._options.items()]\n# \n#     def groups(self) -> Set[str]:\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# --------------------------------------------------\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n", "metadata": {"task_id": "tornado/id41", "ground_truth": "def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():\n        for v in vs:\n            yield (k, v)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "qs_to_qsl", "lineno": 0, "context_start_lineno": 0, "_id": 41, "query_window": {"context": "from typing import Dict, List, AnyStr, Iterable, Tuple\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n    .. versionadded:: 5.0\n    \"\"\"\n    for key, values in qs.items():\n        for value in values:\n            yield (key, value)", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Dict, List, AnyStr, Iterable, Tuple\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for key, values in qs.items():\n        for value in values:\n            yield (key, value)", "task_id": "tornado/id41", "start_line_no": 0, "end_line_no": 8, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        return self.__setattr__(name, value)\n\n    def items(self) -> Iterable[Tuple[str, Any]]:\n        \"\"\"An iterable of (name, value) pairs.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return [(opt.name, opt.value()) for name, opt in self._options.items()]\n\n    def groups(self) -> Set[str]:\n        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.35714285714285715}, {"context": "        return (opt.name for opt in self._options.values())\n\n    def __contains__(self, name: str) -> bool:\n        name = self._normalize_name(name)\n        return name in self._options\n\n    def __getitem__(self, name: str) -> Any:\n        return self.__getattr__(name)\n\n    def __setitem__(self, name: str, value: Any) -> None:\n        return self.__setattr__(name, value)\n\n    def items(self) -> Iterable[Tuple[str, Any]]:\n        \"\"\"An iterable of (name, value) pairs.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return [(opt.name, opt.value()) for name, opt in self._options.items()]\n\n    def groups(self) -> Set[str]:", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.3173076923076923}, {"context": "\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict(\n            (opt.name, opt.value())\n            for name, opt in self._options.items()\n            if not group or group == opt.group_name\n        )\n\n    def as_dict(self) -> Dict[str, Any]:\n        \"\"\"The names and values of all options.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict((opt.name, opt.value()) for name, opt in self._options.items())\n\n    def define(\n        self,\n        name: str,\n        default: Any = None,", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.28846153846153844}, {"context": "    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)\n\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2605633802816901}, {"context": "        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::\n\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.25}, {"context": "        \"\"\"The names and values of all options.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict((opt.name, opt.value()) for name, opt in self._options.items())\n\n    def define(\n        self,\n        name: str,\n        default: Any = None,\n        type: Optional[type] = None,\n        help: Optional[str] = None,\n        metavar: Optional[str] = None,\n        multiple: bool = False,\n        group: Optional[str] = None,\n        callback: Optional[Callable[[Any], None]] = None,\n    ) -> None:\n        \"\"\"Defines a new command line option.\n\n        ``type`` can be any of `str`, `int`, `float`, `bool`,", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24390243902439024}, {"context": "\n\ndef future_set_result_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n) -> None:\n    \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if not future.cancelled():\n        future.set_result(value)\n\n\ndef future_set_exception_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n) -> None:\n    \"\"\"Set the given ``exc`` as the `Future`'s exception.", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24369747899159663}, {"context": "\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict(\n            (opt.name, opt.value())\n            for name, opt in self._options.items()\n            if not group or group == opt.group_name\n        )\n\n    def as_dict(self) -> Dict[str, Any]:", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2413793103448276}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httpserver.py\n# --------------------------------------------------\n#         if proto_header in (\"http\", \"https\"):\n#             self.protocol = proto_header\n# \n#     def _unapply_xheaders(self) -> None:\n#         \"\"\"Undo changes from `_apply_xheaders`.\n# \n#         Xheaders are per-request so they should not leak to the next\n#         request on the same connection.\n#         \"\"\"\n#         self.remote_ip = self._orig_remote_ip\n#         self.protocol = self._orig_protocol\n# \n# \n# class _ProxyAdapter(httputil.HTTPMessageDelegate):\n#     def __init__(\n#         self,\n#         delegate: httputil.HTTPMessageDelegate,\n#         request_conn: httputil.HTTPConnection,\n#     ) -> None:\n#         self.connection = request_conn\n# --------------------------------------------------\n# the below code fragment can be found in:\n# simple_httpclient.py\n# --------------------------------------------------\n#             if self.request.expect_100_continue:\n#                 await self.connection.read_response(self)\n#             else:\n#                 await self._write_body(True)\n#         except Exception:\n#             if not self._handle_exception(*sys.exc_info()):\n#                 raise\n# \n#     def _get_ssl_options(\n#         self, scheme: str\n#     ) -> Union[None, Dict[str, Any], ssl.SSLContext]:\n#         if scheme == \"https\":\n#             if self.request.ssl_options is not None:\n#                 return self.request.ssl_options\n#             # If we are using the defaults, don't construct a\n#             # new SSLContext.\n#             if (\n#                 self.request.validate_cert\n#                 and self.request.ca_certs is None\n#                 and self.request.client_cert is None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#                       self.current_user = yield load_user(user_id_cookie)\n# \n#         Note that `prepare()` may be a coroutine while `get_current_user()`\n#         may not, so the latter form is necessary if loading the user requires\n#         asynchronous operations.\n# \n#         The user object may be any type of the application's choosing.\n#         \"\"\"\n#         if not hasattr(self, \"_current_user\"):\n#             self._current_user = self.get_current_user()\n#         return self._current_user\n# \n#     @current_user.setter\n#     def current_user(self, value: Any) -> None:\n#         self._current_user = value\n# \n#     def get_current_user(self) -> Any:\n#         \"\"\"Override to determine the current user from, e.g., a cookie.\n# \n#         This method may not be a coroutine.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# locale.py\n# --------------------------------------------------\n#        Added ``encoding`` parameter. Added support for BOM-based encoding\n#        detection, UTF-16, and UTF-8-with-BOM.\n#     \"\"\"\n#     global _translations\n#     global _supported_locales\n#     _translations = {}\n#     for path in os.listdir(directory):\n#         if not path.endswith(\".csv\"):\n#             continue\n#         locale, extension = path.split(\".\")\n#         if not re.match(\"[a-z]+(_[A-Z]+)?$\", locale):\n#             gen_log.error(\n#                 \"Unrecognized locale %r (path: %s)\",\n#                 locale,\n#                 os.path.join(directory, path),\n#             )\n#             continue\n#         full_path = os.path.join(directory, path)\n#         if encoding is None:\n#             # Try to autodetect encoding based on the BOM.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         This method searches both the query and body arguments.\n#         \"\"\"\n# \n#         # Make sure `get_arguments` isn't accidentally being called with a\n#         # positional argument that's assumed to be a default (like in\n#         # `get_argument`.)\n#         assert isinstance(strip, bool)\n# \n#         return self._get_arguments(name, self.request.arguments, strip)\n# \n#     def get_body_argument(\n#         self,\n#         name: str,\n#         default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n#         strip: bool = True,\n#     ) -> Optional[str]:\n#         \"\"\"Returns the value of the argument with the given name\n#         from the request body.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"Decodes the given value from a URL.\n# \n#     The argument may be either a byte or unicode string.\n# \n#     If encoding is None, the result will be a byte string.  Otherwise,\n#     the result is a unicode string in the specified encoding.\n# \n#     If ``plus`` is true (the default), plus signs will be interpreted\n#     as spaces (literal plus signs must be represented as \"%2B\").  This\n#     is appropriate for query strings and form-encoded values but not\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#                     url = url[:amp]\n#                 url += \"...\"\n# \n#                 if len(url) >= len(before_clip):\n#                     url = before_clip\n#                 else:\n#                     # full url is visible on mouse-over (for those who don't\n#                     # have a status bar, such as Safari by default)\n#                     params += ' title=\"%s\"' % href\n# \n#         return u'<a href=\"%s\"%s>%s</a>' % (href, params, url)\n# \n#     # First HTML-escape so that our strings are all safe.\n#     # The regex is modified to avoid character entites other than &amp; so\n#     # that we won't pick up &quot;, etc.\n#     text = _unicode(xhtml_escape(text))\n#     return _URL_RE.sub(make_link, text)\n# \n# \n# def _convert_entity(m: typing.Match) -> str:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# routing.py\n# --------------------------------------------------\n# \n# \n# @overload  # noqa: F811\n# def _unquote_or_none(s: None) -> None:\n#     pass\n# \n# \n# def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n#     \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n#     groups correctly.\n# \n#     Note that args are passed as bytes so the handler can decide what\n#     encoding to use.\n#     \"\"\"\n#     if s is None:\n#         return s\n#     return url_unescape(s, encoding=None, plus=False)\n# --------------------------------------------------\n\ndef _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id42", "ground_truth": "def _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n    # If there aren't any doublequotes,\n    # then there can't be any special characters.  See RFC 2109.\n    if s is None or len(s) < 2:\n        return s\n    if s[0] != '\"' or s[-1] != '\"':\n        return s\n\n    # We have to assume that we must decode this string.\n    # Down to work.\n\n    # Remove the \"s\n    s = s[1:-1]\n\n    # Check for special sequences.  Examples:\n    #    \\012 --> \\n\n    #    \\\"   --> \"\n    #\n    i = 0\n    n = len(s)\n    res = []\n    while 0 <= i < n:\n        o_match = _OctalPatt.search(s, i)\n        q_match = _QuotePatt.search(s, i)\n        if not o_match and not q_match:  # Neither matched\n            res.append(s[i:])\n            break\n        # else:\n        j = k = -1\n        if o_match:\n            j = o_match.start(0)\n        if q_match:\n            k = q_match.start(0)\n        if q_match and (not o_match or k < j):  # QuotePatt matched\n            res.append(s[i:k])\n            res.append(s[k + 1])\n            i = k + 2\n        else:  # OctalPatt matched\n            res.append(s[i:j])\n            res.append(chr(int(s[j + 1 : j + 4], 8)))\n            i = j + 4\n    return _nulljoin(res)", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "_unquote_cookie", "lineno": 0, "context_start_lineno": 0, "_id": 42, "query_window": {"context": "import re\ndef _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n    # Use a regular expression to handle unquoting\n    if s.startswith('\"') and s.endswith('\"'):\n        # Remove surrounding double quotes", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "import re\n\ndef _unquote_cookie(s: str) -> str:\n    \"\"\"Handle double quotes and escaping in cookie values.\n\n    This method is copied verbatim from the Python 3.5 standard\n    library (http.cookies._unquote) so we don't have to depend on\n    non-public interfaces.\n    \"\"\"\n    # Use a regular expression to handle unquoting\n    if s.startswith('\"') and s.endswith('\"'):\n        # Remove surrounding double quotes\n        s = s[1:-1]\n    \n    # Unescape any escaped characters\n    # Note: In cookie values, the only character that can be escaped\n    # is the double quote itself with a backslash\n    return re.sub(r'\\\\(.)', r'\\1', s)", "task_id": "tornado/id42", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "\n\n@overload  # noqa: F811\ndef _unquote_or_none(s: None) -> None:\n    pass\n\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "metadata": [{"fpath_tuple": ["tornado", "routing.py"], "line_no": 710, "start_line_no": 700, "end_line_no": 717, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1875}, {"context": "                    url = url[:amp]\n                url += \"...\"\n\n                if len(url) >= len(before_clip):\n                    url = before_clip\n                else:\n                    # full url is visible on mouse-over (for those who don't\n                    # have a status bar, such as Safari by default)\n                    params += ' title=\"%s\"' % href\n\n        return u'<a href=\"%s\"%s>%s</a>' % (href, params, url)\n\n    # First HTML-escape so that our strings are all safe.\n    # The regex is modified to avoid character entites other than &amp; so\n    # that we won't pick up &quot;, etc.\n    text = _unicode(xhtml_escape(text))\n    return _URL_RE.sub(make_link, text)\n\n\ndef _convert_entity(m: typing.Match) -> str:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17543859649122806}, {"context": "    \"\"\"Decodes the given value from a URL.\n\n    The argument may be either a byte or unicode string.\n\n    If encoding is None, the result will be a byte string.  Otherwise,\n    the result is a unicode string in the specified encoding.\n\n    If ``plus`` is true (the default), plus signs will be interpreted\n    as spaces (literal plus signs must be represented as \"%2B\").  This\n    is appropriate for query strings and form-encoded values but not\n    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17261904761904762}, {"context": "\n        This method searches both the query and body arguments.\n        \"\"\"\n\n        # Make sure `get_arguments` isn't accidentally being called with a\n        # positional argument that's assumed to be a default (like in\n        # `get_argument`.)\n        assert isinstance(strip, bool)\n\n        return self._get_arguments(name, self.request.arguments, strip)\n\n    def get_body_argument(\n        self,\n        name: str,\n        default: Union[None, str, _ArgDefaultMarker] = _ARG_DEFAULT,\n        strip: bool = True,\n    ) -> Optional[str]:\n        \"\"\"Returns the value of the argument with the given name\n        from the request body.\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1724137931034483}, {"context": "       Added ``encoding`` parameter. Added support for BOM-based encoding\n       detection, UTF-16, and UTF-8-with-BOM.\n    \"\"\"\n    global _translations\n    global _supported_locales\n    _translations = {}\n    for path in os.listdir(directory):\n        if not path.endswith(\".csv\"):\n            continue\n        locale, extension = path.split(\".\")\n        if not re.match(\"[a-z]+(_[A-Z]+)?$\", locale):\n            gen_log.error(\n                \"Unrecognized locale %r (path: %s)\",\n                locale,\n                os.path.join(directory, path),\n            )\n            continue\n        full_path = os.path.join(directory, path)\n        if encoding is None:\n            # Try to autodetect encoding based on the BOM.", "metadata": [{"fpath_tuple": ["tornado", "locale.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17197452229299362}, {"context": "                      self.current_user = yield load_user(user_id_cookie)\n\n        Note that `prepare()` may be a coroutine while `get_current_user()`\n        may not, so the latter form is necessary if loading the user requires\n        asynchronous operations.\n\n        The user object may be any type of the application's choosing.\n        \"\"\"\n        if not hasattr(self, \"_current_user\"):\n            self._current_user = self.get_current_user()\n        return self._current_user\n\n    @current_user.setter\n    def current_user(self, value: Any) -> None:\n        self._current_user = value\n\n    def get_current_user(self) -> Any:\n        \"\"\"Override to determine the current user from, e.g., a cookie.\n\n        This method may not be a coroutine.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1340, "start_line_no": 1330, "end_line_no": 1350, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17142857142857143}, {"context": "            if self.request.expect_100_continue:\n                await self.connection.read_response(self)\n            else:\n                await self._write_body(True)\n        except Exception:\n            if not self._handle_exception(*sys.exc_info()):\n                raise\n\n    def _get_ssl_options(\n        self, scheme: str\n    ) -> Union[None, Dict[str, Any], ssl.SSLContext]:\n        if scheme == \"https\":\n            if self.request.ssl_options is not None:\n                return self.request.ssl_options\n            # If we are using the defaults, don't construct a\n            # new SSLContext.\n            if (\n                self.request.validate_cert\n                and self.request.ca_certs is None\n                and self.request.client_cert is None", "metadata": [{"fpath_tuple": ["tornado", "simple_httpclient.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17123287671232876}, {"context": "        if proto_header in (\"http\", \"https\"):\n            self.protocol = proto_header\n\n    def _unapply_xheaders(self) -> None:\n        \"\"\"Undo changes from `_apply_xheaders`.\n\n        Xheaders are per-request so they should not leak to the next\n        request on the same connection.\n        \"\"\"\n        self.remote_ip = self._orig_remote_ip\n        self.protocol = self._orig_protocol\n\n\nclass _ProxyAdapter(httputil.HTTPMessageDelegate):\n    def __init__(\n        self,\n        delegate: httputil.HTTPMessageDelegate,\n        request_conn: httputil.HTTPConnection,\n    ) -> None:\n        self.connection = request_conn", "metadata": [{"fpath_tuple": ["tornado", "httpserver.py"], "line_no": 360, "start_line_no": 350, "end_line_no": 370, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1702127659574468}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return dict(\n#             (opt.name, opt.value())\n#             for name, opt in self._options.items()\n#             if not group or group == opt.group_name\n#         )\n# \n#     def as_dict(self) -> Dict[str, Any]:\n#         \"\"\"The names and values of all options.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return dict((opt.name, opt.value()) for name, opt in self._options.items())\n# \n#     def define(\n#         self,\n#         name: str,\n#         default: Any = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         # not generally be used by application code.\n# \n#         # .. versionadded:: 4.0\n#         # \"\"\"\n#         if isinstance(fd, int):\n#             return fd, fd\n#         return fd.fileno(), fd\n# \n#     def close_fd(self, fd: Union[int, _Selectable]) -> None:\n#         # \"\"\"Utility method to close an ``fd``.\n# \n#         # If ``fd`` is a file-like object, we close it directly; otherwise\n#         # we use `os.close`.\n# \n#         # This method is provided for use by `IOLoop` subclasses (in\n#         # implementations of ``IOLoop.close(all_fds=True)`` and should\n#         # not generally be used by application code.\n# \n#         # .. versionadded:: 4.0\n#         # \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def write_message(\n#         self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n#     ) -> \"Future[None]\":\n#         \"\"\"Sends the given message to the client of this Web Socket.\n# \n#         The message may be either a string or a dict (which will be\n#         encoded as json).  If the ``binary`` argument is false, the\n#         message will be sent as utf8; in binary mode any byte string\n#         is allowed.\n# \n#         If the connection is already closed, raises `WebSocketClosedError`.\n#         Returns a `.Future` which can be used for flow control.\n# \n#         .. versionchanged:: 3.2\n#            `WebSocketClosedError` was added (previously a closed connection\n#            would raise an `AttributeError`)\n# \n#         .. versionchanged:: 4.3\n#            Returns a `.Future` which can be used for flow control.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         return self.request.cookies\n# \n#     def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n#         \"\"\"Returns the value of the request cookie with the given name.\n# \n#         If the named cookie is not present, returns ``default``.\n# \n#         This method only returns cookies that were present in the request.\n#         It does not see the outgoing cookies set by `set_cookie` in this\n#         handler.\n#         \"\"\"\n#         if self.request.cookies is not None and name in self.request.cookies:\n#             return self.request.cookies[name].value\n#         return default\n# \n#     def set_cookie(\n#         self,\n#         name: str,\n#         value: Union[str, bytes],\n#         domain: Optional[str] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n#         return urllib.parse.unquote_to_bytes(value)\n#     else:\n#         unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n#         return unquote(to_basestring(value), encoding=encoding)\n# \n# \n# def parse_qs_bytes(\n#     qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n# ) -> Dict[str, List[bytes]]:\n#     \"\"\"Parses a query string like urlparse.parse_qs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def parse_url_path(self, url_path: str) -> str:\n#         \"\"\"Converts a static URL path into a filesystem path.\n# \n#         ``url_path`` is the path component of the URL with\n#         ``static_url_prefix`` removed.  The return value should be\n#         filesystem path relative to ``static_path``.\n# \n#         This is the inverse of `make_static_url`.\n#         \"\"\"\n#         if os.path.sep != \"/\":\n#             url_path = url_path.replace(\"/\", os.path.sep)\n#         return url_path\n# \n#     @classmethod\n#     def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n#         \"\"\"Generate the version string to be used in static URLs.\n# \n#         ``settings`` is the `Application.settings` dictionary and ``path``\n#         is the relative location of the requested asset on the filesystem.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         return self.__setattr__(name, value)\n# \n#     def items(self) -> Iterable[Tuple[str, Any]]:\n#         \"\"\"An iterable of (name, value) pairs.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return [(opt.name, opt.value()) for name, opt in self._options.items()]\n# \n#     def groups(self) -> Set[str]:\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         self,\n#         name: str,\n#         value: Optional[str] = None,\n#         max_age_days: float = 31,\n#         min_version: Optional[int] = None,\n#     ) -> Optional[bytes]:\n#         \"\"\"Returns the given signed cookie if it validates, or None.\n# \n#         The decoded cookie value is returned as a byte string (unlike\n#         `get_cookie`).\n# \n#         Similar to `get_cookie`, this method only returns cookies that\n#         were present in the request. It does not see outgoing cookies set by\n#         `set_secure_cookie` in this handler.\n# \n#         .. versionchanged:: 3.2.1\n# \n#            Added the ``min_version`` argument.  Introduced cookie version 2;\n#            both versions 1 and 2 are accepted by default.\n#         \"\"\"\n# --------------------------------------------------\n\ndef parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n", "metadata": {"task_id": "tornado/id43", "ground_truth": "def parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n    cookiedict = {}\n    for chunk in cookie.split(str(\";\")):\n        if str(\"=\") in chunk:\n            key, val = chunk.split(str(\"=\"), 1)\n        else:\n            # Assume an empty name per\n            # https://bugzilla.mozilla.org/show_bug.cgi?id=169091\n            key, val = str(\"\"), chunk\n        key, val = key.strip(), val.strip()\n        if key or val:\n            # unquote using Python's algorithm.\n            cookiedict[key] = _unquote_cookie(val)\n    return cookiedict", "fpath_tuple": ["tornado", "httputil.py"], "function_name": "parse_cookie", "lineno": 0, "context_start_lineno": 0, "_id": 43, "query_window": {"context": "from typing import Dict\ndef parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n    The algorithm used is identical to that used by Django version 1.9.10.\n    .. versionadded:: 4.4.2\n    \"\"\"\n    # Prepare a dictionary to hold the parsed cookies", "metadata": {"fpath_tuple": ["tornado", "httputil.py"], "line_no": 0, "prediction": "from typing import Dict\n\ndef parse_cookie(cookie: str) -> Dict[str, str]:\n    \"\"\"Parse a ``Cookie`` HTTP header into a dict of name/value pairs.\n\n    This function attempts to mimic browser cookie parsing behavior;\n    it specifically does not follow any of the cookie-related RFCs\n    (because browsers don't either).\n\n    The algorithm used is identical to that used by Django version 1.9.10.\n\n    .. versionadded:: 4.4.2\n    \"\"\"\n    # Prepare a dictionary to hold the parsed cookies\n    cookies = {}\n    \n    # Split the cookie string by semicolon to get individual name-value pairs\n    for morsel in cookie.split(';'):\n        # Further split each morsel into name and value\n        key_value = morsel.split('=', 1)  # Split only on the first `=`\n        \n        if len(key_value) == 2:\n            key = key_value[0].strip()\n            value = key_value[1].strip().strip('\"')  # Remove surrounding whitespace and quotes\n            cookies[key] = value\n    \n    return cookies", "task_id": "tornado/id43", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        self,\n        name: str,\n        value: Optional[str] = None,\n        max_age_days: float = 31,\n        min_version: Optional[int] = None,\n    ) -> Optional[bytes]:\n        \"\"\"Returns the given signed cookie if it validates, or None.\n\n        The decoded cookie value is returned as a byte string (unlike\n        `get_cookie`).\n\n        Similar to `get_cookie`, this method only returns cookies that\n        were present in the request. It does not see outgoing cookies set by\n        `set_secure_cookie` in this handler.\n\n        .. versionchanged:: 3.2.1\n\n           Added the ``min_version`` argument.  Introduced cookie version 2;\n           both versions 1 and 2 are accepted by default.\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 760, "start_line_no": 750, "end_line_no": 770, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22641509433962265}, {"context": "        return self.__setattr__(name, value)\n\n    def items(self) -> Iterable[Tuple[str, Any]]:\n        \"\"\"An iterable of (name, value) pairs.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return [(opt.name, opt.value()) for name, opt in self._options.items()]\n\n    def groups(self) -> Set[str]:\n        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21830985915492956}, {"context": "\n    def parse_url_path(self, url_path: str) -> str:\n        \"\"\"Converts a static URL path into a filesystem path.\n\n        ``url_path`` is the path component of the URL with\n        ``static_url_prefix`` removed.  The return value should be\n        filesystem path relative to ``static_path``.\n\n        This is the inverse of `make_static_url`.\n        \"\"\"\n        if os.path.sep != \"/\":\n            url_path = url_path.replace(\"/\", os.path.sep)\n        return url_path\n\n    @classmethod\n    def get_version(cls, settings: Dict[str, Any], path: str) -> Optional[str]:\n        \"\"\"Generate the version string to be used in static URLs.\n\n        ``settings`` is the `Application.settings` dictionary and ``path``\n        is the relative location of the requested asset on the filesystem.", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2960, "start_line_no": 2950, "end_line_no": 2970, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21710526315789475}, {"context": "    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)\n\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21212121212121213}, {"context": "        return self.request.cookies\n\n    def get_cookie(self, name: str, default: Optional[str] = None) -> Optional[str]:\n        \"\"\"Returns the value of the request cookie with the given name.\n\n        If the named cookie is not present, returns ``default``.\n\n        This method only returns cookies that were present in the request.\n        It does not see the outgoing cookies set by `set_cookie` in this\n        handler.\n        \"\"\"\n        if self.request.cookies is not None and name in self.request.cookies:\n            return self.request.cookies[name].value\n        return default\n\n    def set_cookie(\n        self,\n        name: str,\n        value: Union[str, bytes],\n        domain: Optional[str] = None,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2116788321167883}, {"context": "\n    def write_message(\n        self, message: Union[bytes, str, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        \"\"\"Sends the given message to the client of this Web Socket.\n\n        The message may be either a string or a dict (which will be\n        encoded as json).  If the ``binary`` argument is false, the\n        message will be sent as utf8; in binary mode any byte string\n        is allowed.\n\n        If the connection is already closed, raises `WebSocketClosedError`.\n        Returns a `.Future` which can be used for flow control.\n\n        .. versionchanged:: 3.2\n           `WebSocketClosedError` was added (previously a closed connection\n           would raise an `AttributeError`)\n\n        .. versionchanged:: 4.3\n           Returns a `.Future` which can be used for flow control.", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20588235294117646}, {"context": "        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        if isinstance(fd, int):\n            return fd, fd\n        return fd.fileno(), fd\n\n    def close_fd(self, fd: Union[int, _Selectable]) -> None:\n        # \"\"\"Utility method to close an ``fd``.\n\n        # If ``fd`` is a file-like object, we close it directly; otherwise\n        # we use `os.close`.\n\n        # This method is provided for use by `IOLoop` subclasses (in\n        # implementations of ``IOLoop.close(all_fds=True)`` and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 790, "start_line_no": 780, "end_line_no": 800, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20394736842105263}, {"context": "\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict(\n            (opt.name, opt.value())\n            for name, opt in self._options.items()\n            if not group or group == opt.group_name\n        )\n\n    def as_dict(self) -> Dict[str, Any]:\n        \"\"\"The names and values of all options.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return dict((opt.name, opt.value()) for name, opt in self._options.items())\n\n    def define(\n        self,\n        name: str,\n        default: Any = None,", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20155038759689922}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/util_test.py\n# --------------------------------------------------\n# from io import StringIO\n# import re\n# import sys\n# import datetime\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import utf8\n# from tornado.util import (\n#     raise_exc_info,\n#     Configurable,\n#     exec_in,\n#     ArgReplacer,\n#     timedelta_to_seconds,\n#     import_object,\n#     re_unescape,\n#     is_finalizing,\n# )\n# \n# import typing\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     Iterator,\n#     Dict,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Generator,\n#     AnyStr,\n# )\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Deque  # noqa: F401\n#     from asyncio import Future  # noqa: F401\n#     import unittest  # noqa: F401\n# \n# \n# @lru_cache(1000)\n# def _normalize_header(name: str) -> str:\n#     \"\"\"Map a header name to Http-Header-Case.\n# \n#     >>> _normalize_header(\"coNtent-TYPE\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n#         \"\"\"The set of option-groups created by ``define``.\n# \n#         .. versionadded:: 3.1\n#         \"\"\"\n#         return set(opt.group_name for opt in self._options.values())\n# \n#     def group_dict(self, group: str) -> Dict[str, Any]:\n#         \"\"\"The names and values of options in a group.\n# \n#         Useful for copying options into Application settings::\n# \n#             from tornado.options import define, parse_command_line, options\n# \n#             define('template_path', group='application')\n#             define('static_path', group='application')\n# \n#             parse_command_line()\n# \n#             application = Application(\n#                 handlers, **options.group_dict('application'))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# http1connection.py\n# --------------------------------------------------\n# from tornado.escape import native_str, utf8\n# from tornado import gen\n# from tornado import httputil\n# from tornado import iostream\n# from tornado.log import gen_log, app_log\n# from tornado.util import GzipDecompressor\n# \n# \n# from typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple\n# \n# \n# class _QuietException(Exception):\n#     def __init__(self) -> None:\n#         pass\n# \n# \n# class _ExceptionLoggingContext(object):\n#     \"\"\"Used with the ``with`` statement when calling delegate methods to\n#     log any exceptions with the given logger.  Any exceptions caught are\n#     converted to _QuietException\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/web_test.py\n# --------------------------------------------------\n# from tornado.concurrent import Future\n# from tornado import gen\n# from tornado.escape import (\n#     json_decode,\n#     utf8,\n#     to_unicode,\n#     recursive_unicode,\n#     native_str,\n#     to_basestring,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import (\n#     utf8,\n#     xhtml_escape,\n#     xhtml_unescape,\n#     url_escape,\n#     url_unescape,\n#     to_unicode,\n#     json_decode,\n#     json_encode,\n#     squeeze,\n#     recursive_unicode,\n# )\n# from tornado.util import unicode_type\n# \n# from typing import List, Tuple, Union, Dict, Any  # noqa: F401\n# \n# linkify_tests = [\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httpclient.py\n# --------------------------------------------------\n# \n# HTTPError = HTTPClientError\n# \n# \n# class _RequestProxy(object):\n#     \"\"\"Combines an object with a dictionary of defaults.\n# \n#     Used internally by AsyncHTTPClient implementations.\n#     \"\"\"\n# \n#     def __init__(\n#         self, request: HTTPRequest, defaults: Optional[Dict[str, Any]]\n#     ) -> None:\n#         self.request = request\n#         self.defaults = defaults\n# \n#     def __getattr__(self, name: str) -> Any:\n#         request_attr = getattr(self.request, name)\n#         if request_attr is not None:\n#             return request_attr\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Tuple, ContextManager  # noqa: F401\n# \n# _DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n# \n# \n# class _UnsetMarker:\n#     pass\n# \n# \n# _UNSET = _UnsetMarker()\n# \n# \n# def filter_whitespace(mode: str, text: str) -> str:\n#     \"\"\"Transform whitespace in ``text`` according to ``mode``.\n# \n#     Available modes are:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. versionchanged:: 4.3\n#        Now accepts any yieldable object, not just\n#        `tornado.concurrent.Future`.\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import (\n#     utf8,\n#     xhtml_escape,\n#     xhtml_unescape,\n#     url_escape,\n#     url_unescape,\n#     to_unicode,\n# --------------------------------------------------\n\ndef import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n    ...\n    ImportError: No module named missing_module\n    \"\"\"\n", "metadata": {"task_id": "tornado/id44", "ground_truth": "def import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n        ...\n    ImportError: No module named missing_module\n    \"\"\"\n    if name.count(\".\") == 0:\n        return __import__(name)\n\n    parts = name.split(\".\")\n    obj = __import__(\".\".join(parts[:-1]), fromlist=[parts[-1]])\n    try:\n        return getattr(obj, parts[-1])\n    except AttributeError:\n        raise ImportError(\"No module named %s\" % parts[-1])", "fpath_tuple": ["tornado", "util.py"], "function_name": "import_object", "lineno": 0, "context_start_lineno": 0, "_id": 44, "query_window": {"context": "import importlib\ndef import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True", "metadata": {"fpath_tuple": ["tornado", "util.py"], "line_no": 0, "prediction": "import importlib\n\ndef import_object(name: str) -> Any:\n    \"\"\"Imports an object by name.\n\n    ``import_object('x')`` is equivalent to ``import x``.\n    ``import_object('x.y.z')`` is equivalent to ``from x.y import z``.\n\n    >>> import tornado.escape\n    >>> import_object('tornado.escape') is tornado.escape\n    True\n    >>> import_object('tornado.escape.utf8') is tornado.escape.utf8\n    True\n    >>> import_object('tornado') is tornado\n    True\n    >>> import_object('tornado.missing_module')\n    Traceback (most recent call last):\n    ...\n    ImportError: No module named missing_module\n    \"\"\"\n    try:\n        # Split the name into module and attribute parts\n        module_name, _, attribute_name = name.rpartition('.')\n        # Import the module\n        module = importlib.import_module(module_name)\n        # If an attribute is specified, return it\n        if attribute_name:\n            return getattr(module, attribute_name)\n        return module\n    except ImportError as e:\n        raise ImportError(f\"No module named '{name}'\") from e", "task_id": "tornado/id44", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "import unittest\n\nimport tornado.escape\nfrom tornado.escape import (\n    utf8,\n    xhtml_escape,\n    xhtml_unescape,\n    url_escape,\n    url_unescape,\n    to_unicode,", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21428571428571427}, {"context": "    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18947368421052632}, {"context": "from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Tuple, ContextManager  # noqa: F401\n\n_DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n\n\nclass _UnsetMarker:\n    pass\n\n\n_UNSET = _UnsetMarker()\n\n\ndef filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18691588785046728}, {"context": "\nHTTPError = HTTPClientError\n\n\nclass _RequestProxy(object):\n    \"\"\"Combines an object with a dictionary of defaults.\n\n    Used internally by AsyncHTTPClient implementations.\n    \"\"\"\n\n    def __init__(\n        self, request: HTTPRequest, defaults: Optional[Dict[str, Any]]\n    ) -> None:\n        self.request = request\n        self.defaults = defaults\n\n    def __getattr__(self, name: str) -> Any:\n        request_attr = getattr(self.request, name)\n        if request_attr is not None:\n            return request_attr", "metadata": [{"fpath_tuple": ["tornado", "httpclient.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18085106382978725}, {"context": "import unittest\n\nimport tornado.escape\nfrom tornado.escape import (\n    utf8,\n    xhtml_escape,\n    xhtml_unescape,\n    url_escape,\n    url_unescape,\n    to_unicode,\n    json_decode,\n    json_encode,\n    squeeze,\n    recursive_unicode,\n)\nfrom tornado.util import unicode_type\n\nfrom typing import List, Tuple, Union, Dict, Any  # noqa: F401\n\nlinkify_tests = [", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18072289156626506}, {"context": "from tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.escape import (\n    json_decode,\n    utf8,\n    to_unicode,\n    recursive_unicode,\n    native_str,\n    to_basestring,\n)", "metadata": [{"fpath_tuple": ["tornado", "test", "web_test.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1774193548387097}, {"context": "from tornado.escape import native_str, utf8\nfrom tornado import gen\nfrom tornado import httputil\nfrom tornado import iostream\nfrom tornado.log import gen_log, app_log\nfrom tornado.util import GzipDecompressor\n\n\nfrom typing import cast, Optional, Type, Awaitable, Callable, Union, Tuple\n\n\nclass _QuietException(Exception):\n    def __init__(self) -> None:\n        pass\n\n\nclass _ExceptionLoggingContext(object):\n    \"\"\"Used with the ``with`` statement when calling delegate methods to\n    log any exceptions with the given logger.  Any exceptions caught are\n    converted to _QuietException", "metadata": [{"fpath_tuple": ["tornado", "http1connection.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17117117117117117}, {"context": "        \"\"\"The set of option-groups created by ``define``.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return set(opt.group_name for opt in self._options.values())\n\n    def group_dict(self, group: str) -> Dict[str, Any]:\n        \"\"\"The names and values of options in a group.\n\n        Useful for copying options into Application settings::\n\n            from tornado.options import define, parse_command_line, options\n\n            define('template_path', group='application')\n            define('static_path', group='application')\n\n            parse_command_line()\n\n            application = Application(\n                handlers, **options.group_dict('application'))", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17117117117117117}, {"context": "    Iterator,\n    Dict,\n    Union,\n    Optional,\n    Awaitable,\n    Generator,\n    AnyStr,\n)\n\nif typing.TYPE_CHECKING:\n    from typing import Deque  # noqa: F401\n    from asyncio import Future  # noqa: F401\n    import unittest  # noqa: F401\n\n\n@lru_cache(1000)\ndef _normalize_header(name: str) -> str:\n    \"\"\"Map a header name to Http-Header-Case.\n\n    >>> _normalize_header(\"coNtent-TYPE\")", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17}, {"context": "from io import StringIO\nimport re\nimport sys\nimport datetime\nimport unittest\n\nimport tornado.escape\nfrom tornado.escape import utf8\nfrom tornado.util import (\n    raise_exc_info,\n    Configurable,\n    exec_in,\n    ArgReplacer,\n    timedelta_to_seconds,\n    import_object,\n    re_unescape,\n    is_finalizing,\n)\n\nimport typing", "metadata": [{"fpath_tuple": ["tornado", "test", "util_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16883116883116883}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n#         self._running_future = None  # type: Optional[Future]\n# \n#         for future in futures:\n#             future_add_done_callback(future, self._done_callback)\n# \n#     def done(self) -> bool:\n#         \"\"\"Returns True if this iterator has no more results.\"\"\"\n#         if self._finished or self._unfinished:\n#             return False\n#         # Clear the 'current' values when iteration is done.\n#         self.current_index = self.current_future = None\n#         return True\n# \n#     def next(self) -> Future:\n#         \"\"\"Returns a `.Future` that will yield the next available result.\n# \n#         Note that this `.Future` will not be the same object as any of\n#         the inputs.\n#         \"\"\"\n#         self._running_future = Future()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# \n#     def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n#         try:\n#             return self._fio.readinto(buf)  # type: ignore\n#         except (IOError, OSError) as e:\n#             if errno_from_exception(e) == errno.EBADF:\n#                 # If the writing half of a pipe is closed, select will\n#                 # report it as readable but reads will fail with EBADF.\n#                 self.close(exc_info=e)\n#                 return None\n#             else:\n#                 raise\n#         finally:\n#             del buf\n# \n# \n# def doctests() -> Any:\n#     import doctest\n# \n#     return doctest.DocTestSuite()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n#     \"\"\"Provides an iterator to yield the results of awaitables as they finish.\n# \n#     Yielding a set of awaitables like this:\n# \n#     ``results = yield [awaitable1, awaitable2]``\n# \n#     pauses the coroutine until both ``awaitable1`` and ``awaitable2``\n#     return, and then restarts the coroutine with the results of both\n#     awaitables. If either awaitable raises an exception, the\n#     expression will raise that exception and all the results will be\n#     lost.\n# \n#     If you need to get the result of each awaitable as soon as possible,\n#     or if you need the result of some awaitables even if others produce\n#     errors, you can use ``WaitIterator``::\n# \n#       wait_iterator = gen.WaitIterator(awaitable1, awaitable2)\n#       while not wait_iterator.done():\n#           try:\n#               result = yield wait_iterator.next()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         Returns the number of bytes written.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n#         \"\"\"Attempts to read from the underlying file.\n# \n#         Reads up to ``len(buf)`` bytes, storing them in the buffer.\n#         Returns the number of bytes read. Returns None if there was\n#         nothing to read (the socket returned `~errno.EWOULDBLOCK` or\n#         equivalent), and zero on EOF.\n# \n#         .. versionchanged:: 5.0\n# \n#            Interface redesigned to take a buffer and return a number\n#            of bytes instead of a freshly-allocated object.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def get_fd_error(self) -> Optional[Exception]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         self._check_closed()\n#         pos = self._read_to_buffer_loop()\n#         if pos is not None:\n#             self._read_from_buffer(pos)\n#             return\n#         # We couldn't satisfy the read inline, so make sure we're\n#         # listening for new data unless the stream is closed.\n#         if not self.closed():\n#             self._add_io_state(ioloop.IOLoop.READ)\n# \n#     def _read_to_buffer(self) -> Optional[int]:\n#         \"\"\"Reads from the socket and appends the result to the read buffer.\n# \n#         Returns the number of bytes read.  Returns 0 if there is nothing\n#         to read (i.e. the read returns EWOULDBLOCK or equivalent).  On\n#         error closes the socket and raises an exception.\n#         \"\"\"\n#         try:\n#             while True:\n#                 try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n#         use that instead of `sys.exc_info`).\n#         \"\"\"\n#         if not self.closed():\n#             if exc_info:\n#                 if isinstance(exc_info, tuple):\n#                     self.error = exc_info[1]\n#                 elif isinstance(exc_info, BaseException):\n#                     self.error = exc_info\n#                 else:\n#                     exc_info = sys.exc_info()\n#                     if any(exc_info):\n#                         self.error = exc_info[1]\n#             if self._read_until_close:\n#                 self._read_until_close = False\n#                 self._finish_read(self._read_buffer_size, False)\n#             elif self._read_future is not None:\n#                 # resolve reads that are pending and ready to complete\n#                 try:\n#                     pos = self._find_read_pos()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         \"\"\"Logs the current request.\n# \n#         Sort of deprecated since this functionality was moved to the\n#         Application, but left in place for the benefit of existing apps\n#         that have overridden this method.\n#         \"\"\"\n#         self.application.log_request(self)\n# \n#     def _request_summary(self) -> str:\n#         return \"%s %s (%s)\" % (\n#             self.request.method,\n#             self.request.uri,\n#             self.request.remote_ip,\n#         )\n# \n#     def _handle_request_exception(self, e: BaseException) -> None:\n#         if isinstance(e, Finish):\n#             # Not an error; just finish the request without logging.\n#             if not self._finished:\n#                 self.finish(*e.args)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#             Tuple[\n#                 \"Optional[Type[BaseException]]\",\n#                 Optional[BaseException],\n#                 Optional[TracebackType],\n#             ],\n#         ] = False,\n#     ) -> None:\n#         \"\"\"Close this stream.\n# \n#         If ``exc_info`` is true, set the ``error`` attribute to the current\n#         exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n#         use that instead of `sys.exc_info`).\n#         \"\"\"\n#         if not self.closed():\n#             if exc_info:\n#                 if isinstance(exc_info, tuple):\n#                     self.error = exc_info[1]\n#                 elif isinstance(exc_info, BaseException):\n#                     self.error = exc_info\n#                 else:\n# --------------------------------------------------\n\ndef errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if someone instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id45", "ground_truth": "def errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if someone instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n\n    if hasattr(e, \"errno\"):\n        return e.errno  # type: ignore\n    elif e.args:\n        return e.args[0]\n    else:\n        return None", "fpath_tuple": ["tornado", "util.py"], "function_name": "errno_from_exception", "lineno": 0, "context_start_lineno": 0, "_id": 45, "query_window": {"context": "from typing import Optional\ndef errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if some instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n    # First, try to get errno from the exception's `errno` attribute.", "metadata": {"fpath_tuple": ["tornado", "util.py"], "line_no": 0, "prediction": "from typing import Optional\n\ndef errno_from_exception(e: BaseException) -> Optional[int]:\n    \"\"\"Provides the errno from an Exception object.\n\n    There are cases that the errno attribute was not set so we pull\n    the errno out of the args but if some instantiates an Exception\n    without any args you will get a tuple error. So this function\n    abstracts all that behavior to give you a safe way to get the\n    errno.\n    \"\"\"\n    \n    # First, try to get errno from the exception's `errno` attribute.\n    if hasattr(e, 'errno'):\n        return getattr(e, 'errno')\n\n    # If `errno` attribute does not exist, try to get it from the `args`.\n    if e.args:\n        # If it's a tuple, we check the first element.\n        if isinstance(e.args, tuple):\n            if len(e.args) > 0 and isinstance(e.args[0], int):\n                return e.args[0]\n    \n    # If no valid errno has been found, return None.\n    return None", "task_id": "tornado/id45", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "            Tuple[\n                \"Optional[Type[BaseException]]\",\n                Optional[BaseException],\n                Optional[TracebackType],\n            ],\n        ] = False,\n    ) -> None:\n        \"\"\"Close this stream.\n\n        If ``exc_info`` is true, set the ``error`` attribute to the current\n        exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n        use that instead of `sys.exc_info`).\n        \"\"\"\n        if not self.closed():\n            if exc_info:\n                if isinstance(exc_info, tuple):\n                    self.error = exc_info[1]\n                elif isinstance(exc_info, BaseException):\n                    self.error = exc_info\n                else:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 580, "start_line_no": 570, "end_line_no": 590, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21705426356589147}, {"context": "        \"\"\"Logs the current request.\n\n        Sort of deprecated since this functionality was moved to the\n        Application, but left in place for the benefit of existing apps\n        that have overridden this method.\n        \"\"\"\n        self.application.log_request(self)\n\n    def _request_summary(self) -> str:\n        return \"%s %s (%s)\" % (\n            self.request.method,\n            self.request.uri,\n            self.request.remote_ip,\n        )\n\n    def _handle_request_exception(self, e: BaseException) -> None:\n        if isinstance(e, Finish):\n            # Not an error; just finish the request without logging.\n            if not self._finished:\n                self.finish(*e.args)", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 1740, "start_line_no": 1730, "end_line_no": 1750, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20714285714285716}, {"context": "        exception from `sys.exc_info` (or if ``exc_info`` is a tuple,\n        use that instead of `sys.exc_info`).\n        \"\"\"\n        if not self.closed():\n            if exc_info:\n                if isinstance(exc_info, tuple):\n                    self.error = exc_info[1]\n                elif isinstance(exc_info, BaseException):\n                    self.error = exc_info\n                else:\n                    exc_info = sys.exc_info()\n                    if any(exc_info):\n                        self.error = exc_info[1]\n            if self._read_until_close:\n                self._read_until_close = False\n                self._finish_read(self._read_buffer_size, False)\n            elif self._read_future is not None:\n                # resolve reads that are pending and ready to complete\n                try:\n                    pos = self._find_read_pos()", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2}, {"context": "        self._check_closed()\n        pos = self._read_to_buffer_loop()\n        if pos is not None:\n            self._read_from_buffer(pos)\n            return\n        # We couldn't satisfy the read inline, so make sure we're\n        # listening for new data unless the stream is closed.\n        if not self.closed():\n            self._add_io_state(ioloop.IOLoop.READ)\n\n    def _read_to_buffer(self) -> Optional[int]:\n        \"\"\"Reads from the socket and appends the result to the read buffer.\n\n        Returns the number of bytes read.  Returns 0 if there is nothing\n        to read (i.e. the read returns EWOULDBLOCK or equivalent).  On\n        error closes the socket and raises an exception.\n        \"\"\"\n        try:\n            while True:\n                try:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 850, "start_line_no": 840, "end_line_no": 860, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19480519480519481}, {"context": "        Returns the number of bytes written.\n        \"\"\"\n        raise NotImplementedError()\n\n    def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        \"\"\"Attempts to read from the underlying file.\n\n        Reads up to ``len(buf)`` bytes, storing them in the buffer.\n        Returns the number of bytes read. Returns None if there was\n        nothing to read (the socket returned `~errno.EWOULDBLOCK` or\n        equivalent), and zero on EOF.\n\n        .. versionchanged:: 5.0\n\n           Interface redesigned to take a buffer and return a number\n           of bytes instead of a freshly-allocated object.\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_fd_error(self) -> Optional[Exception]:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19480519480519481}, {"context": "    \"\"\"Provides an iterator to yield the results of awaitables as they finish.\n\n    Yielding a set of awaitables like this:\n\n    ``results = yield [awaitable1, awaitable2]``\n\n    pauses the coroutine until both ``awaitable1`` and ``awaitable2``\n    return, and then restarts the coroutine with the results of both\n    awaitables. If either awaitable raises an exception, the\n    expression will raise that exception and all the results will be\n    lost.\n\n    If you need to get the result of each awaitable as soon as possible,\n    or if you need the result of some awaitables even if others produce\n    errors, you can use ``WaitIterator``::\n\n      wait_iterator = gen.WaitIterator(awaitable1, awaitable2)\n      while not wait_iterator.done():\n          try:\n              result = yield wait_iterator.next()", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19310344827586207}, {"context": "\n    def read_from_fd(self, buf: Union[bytearray, memoryview]) -> Optional[int]:\n        try:\n            return self._fio.readinto(buf)  # type: ignore\n        except (IOError, OSError) as e:\n            if errno_from_exception(e) == errno.EBADF:\n                # If the writing half of a pipe is closed, select will\n                # report it as readable but reads will fail with EBADF.\n                self.close(exc_info=e)\n                return None\n            else:\n                raise\n        finally:\n            del buf\n\n\ndef doctests() -> Any:\n    import doctest\n\n    return doctest.DocTestSuite()", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 1650, "start_line_no": 1640, "end_line_no": 1660, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19078947368421054}, {"context": "        self._running_future = None  # type: Optional[Future]\n\n        for future in futures:\n            future_add_done_callback(future, self._done_callback)\n\n    def done(self) -> bool:\n        \"\"\"Returns True if this iterator has no more results.\"\"\"\n        if self._finished or self._unfinished:\n            return False\n        # Clear the 'current' values when iteration is done.\n        self.current_index = self.current_future = None\n        return True\n\n    def next(self) -> Future:\n        \"\"\"Returns a `.Future` that will yield the next available result.\n\n        Note that this `.Future` will not be the same object as any of\n        the inputs.\n        \"\"\"\n        self._running_future = Future()", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18382352941176472}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     This is a subclass of `HTTPError`, so if it is uncaught a 400 response\n#     code will be used instead of 500 (and a stack trace will not be logged).\n# \n#     .. versionadded:: 3.1\n#     \"\"\"\n# \n#     def __init__(self, arg_name: str) -> None:\n#         super().__init__(400, \"Missing argument %s\" % arg_name)\n#         self.arg_name = arg_name\n# \n# \n# class ErrorHandler(RequestHandler):\n#     \"\"\"Generates an error response with ``status_code`` for all requests.\"\"\"\n# \n#     def initialize(self, status_code: int) -> None:\n#         self.set_status(status_code)\n# \n#     def prepare(self) -> None:\n#         raise HTTPError(self._status_code)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#     The ``real_error`` attribute contains the underlying error that caused\n#     the stream to close (if any).\n# \n#     .. versionchanged:: 4.3\n#        Added the ``real_error`` attribute.\n#     \"\"\"\n# \n#     def __init__(self, real_error: Optional[BaseException] = None) -> None:\n#         super().__init__(\"Stream is closed\")\n#         self.real_error = real_error\n# \n# \n# class UnsatisfiableReadError(Exception):\n#     \"\"\"Exception raised when a read cannot be satisfied.\n# \n#     Raised by ``read_until`` and ``read_until_regex`` with a ``max_bytes``\n#     argument.\n#     \"\"\"\n# \n#     pass\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n#         :arg str autoescape: The name of a function in the template\n#             namespace, or ``None`` to disable escaping by default.\n#         :arg str whitespace: A string specifying treatment of whitespace;\n#             see `filter_whitespace` for options.\n# \n#         .. versionchanged:: 4.3\n#            Added ``whitespace`` parameter; deprecated ``compress_whitespace``.\n#         \"\"\"\n#         self.name = escape.native_str(name)\n# \n#         if compress_whitespace is not _UNSET:\n#             # Convert deprecated compress_whitespace (bool) to whitespace (str).\n#             if whitespace is not None:\n#                 raise Exception(\"cannot set both whitespace and compress_whitespace\")\n#             whitespace = \"single\" if compress_whitespace else \"all\"\n#         if whitespace is None:\n#             if loader and loader.whitespace:\n#                 whitespace = loader.whitespace\n#             else:\n#                 # Whitespace defaults by filename.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#         :arg request_conn: is a `.HTTPConnection` object for a single\n#             request/response exchange.\n# \n#         This method should return a `.HTTPMessageDelegate`.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def on_close(self, server_conn: object) -> None:\n#         \"\"\"This method is called when a connection has been closed.\n# \n#         :arg server_conn: is a server connection that has previously been\n#             passed to ``start_request``.\n#         \"\"\"\n#         pass\n# \n# \n# class HTTPMessageDelegate(object):\n#     \"\"\"Implement this interface to handle an HTTP request or response.\n# \n#     .. versionadded:: 4.0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     .. versionchanged:: 4.3\n#        Arguments passed to ``Finish()`` will be passed on to\n#        `RequestHandler.finish`.\n#     \"\"\"\n# \n#     pass\n# \n# \n# class MissingArgumentError(HTTPError):\n#     \"\"\"Exception raised by `RequestHandler.get_argument`.\n# \n#     This is a subclass of `HTTPError`, so if it is uncaught a 400 response\n#     code will be used instead of 500 (and a stack trace will not be logged).\n# \n#     .. versionadded:: 3.1\n#     \"\"\"\n# \n#     def __init__(self, arg_name: str) -> None:\n#         super().__init__(400, \"Missing argument %s\" % arg_name)\n#         self.arg_name = arg_name\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     Returned ``port`` will be ``None`` if not present.\n# \n#     .. versionadded:: 4.1\n#     \"\"\"\n#     match = _netloc_re.match(netloc)\n#     if match:\n#         host = match.group(1)\n#         port = int(match.group(2))  # type: Optional[int]\n#     else:\n#         host = netloc\n#         port = None\n#     return (host, port)\n# \n# \n# def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n#     \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     for k, vs in qs.items():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         # not generally be used by application code.\n# \n#         # .. versionadded:: 4.0\n#         # \"\"\"\n#         if isinstance(fd, int):\n#             return fd, fd\n#         return fd.fileno(), fd\n# \n#     def close_fd(self, fd: Union[int, _Selectable]) -> None:\n#         # \"\"\"Utility method to close an ``fd``.\n# \n#         # If ``fd`` is a file-like object, we close it directly; otherwise\n#         # we use `os.close`.\n# \n#         # This method is provided for use by `IOLoop` subclasses (in\n#         # implementations of ``IOLoop.close(all_fds=True)`` and should\n#         # not generally be used by application code.\n# \n#         # .. versionadded:: 4.0\n#         # \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. versionchanged:: 4.3\n#        Now accepts any yieldable object, not just\n#        `tornado.concurrent.Future`.\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n# --------------------------------------------------\n\ndef re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n", "metadata": {"task_id": "tornado/id46", "ground_truth": "def re_unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `re.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be unescaped).\n\n    .. versionadded:: 4.4\n    \"\"\"\n    return _re_unescape_pattern.sub(_re_unescape_replacement, s)", "fpath_tuple": ["tornado", "util.py"], "function_name": "re_unescape", "lineno": 0, "context_start_lineno": 0, "_id": 46, "query_window": {"context": "import re\ndef unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `.escape`.\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be generated by `re.escape`).\n    .. versionadded:: 4.4\n    \"\"\"\n    # A regex to match escape sequences\n    # This catches sequences that start with a backslash not followed by a valid character", "metadata": {"fpath_tuple": ["tornado", "util.py"], "line_no": 0, "prediction": "import re\n\ndef unescape(s: str) -> str:\n    r\"\"\"Unescape a string escaped by `.escape`.\n\n    May raise ``ValueError`` for regular expressions which could not\n    have been produced by `re.escape` (for example, strings containing\n    ``\\d`` cannot be generated by `re.escape`).\n\n    .. versionadded:: 4.4\n    \"\"\"\n    # A regex to match escape sequences\n    # This catches sequences that start with a backslash not followed by a valid character\n    escape_regex = re.compile(r'\\\\([^\\\\])')\n\n    # Check for invalid escape sequences\n    if re.search(escape_regex, s):\n        raise ValueError(\"Input string contains invalid escape sequences\")\n\n    # Replace valid escape sequences with their literal counterparts\n    unescaped = re.sub(r'\\\\(.)', lambda match: match.group(1), s)\n    \n    return unescaped", "task_id": "tornado/id46", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2032520325203252}, {"context": "        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"\n        if isinstance(fd, int):\n            return fd, fd\n        return fd.fileno(), fd\n\n    def close_fd(self, fd: Union[int, _Selectable]) -> None:\n        # \"\"\"Utility method to close an ``fd``.\n\n        # If ``fd`` is a file-like object, we close it directly; otherwise\n        # we use `os.close`.\n\n        # This method is provided for use by `IOLoop` subclasses (in\n        # implementations of ``IOLoop.close(all_fds=True)`` and should\n        # not generally be used by application code.\n\n        # .. versionadded:: 4.0\n        # \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 790, "start_line_no": 780, "end_line_no": 800, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20279720279720279}, {"context": "    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)\n\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1040, "start_line_no": 1030, "end_line_no": 1050, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19863013698630136}, {"context": "    .. versionchanged:: 4.3\n       Arguments passed to ``Finish()`` will be passed on to\n       `RequestHandler.finish`.\n    \"\"\"\n\n    pass\n\n\nclass MissingArgumentError(HTTPError):\n    \"\"\"Exception raised by `RequestHandler.get_argument`.\n\n    This is a subclass of `HTTPError`, so if it is uncaught a 400 response\n    code will be used instead of 500 (and a stack trace will not be logged).\n\n    .. versionadded:: 3.1\n    \"\"\"\n\n    def __init__(self, arg_name: str) -> None:\n        super().__init__(400, \"Missing argument %s\" % arg_name)\n        self.arg_name = arg_name", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2410, "start_line_no": 2400, "end_line_no": 2420, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19727891156462585}, {"context": "        :arg request_conn: is a `.HTTPConnection` object for a single\n            request/response exchange.\n\n        This method should return a `.HTTPMessageDelegate`.\n        \"\"\"\n        raise NotImplementedError()\n\n    def on_close(self, server_conn: object) -> None:\n        \"\"\"This method is called when a connection has been closed.\n\n        :arg server_conn: is a server connection that has previously been\n            passed to ``start_request``.\n        \"\"\"\n        pass\n\n\nclass HTTPMessageDelegate(object):\n    \"\"\"Implement this interface to handle an HTTP request or response.\n\n    .. versionadded:: 4.0", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19424460431654678}, {"context": "        :arg str autoescape: The name of a function in the template\n            namespace, or ``None`` to disable escaping by default.\n        :arg str whitespace: A string specifying treatment of whitespace;\n            see `filter_whitespace` for options.\n\n        .. versionchanged:: 4.3\n           Added ``whitespace`` parameter; deprecated ``compress_whitespace``.\n        \"\"\"\n        self.name = escape.native_str(name)\n\n        if compress_whitespace is not _UNSET:\n            # Convert deprecated compress_whitespace (bool) to whitespace (str).\n            if whitespace is not None:\n                raise Exception(\"cannot set both whitespace and compress_whitespace\")\n            whitespace = \"single\" if compress_whitespace else \"all\"\n        if whitespace is None:\n            if loader and loader.whitespace:\n                whitespace = loader.whitespace\n            else:\n                # Whitespace defaults by filename.", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19333333333333333}, {"context": "    The ``real_error`` attribute contains the underlying error that caused\n    the stream to close (if any).\n\n    .. versionchanged:: 4.3\n       Added the ``real_error`` attribute.\n    \"\"\"\n\n    def __init__(self, real_error: Optional[BaseException] = None) -> None:\n        super().__init__(\"Stream is closed\")\n        self.real_error = real_error\n\n\nclass UnsatisfiableReadError(Exception):\n    \"\"\"Exception raised when a read cannot be satisfied.\n\n    Raised by ``read_until`` and ``read_until_regex`` with a ``max_bytes``\n    argument.\n    \"\"\"\n\n    pass", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19285714285714287}, {"context": "\n    This is a subclass of `HTTPError`, so if it is uncaught a 400 response\n    code will be used instead of 500 (and a stack trace will not be logged).\n\n    .. versionadded:: 3.1\n    \"\"\"\n\n    def __init__(self, arg_name: str) -> None:\n        super().__init__(400, \"Missing argument %s\" % arg_name)\n        self.arg_name = arg_name\n\n\nclass ErrorHandler(RequestHandler):\n    \"\"\"Generates an error response with ``status_code`` for all requests.\"\"\"\n\n    def initialize(self, status_code: int) -> None:\n        self.set_status(status_code)\n\n    def prepare(self) -> None:\n        raise HTTPError(self._status_code)", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 2420, "start_line_no": 2410, "end_line_no": 2430, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1917808219178082}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#             raise\n#         return future\n# \n#     def read_bytes(self, num_bytes: int, partial: bool = False) -> Awaitable[bytes]:\n#         \"\"\"Asynchronously read a number of bytes.\n# \n#         If ``partial`` is true, data is returned as soon as we have\n#         any bytes to return (but never more than ``num_bytes``)\n# \n#         .. versionchanged:: 4.0\n#             Added the ``partial`` argument.  The callback argument is now\n#             optional and a `.Future` will be returned if it is omitted.\n# \n#         .. versionchanged:: 6.0\n# \n#            The ``callback`` and ``streaming_callback`` arguments have\n#            been removed. Use the returned `.Future` (and\n#            ``partial=True`` for ``streaming_callback``) instead.\n# \n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n#         self.current_index = self.current_future = None\n#         return True\n# \n#     def next(self) -> Future:\n#         \"\"\"Returns a `.Future` that will yield the next available result.\n# \n#         Note that this `.Future` will not be the same object as any of\n#         the inputs.\n#         \"\"\"\n#         self._running_future = Future()\n# \n#         if self._finished:\n#             self._return_result(self._finished.popleft())\n# \n#         return self._running_future\n# \n#     def _done_callback(self, done: Future) -> None:\n#         if self._running_future and not self._running_future.done():\n#             self._return_result(done)\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n# def _get_version(value: bytes) -> int:\n#     # Figures out what version value is.  Version 1 did not include an\n#     # explicit version field and started with arbitrary base64 data,\n#     # which makes this tricky.\n#     m = _signed_value_version_re.match(value)\n#     if m is None:\n#         version = 1\n#     else:\n#         try:\n#             version = int(m.group(1))\n#             if version > 999:\n#                 # Certain payloads from the version-less v1 format may\n#                 # be parsed as valid integers.  Due to base64 padding\n#                 # restrictions, this can only happen for numbers whose\n#                 # length is a multiple of 4, so we can treat all\n#                 # numbers up to 999 as versions, and for the rest we\n#                 # fall back to v1 format.\n#                 version = 1\n#         except ValueError:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def ping(self, data: bytes = b\"\") -> None:\n#         \"\"\"Send ping frame to the remote end.\n# \n#         The data argument allows a small amount of data (up to 125\n#         bytes) to be sent as a part of the ping message. Note that not\n#         all websocket implementations expose this data to\n#         applications.\n# \n#         Consider using the ``ping_interval`` argument to\n#         `websocket_connect` instead of sending pings manually.\n# \n#         .. versionadded:: 5.1\n# \n#         \"\"\"\n#         data = utf8(data)\n#         if self.protocol is None:\n#             raise WebSocketClosedError()\n#         self.protocol.write_ping(data)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n# \n#     def _write_frame(\n#         self, fin: bool, opcode: int, data: bytes, flags: int = 0\n#     ) -> \"Future[None]\":\n#         data_len = len(data)\n#         if opcode & 0x8:\n#             # All control frames MUST have a payload length of 125\n#             # bytes or less and MUST NOT be fragmented.\n#             if not fin:\n#                 raise ValueError(\"control frames may not be fragmented\")\n#             if data_len > 125:\n#                 raise ValueError(\"control frame payloads may not exceed 125 bytes\")\n#         if fin:\n#             finbit = self.FIN\n#         else:\n#             finbit = 0\n#         frame = struct.pack(\"B\", finbit | opcode | flags)\n#         if self.mask_outgoing:\n#             mask_bit = 0x80\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         `websocket_connect` instead of sending pings manually.\n# \n#         .. versionadded:: 5.1\n# \n#         \"\"\"\n#         data = utf8(data)\n#         if self.protocol is None:\n#             raise WebSocketClosedError()\n#         self.protocol.write_ping(data)\n# \n#     def on_pong(self, data: bytes) -> None:\n#         pass\n# \n#     def on_ping(self, data: bytes) -> None:\n#         pass\n# \n#     def get_websocket_protocol(self) -> WebSocketProtocol:\n#         return WebSocketProtocol13(self, mask_outgoing=True, params=self.params)\n# \n#     @property\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# \n#     def read_into(self, buf: bytearray, partial: bool = False) -> Awaitable[int]:\n#         \"\"\"Asynchronously read a number of bytes.\n# \n#         ``buf`` must be a writable buffer into which data will be read.\n# \n#         If ``partial`` is true, the callback is run as soon as any bytes\n#         have been read.  Otherwise, it is run when the ``buf`` has been\n#         entirely filled with read data.\n# \n#         .. versionadded:: 5.0\n# \n#         .. versionchanged:: 6.0\n# \n#            The ``callback`` argument was removed. Use the returned\n#            `.Future` instead.\n# \n#         \"\"\"\n#         future = self._start_read()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         self._size = 0\n# \n#     def __len__(self) -> int:\n#         return self._size\n# \n#     # Data above this size will be appended separately instead\n#     # of extending an existing bytearray\n#     _large_buf_threshold = 2048\n# \n#     def append(self, data: Union[bytes, bytearray, memoryview]) -> None:\n#         \"\"\"\n#         Append the given piece of data (should be a buffer-compatible object).\n#         \"\"\"\n#         size = len(data)\n#         if size > self._large_buf_threshold:\n#             if not isinstance(data, memoryview):\n#                 data = memoryview(data)\n#             self._buffers.append((True, data))\n#         elif size > 0:\n#             if self._buffers:\n# --------------------------------------------------\n\ndef _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id47", "ground_truth": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n    mask_arr = array.array(\"B\", mask)\n    unmasked_arr = array.array(\"B\", data)\n    for i in range(len(data)):\n        unmasked_arr[i] = unmasked_arr[i] ^ mask_arr[i % 4]\n    return unmasked_arr.tobytes()", "fpath_tuple": ["tornado", "util.py"], "function_name": "_websocket_mask_python", "lineno": 0, "context_start_lineno": 0, "_id": 47, "query_window": {"context": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n    if len(mask) != 4:\n        raise ValueError(\"Mask must be 4 bytes long\")\n    masked_data = bytearray(len(data))", "metadata": {"fpath_tuple": ["tornado", "util.py"], "line_no": 0, "prediction": "def _websocket_mask_python(mask: bytes, data: bytes) -> bytes:\n    \"\"\"Websocket masking function.\n\n    `mask` is a `bytes` object of length 4; `data` is a `bytes` object of any length.\n    Returns a `bytes` object of the same length as `data` with the mask applied\n    as specified in section 5.3 of RFC 6455.\n\n    This pure-python implementation may be replaced by an optimized version when available.\n    \"\"\"\n    if len(mask) != 4:\n        raise ValueError(\"Mask must be 4 bytes long\")\n    \n    masked_data = bytearray(len(data))\n    for i in range(len(data)):\n        masked_data[i] = data[i] ^ mask[i % 4]\n    \n    return bytes(masked_data)", "task_id": "tornado/id47", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        self._size = 0\n\n    def __len__(self) -> int:\n        return self._size\n\n    # Data above this size will be appended separately instead\n    # of extending an existing bytearray\n    _large_buf_threshold = 2048\n\n    def append(self, data: Union[bytes, bytearray, memoryview]) -> None:\n        \"\"\"\n        Append the given piece of data (should be a buffer-compatible object).\n        \"\"\"\n        size = len(data)\n        if size > self._large_buf_threshold:\n            if not isinstance(data, memoryview):\n                data = memoryview(data)\n            self._buffers.append((True, data))\n        elif size > 0:\n            if self._buffers:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2318840579710145}, {"context": "\n    def read_into(self, buf: bytearray, partial: bool = False) -> Awaitable[int]:\n        \"\"\"Asynchronously read a number of bytes.\n\n        ``buf`` must be a writable buffer into which data will be read.\n\n        If ``partial`` is true, the callback is run as soon as any bytes\n        have been read.  Otherwise, it is run when the ``buf`` has been\n        entirely filled with read data.\n\n        .. versionadded:: 5.0\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` argument was removed. Use the returned\n           `.Future` instead.\n\n        \"\"\"\n        future = self._start_read()\n", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23076923076923078}, {"context": "        `websocket_connect` instead of sending pings manually.\n\n        .. versionadded:: 5.1\n\n        \"\"\"\n        data = utf8(data)\n        if self.protocol is None:\n            raise WebSocketClosedError()\n        self.protocol.write_ping(data)\n\n    def on_pong(self, data: bytes) -> None:\n        pass\n\n    def on_ping(self, data: bytes) -> None:\n        pass\n\n    def get_websocket_protocol(self) -> WebSocketProtocol:\n        return WebSocketProtocol13(self, mask_outgoing=True, params=self.params)\n\n    @property", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1560, "start_line_no": 1550, "end_line_no": 1570, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.224}, {"context": "\n    def _write_frame(\n        self, fin: bool, opcode: int, data: bytes, flags: int = 0\n    ) -> \"Future[None]\":\n        data_len = len(data)\n        if opcode & 0x8:\n            # All control frames MUST have a payload length of 125\n            # bytes or less and MUST NOT be fragmented.\n            if not fin:\n                raise ValueError(\"control frames may not be fragmented\")\n            if data_len > 125:\n                raise ValueError(\"control frame payloads may not exceed 125 bytes\")\n        if fin:\n            finbit = self.FIN\n        else:\n            finbit = 0\n        frame = struct.pack(\"B\", finbit | opcode | flags)\n        if self.mask_outgoing:\n            mask_bit = 0x80\n        else:", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1050, "start_line_no": 1040, "end_line_no": 1060, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22388059701492538}, {"context": "\n    def ping(self, data: bytes = b\"\") -> None:\n        \"\"\"Send ping frame to the remote end.\n\n        The data argument allows a small amount of data (up to 125\n        bytes) to be sent as a part of the ping message. Note that not\n        all websocket implementations expose this data to\n        applications.\n\n        Consider using the ``ping_interval`` argument to\n        `websocket_connect` instead of sending pings manually.\n\n        .. versionadded:: 5.1\n\n        \"\"\"\n        data = utf8(data)\n        if self.protocol is None:\n            raise WebSocketClosedError()\n        self.protocol.write_ping(data)\n", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1550, "start_line_no": 1540, "end_line_no": 1560, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22377622377622378}, {"context": "\ndef _get_version(value: bytes) -> int:\n    # Figures out what version value is.  Version 1 did not include an\n    # explicit version field and started with arbitrary base64 data,\n    # which makes this tricky.\n    m = _signed_value_version_re.match(value)\n    if m is None:\n        version = 1\n    else:\n        try:\n            version = int(m.group(1))\n            if version > 999:\n                # Certain payloads from the version-less v1 format may\n                # be parsed as valid integers.  Due to base64 padding\n                # restrictions, this can only happen for numbers whose\n                # length is a multiple of 4, so we can treat all\n                # numbers up to 999 as versions, and for the rest we\n                # fall back to v1 format.\n                version = 1\n        except ValueError:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3420, "start_line_no": 3410, "end_line_no": 3430, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21052631578947367}, {"context": "        self.current_index = self.current_future = None\n        return True\n\n    def next(self) -> Future:\n        \"\"\"Returns a `.Future` that will yield the next available result.\n\n        Note that this `.Future` will not be the same object as any of\n        the inputs.\n        \"\"\"\n        self._running_future = Future()\n\n        if self._finished:\n            self._return_result(self._finished.popleft())\n\n        return self._running_future\n\n    def _done_callback(self, done: Future) -> None:\n        if self._running_future and not self._running_future.done():\n            self._return_result(done)\n        else:", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20833333333333334}, {"context": "            raise\n        return future\n\n    def read_bytes(self, num_bytes: int, partial: bool = False) -> Awaitable[bytes]:\n        \"\"\"Asynchronously read a number of bytes.\n\n        If ``partial`` is true, data is returned as soon as we have\n        any bytes to return (but never more than ``num_bytes``)\n\n        .. versionchanged:: 4.0\n            Added the ``partial`` argument.  The callback argument is now\n            optional and a `.Future` will be returned if it is omitted.\n\n        .. versionchanged:: 6.0\n\n           The ``callback`` and ``streaming_callback`` arguments have\n           been removed. Use the returned `.Future` (and\n           ``partial=True`` for ``streaming_callback``) instead.\n\n        \"\"\"", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2054794520547945}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# locks.py\n# --------------------------------------------------\n#     >>> async def f():\n#     ...    async with lock:\n#     ...        # Do something holding the lock.\n#     ...        pass\n#     ...\n#     ...    # Now the lock is released.\n# \n#     For compatibility with older versions of Python, the `.acquire`\n#     method asynchronously returns a regular context manager:\n# \n#     >>> async def f2():\n#     ...    with (yield lock.acquire()):\n#     ...        # Do something holding the lock.\n#     ...        pass\n#     ...\n#     ...    # Now the lock is released.\n# \n#     .. versionchanged:: 4.3\n#        Added ``async with`` support in Python 3.5.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#         If the argument appears in the url more than once, we return the\n#         last value.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_argument(name, default, self.request.query_arguments, strip)\n# \n#     def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n#         \"\"\"Returns a list of the query arguments with the given name.\n# \n#         If the argument is not present, returns an empty list.\n# \n#         .. versionadded:: 3.2\n#         \"\"\"\n#         return self._get_arguments(name, self.request.query_arguments, strip)\n# \n#     def _get_argument(\n#         self,\n#         name: str,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#         \"\"\"Called after the last chunk of data has been received.\"\"\"\n#         pass\n# \n#     def on_connection_close(self) -> None:\n#         \"\"\"Called if the connection is closed without finishing the request.\n# \n#         If ``headers_received`` is called, either ``finish`` or\n#         ``on_connection_close`` will be called, but not both.\n#         \"\"\"\n#         pass\n# \n# \n# class HTTPConnection(object):\n#     \"\"\"Applications use this interface to write their responses.\n# \n#     .. versionadded:: 4.0\n#     \"\"\"\n# \n#     def write_headers(\n#         self,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         will be enabled.  The contents of the dict may be used to\n#         control the following compression options:\n# \n#         ``compression_level`` specifies the compression level.\n# \n#         ``mem_level`` specifies the amount of memory used for the internal compression state.\n# \n#          These parameters are documented in details here:\n#          https://docs.python.org/3.6/library/zlib.html#zlib.compressobj\n# \n#         .. versionadded:: 4.1\n# \n#         .. versionchanged:: 4.5\n# \n#            Added ``compression_level`` and ``mem_level``.\n#         \"\"\"\n#         # TODO: Add wbits option.\n#         return None\n# \n#     def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         .. versionadded:: 4.1\n# \n#         .. versionchanged:: 4.5\n# \n#            Added ``compression_level`` and ``mem_level``.\n#         \"\"\"\n#         # TODO: Add wbits option.\n#         return None\n# \n#     def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n#         \"\"\"Invoked when a new WebSocket is opened.\n# \n#         The arguments to `open` are extracted from the `tornado.web.URLSpec`\n#         regular expression, just like the arguments to\n#         `tornado.web.RequestHandler.get`.\n# \n#         `open` may be a coroutine. `on_message` will not be called until\n#         `open` has returned.\n# \n#         .. versionchanged:: 5.1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n# \n# \n# def is_coroutine_function(func: Any) -> bool:\n#     \"\"\"Return whether *func* is a coroutine function, i.e. a function\n#     wrapped with `~.gen.coroutine`.\n# \n#     .. versionadded:: 4.5\n#     \"\"\"\n#     return getattr(func, \"__tornado_coroutine__\", False)\n# \n# \n# class Return(Exception):\n#     \"\"\"Special exception to return a value from a `coroutine`.\n# \n#     If this exception is raised, its value argument is used as the\n#     result of the coroutine::\n# \n#         @gen.coroutine\n#         def fetch_json(url):\n#             response = yield AsyncHTTPClient().fetch(url)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n#     ``callback`` is invoked with one argument, the ``future``.\n# \n#     If ``future`` is already done, ``callback`` is invoked immediately.\n#     This may differ from the behavior of ``Future.add_done_callback``,\n#     which makes no such guarantee.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if future.done():\n#         callback(future)\n#     else:\n#         future.add_done_callback(callback)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n#        .. versionadded:: 3.2\n# \n#     .. attribute:: files\n# \n#        File uploads are available in the files property, which maps file\n#        names to lists of `.HTTPFile`.\n# \n#     .. attribute:: connection\n# \n#        An HTTP request is attached to a single HTTP connection, which can\n#        be accessed through the \"connection\" attribute. Since connections\n#        are typically kept open in HTTP/1.1, multiple requests can be handled\n#        sequentially on a single connection.\n# \n#     .. versionchanged:: 4.0\n#        Moved from ``tornado.httpserver.HTTPRequest``.\n#     \"\"\"\n# \n#     path = None  # type: str\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. versionchanged:: 4.3\n#        Now accepts any yieldable object, not just\n#        `tornado.concurrent.Future`.\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n# --------------------------------------------------\n\ndef filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n    character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n    character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n", "metadata": {"task_id": "tornado/id48", "ground_truth": "def filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n      character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n      character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n    if mode == \"all\":\n        return text\n    elif mode == \"single\":\n        text = re.sub(r\"([\\t ]+)\", \" \", text)\n        text = re.sub(r\"(\\s*\\n\\s*)\", \"\\n\", text)\n        return text\n    elif mode == \"oneline\":\n        return re.sub(r\"(\\s+)\", \" \", text)\n    else:\n        raise Exception(\"invalid whitespace mode %s\" % mode)", "fpath_tuple": ["tornado", "template.py"], "function_name": "filter_whitespace", "lineno": 0, "context_start_lineno": 0, "_id": 48, "query_window": {"context": "def filter_(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n    Available modes are:\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n    character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n    character, removing all newlines in the process.\n    .. versionadded:: 4.3\n    \"\"\"", "metadata": {"fpath_tuple": ["tornado", "template.py"], "line_no": 0, "prediction": "def filter_(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:\n\n    * ``all``: Return all whitespace unmodified.\n    * ``single``: Collapse consecutive whitespace with a single whitespace\n    character, preserving newlines.\n    * ``oneline``: Collapse all runs of whitespace into a single space\n    character, removing all newlines in the process.\n\n    .. versionadded:: 4.3\n    \"\"\"\n    if mode == 'all':\n        return text\n    elif mode == 'single':\n        # Replace consecutive whitespace with a single space, preserving newlines\n        return ' '.join(text.split())\n    elif mode == 'oneline':\n        # Replace all whitespace with a single space, removing all newlines\n        return ' '.join(text.split()).replace('\\n', ' ')\n    else:\n        raise ValueError(f\"Invalid mode: {mode}. Choose from 'all', 'single', or 'oneline'.\")", "task_id": "tornado/id48", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.18691588785046728}, {"context": "\n       .. versionadded:: 3.2\n\n    .. attribute:: files\n\n       File uploads are available in the files property, which maps file\n       names to lists of `.HTTPFile`.\n\n    .. attribute:: connection\n\n       An HTTP request is attached to a single HTTP connection, which can\n       be accessed through the \"connection\" attribute. Since connections\n       are typically kept open in HTTP/1.1, multiple requests can be handled\n       sequentially on a single connection.\n\n    .. versionchanged:: 4.0\n       Moved from ``tornado.httpserver.HTTPRequest``.\n    \"\"\"\n\n    path = None  # type: str", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.175}, {"context": "\n    ``callback`` is invoked with one argument, the ``future``.\n\n    If ``future`` is already done, ``callback`` is invoked immediately.\n    This may differ from the behavior of ``Future.add_done_callback``,\n    which makes no such guarantee.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if future.done():\n        callback(future)\n    else:\n        future.add_done_callback(callback)", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 263, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17391304347826086}, {"context": "\n\ndef is_coroutine_function(func: Any) -> bool:\n    \"\"\"Return whether *func* is a coroutine function, i.e. a function\n    wrapped with `~.gen.coroutine`.\n\n    .. versionadded:: 4.5\n    \"\"\"\n    return getattr(func, \"__tornado_coroutine__\", False)\n\n\nclass Return(Exception):\n    \"\"\"Special exception to return a value from a `coroutine`.\n\n    If this exception is raised, its value argument is used as the\n    result of the coroutine::\n\n        @gen.coroutine\n        def fetch_json(url):\n            response = yield AsyncHTTPClient().fetch(url)", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1721311475409836}, {"context": "        .. versionadded:: 4.1\n\n        .. versionchanged:: 4.5\n\n           Added ``compression_level`` and ``mem_level``.\n        \"\"\"\n        # TODO: Add wbits option.\n        return None\n\n    def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:\n        \"\"\"Invoked when a new WebSocket is opened.\n\n        The arguments to `open` are extracted from the `tornado.web.URLSpec`\n        regular expression, just like the arguments to\n        `tornado.web.RequestHandler.get`.\n\n        `open` may be a coroutine. `on_message` will not be called until\n        `open` has returned.\n\n        .. versionchanged:: 5.1", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17164179104477612}, {"context": "        will be enabled.  The contents of the dict may be used to\n        control the following compression options:\n\n        ``compression_level`` specifies the compression level.\n\n        ``mem_level`` specifies the amount of memory used for the internal compression state.\n\n         These parameters are documented in details here:\n         https://docs.python.org/3.6/library/zlib.html#zlib.compressobj\n\n        .. versionadded:: 4.1\n\n        .. versionchanged:: 4.5\n\n           Added ``compression_level`` and ``mem_level``.\n        \"\"\"\n        # TODO: Add wbits option.\n        return None\n\n    def open(self, *args: str, **kwargs: str) -> Optional[Awaitable[None]]:", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17037037037037037}, {"context": "        \"\"\"Called after the last chunk of data has been received.\"\"\"\n        pass\n\n    def on_connection_close(self) -> None:\n        \"\"\"Called if the connection is closed without finishing the request.\n\n        If ``headers_received`` is called, either ``finish`` or\n        ``on_connection_close`` will be called, but not both.\n        \"\"\"\n        pass\n\n\nclass HTTPConnection(object):\n    \"\"\"Applications use this interface to write their responses.\n\n    .. versionadded:: 4.0\n    \"\"\"\n\n    def write_headers(\n        self,", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 560, "start_line_no": 550, "end_line_no": 570, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16666666666666666}, {"context": "\n        If the argument appears in the url more than once, we return the\n        last value.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_argument(name, default, self.request.query_arguments, strip)\n\n    def get_query_arguments(self, name: str, strip: bool = True) -> List[str]:\n        \"\"\"Returns a list of the query arguments with the given name.\n\n        If the argument is not present, returns an empty list.\n\n        .. versionadded:: 3.2\n        \"\"\"\n        return self._get_arguments(name, self.request.query_arguments, strip)\n\n    def _get_argument(\n        self,\n        name: str,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1651376146788991}, {"context": "    >>> async def f():\n    ...    async with lock:\n    ...        # Do something holding the lock.\n    ...        pass\n    ...\n    ...    # Now the lock is released.\n\n    For compatibility with older versions of Python, the `.acquire`\n    method asynchronously returns a regular context manager:\n\n    >>> async def f2():\n    ...    with (yield lock.acquire()):\n    ...        # Do something holding the lock.\n    ...        pass\n    ...\n    ...    # Now the lock is released.\n\n    .. versionchanged:: 4.3\n       Added ``async with`` support in Python 3.5.\n", "metadata": [{"fpath_tuple": ["tornado", "locks.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16037735849056603}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n# \n#     def _clear_current_hook(self) -> None:\n#         if self.is_current:\n#             asyncio.set_event_loop(self.old_asyncio)\n#             self.is_current = False\n# \n# \n# def to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n#     \"\"\"Chain two futures together so that when one completes, so does the other.\n# \n#     The result (success or failure) of ``a`` will be copied to ``b``, unless\n#     ``b`` has already been completed or cancelled by the time ``a`` finishes.\n# \n#     .. versionchanged:: 5.0\n# \n#        Now accepts both Tornado/asyncio `Future` objects and\n#        `concurrent.futures.Future`.\n# \n#     \"\"\"\n# \n#     def copy(future: \"Future[_T]\") -> None:\n#         assert future is a\n#         if b.done():\n#             return\n#         if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n#             future_set_exc_info(b, a.exc_info())  # type: ignore\n#         elif a.exception() is not None:\n#             b.set_exception(a.exception())\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         \"\"\"Call the given callback when the stream is closed.\n# \n#         This mostly is not necessary for applications that use the\n#         `.Future` interface; all outstanding ``Futures`` will resolve\n#         with a `StreamClosedError` when the stream is closed. However,\n#         it is still useful as a way to signal that the stream has been\n#         closed while no other read or write is in progress.\n# \n#         Unlike other callback-based interfaces, ``set_close_callback``\n#         was not removed in Tornado 6.0.\n#         \"\"\"\n#         self._close_callback = callback\n#         self._maybe_add_error_listener()\n# \n#     def close(\n#         self,\n#         exc_info: Union[\n#             None,\n#             bool,\n#             BaseException,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# \n# \n# def future_set_result_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n# ) -> None:\n#     \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n# \n#     Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n#     a cancelled `asyncio.Future`.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if not future.cancelled():\n#         future.set_result(value)\n# \n# \n# def future_set_exception_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n# ) -> None:\n#     \"\"\"Set the given ``exc`` as the `Future`'s exception.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n#         .. versionchanged:: 4.3\n#            Returning a non-``None``, non-awaitable value is now an error.\n# \n#         .. versionchanged:: 5.0\n#            If a timeout occurs, the ``func`` coroutine will be cancelled.\n# \n#         \"\"\"\n#         future_cell = [None]  # type: List[Optional[Future]]\n# \n#         def run() -> None:\n#             try:\n#                 result = func()\n#                 if result is not None:\n#                     from tornado.gen import convert_yielded\n# \n#                     result = convert_yielded(result)\n#             except Exception:\n#                 fut = Future()  # type: Future[Any]\n#                 future_cell[0] = fut\n#                 future_set_exc_info(fut, sys.exc_info())\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n#     .. versionadded:: 5.0\n#     \"\"\"\n#     if not future.cancelled():\n#         future.set_result(value)\n# \n# \n# def future_set_exception_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n# ) -> None:\n#     \"\"\"Set the given ``exc`` as the `Future`'s exception.\n# \n#     If the Future is already canceled, logs the exception instead. If\n#     this logging is not desired, the caller should explicitly check\n#     the state of the Future and call ``Future.set_exception`` instead of\n#     this wrapper.\n# \n#     Avoids ``asyncio.InvalidStateError`` when calling ``set_exception()`` on\n#     a cancelled `asyncio.Future`.\n# \n#     .. versionadded:: 6.0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n#         else:\n#             b.set_result(a.result())\n# \n#     if isinstance(a, Future):\n#         future_add_done_callback(a, copy)\n#     else:\n#         # concurrent.futures.Future\n#         from tornado.ioloop import IOLoop\n# \n#         IOLoop.current().add_future(a, copy)\n# \n# \n# def future_set_result_unless_cancelled(\n#     future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n# ) -> None:\n#     \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n# \n#     Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n#     a cancelled `asyncio.Future`.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n#     .. versionadded:: 4.1\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n#        so this method is now a no-op.\n#     \"\"\"\n#     return asyncio_future\n# \n# \n# def to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n#     \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n# \n#     .. versionadded:: 4.1\n# \n#     .. versionchanged:: 4.3\n#        Now accepts any yieldable object, not just\n#        `tornado.concurrent.Future`.\n# \n#     .. deprecated:: 5.0\n#        Tornado ``Futures`` have been merged with `asyncio.Future`,\n# --------------------------------------------------\n\ndef maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n    This function only handles ``Futures``, not other yieldable objects.\n    Instead of `maybe_future`, check for the non-future result types\n    you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id4", "ground_truth": "def maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n       This function only handles ``Futures``, not other yieldable objects.\n       Instead of `maybe_future`, check for the non-future result types\n       you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n    if is_future(x):\n        return x\n    else:\n        fut = _create_future()\n        fut.set_result(x)\n        return fut", "fpath_tuple": ["tornado", "gen.py"], "function_name": "maybe_future", "lineno": 0, "context_start_lineno": 0, "_id": 4, "query_window": {"context": "from concurrent.futures import Future\ndef maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n    .. deprecated:: 4.3\n    This function only handles ``Futures``, not other yieldable objects.\n    Instead of `maybe_future`, check for the non-future result types", "metadata": {"fpath_tuple": ["tornado", "gen.py"], "line_no": 0, "prediction": "from concurrent.futures import Future\n\ndef maybe_future(x: Any) -> Future:\n    \"\"\"Converts ``x`` into a `.Future`.\n\n    If ``x`` is already a `.Future`, it is simply returned; otherwise\n    it is wrapped in a new `.Future`.  This is suitable for use as\n    ``result = yield gen.maybe_future(f())`` when you don't know whether\n    ``f()`` returns a `.Future` or not.\n\n    .. deprecated:: 4.3\n    This function only handles ``Futures``, not other yieldable objects.\n    Instead of `maybe_future`, check for the non-future result types\n    you expect (often just ``None``), and ``yield`` anything unknown.\n    \"\"\"\n    if isinstance(x, Future):\n        return x\n    else:\n        future = Future()\n        future.set_result(x)\n        return future", "task_id": "tornado/id4", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert a Tornado yieldable object to an `asyncio.Future`.\n\n    .. versionadded:: 4.1\n\n    .. versionchanged:: 4.3\n       Now accepts any yieldable object, not just\n       `tornado.concurrent.Future`.\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.27049180327868855}, {"context": "        else:\n            b.set_result(a.result())\n\n    if isinstance(a, Future):\n        future_add_done_callback(a, copy)\n    else:\n        # concurrent.futures.Future\n        from tornado.ioloop import IOLoop\n\n        IOLoop.current().add_future(a, copy)\n\n\ndef future_set_result_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n) -> None:\n    \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n    a cancelled `asyncio.Future`.\n", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24113475177304963}, {"context": "    .. versionadded:: 5.0\n    \"\"\"\n    if not future.cancelled():\n        future.set_result(value)\n\n\ndef future_set_exception_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n) -> None:\n    \"\"\"Set the given ``exc`` as the `Future`'s exception.\n\n    If the Future is already canceled, logs the exception instead. If\n    this logging is not desired, the caller should explicitly check\n    the state of the Future and call ``Future.set_exception`` instead of\n    this wrapper.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_exception()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 6.0", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23972602739726026}, {"context": "        .. versionchanged:: 4.3\n           Returning a non-``None``, non-awaitable value is now an error.\n\n        .. versionchanged:: 5.0\n           If a timeout occurs, the ``func`` coroutine will be cancelled.\n\n        \"\"\"\n        future_cell = [None]  # type: List[Optional[Future]]\n\n        def run() -> None:\n            try:\n                result = func()\n                if result is not None:\n                    from tornado.gen import convert_yielded\n\n                    result = convert_yielded(result)\n            except Exception:\n                fut = Future()  # type: Future[Any]\n                future_cell[0] = fut\n                future_set_exc_info(fut, sys.exc_info())", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23776223776223776}, {"context": "\n\ndef future_set_result_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", value: _T\n) -> None:\n    \"\"\"Set the given ``value`` as the `Future`'s result, if not cancelled.\n\n    Avoids ``asyncio.InvalidStateError`` when calling ``set_result()`` on\n    a cancelled `asyncio.Future`.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    if not future.cancelled():\n        future.set_result(value)\n\n\ndef future_set_exception_unless_cancelled(\n    future: \"Union[futures.Future[_T], Future[_T]]\", exc: BaseException\n) -> None:\n    \"\"\"Set the given ``exc`` as the `Future`'s exception.", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23134328358208955}, {"context": "        \"\"\"Call the given callback when the stream is closed.\n\n        This mostly is not necessary for applications that use the\n        `.Future` interface; all outstanding ``Futures`` will resolve\n        with a `StreamClosedError` when the stream is closed. However,\n        it is still useful as a way to signal that the stream has been\n        closed while no other read or write is in progress.\n\n        Unlike other callback-based interfaces, ``set_close_callback``\n        was not removed in Tornado 6.0.\n        \"\"\"\n        self._close_callback = callback\n        self._maybe_add_error_listener()\n\n    def close(\n        self,\n        exc_info: Union[\n            None,\n            bool,\n            BaseException,", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 560, "start_line_no": 550, "end_line_no": 570, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22972972972972974}, {"context": "    \"\"\"Chain two futures together so that when one completes, so does the other.\n\n    The result (success or failure) of ``a`` will be copied to ``b``, unless\n    ``b`` has already been completed or cancelled by the time ``a`` finishes.\n\n    .. versionchanged:: 5.0\n\n       Now accepts both Tornado/asyncio `Future` objects and\n       `concurrent.futures.Future`.\n\n    \"\"\"\n\n    def copy(future: \"Future[_T]\") -> None:\n        assert future is a\n        if b.done():\n            return\n        if hasattr(a, \"exc_info\") and a.exc_info() is not None:  # type: ignore\n            future_set_exc_info(b, a.exc_info())  # type: ignore\n        elif a.exception() is not None:\n            b.set_exception(a.exception())", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22784810126582278}, {"context": "\n    def _clear_current_hook(self) -> None:\n        if self.is_current:\n            asyncio.set_event_loop(self.old_asyncio)\n            self.is_current = False\n\n\ndef to_tornado_future(asyncio_future: asyncio.Future) -> asyncio.Future:\n    \"\"\"Convert an `asyncio.Future` to a `tornado.concurrent.Future`.\n\n    .. versionadded:: 4.1\n\n    .. deprecated:: 5.0\n       Tornado ``Futures`` have been merged with `asyncio.Future`,\n       so this method is now a no-op.\n    \"\"\"\n    return asyncio_future\n\n\ndef to_asyncio_future(tornado_future: asyncio.Future) -> asyncio.Future:", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22727272727272727}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Tuple, ContextManager  # noqa: F401\n# \n# _DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n# \n# \n# class _UnsetMarker:\n#     pass\n# \n# \n# _UNSET = _UnsetMarker()\n# \n# \n# def filter_whitespace(mode: str, text: str) -> str:\n#     \"\"\"Transform whitespace in ``text`` according to ``mode``.\n# \n#     Available modes are:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n# \"\"\"\n# \n# import array\n# import atexit\n# from inspect import getfullargspec\n# import os\n# import re\n# import typing\n# import zlib\n# \n# from typing import (\n#     Any,\n#     Optional,\n#     Dict,\n#     Mapping,\n#     List,\n#     Tuple,\n#     Match,\n#     Callable,\n#     Type,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# import linecache\n# import os.path\n# import posixpath\n# import re\n# import threading\n# \n# from tornado import escape\n# from tornado.log import app_log\n# from tornado.util import ObjectDict, exec_in, unicode_type\n# \n# from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Tuple, ContextManager  # noqa: F401\n# \n# _DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n# \n# \n# class _UnsetMarker:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# \n# import html.entities\n# import json\n# import re\n# import urllib.parse\n# \n# from tornado.util import unicode_type\n# \n# import typing\n# from typing import Union, Any, Optional, Dict, List, Callable\n# \n# \n# _XHTML_ESCAPE_RE = re.compile(\"[&<>\\\"']\")\n# _XHTML_ESCAPE_DICT = {\n#     \"&\": \"&amp;\",\n#     \"<\": \"&lt;\",\n#     \">\": \"&gt;\",\n#     '\"': \"&quot;\",\n#     \"'\": \"&#39;\",\n# }\n# --------------------------------------------------\n# the below code fragment can be found in:\n# options.py\n# --------------------------------------------------\n# import textwrap\n# \n# from tornado.escape import _unicode, native_str\n# from tornado.log import define_logging_options\n# from tornado.util import basestring_type, exec_in\n# \n# from typing import (\n#     Any,\n#     Iterator,\n#     Iterable,\n#     Tuple,\n#     Set,\n#     Dict,\n#     Callable,\n#     List,\n#     TextIO,\n#     Optional,\n# )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# # responses is unused in this file, but we re-export it to other files.\n# # Reference it so pyflakes doesn't complain.\n# responses\n# \n# import typing\n# from typing import (\n#     Tuple,\n#     Iterable,\n#     List,\n#     Mapping,\n#     Iterator,\n#     Dict,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Generator,\n#     AnyStr,\n# )\n# \n# if typing.TYPE_CHECKING:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# from tornado.util import errno_from_exception\n# \n# import typing\n# from typing import (\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Callable,\n#     Pattern,\n#     Any,\n#     Dict,\n#     TypeVar,\n#     Tuple,\n# )\n# from types import TracebackType\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Deque, List, Type  # noqa: F401\n# \n# _IOStreamType = TypeVar(\"_IOStreamType\", bound=\"IOStream\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     Any,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Tuple,\n#     List,\n#     Callable,\n#     Iterable,\n#     Generator,\n#     Type,\n#     cast,\n#     overload,\n# )\n# from types import TracebackType\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Set  # noqa: F401\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     ReversibleRuleRouter,\n#     URLSpec,\n#     _RuleList,\n# )\n# from tornado.util import ObjectDict, unicode_type, _websocket_mask\n# \n# url = URLSpec\n# \n# from typing import (\n#     Dict,\n#     Any,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Tuple,\n#     List,\n#     Callable,\n#     Iterable,\n#     Generator,\n#     Type,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import (\n#     utf8,\n#     xhtml_escape,\n#     xhtml_unescape,\n#     url_escape,\n#     url_unescape,\n#     to_unicode,\n#     json_decode,\n#     json_encode,\n#     squeeze,\n#     recursive_unicode,\n# )\n# from tornado.util import unicode_type\n# \n# from typing import List, Tuple, Union, Dict, Any  # noqa: F401\n# \n# linkify_tests = [\n# --------------------------------------------------\n\ndef get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id49", "ground_truth": "def get(*locale_codes: str) -> \"Locale\":\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n    return Locale.get_closest(*locale_codes)", "fpath_tuple": ["tornado", "locale.py"], "function_name": "get", "lineno": 0, "context_start_lineno": 0, "_id": 49, "query_window": {"context": "from typing import List, Tuple, Optional\n# Predefined list of available locales for demonstration purposes.\nAVAILABLE_LOCALES = [\n    \"en_US\",\n    \"en_GB\",\n    \"fr_FR\",\n    \"de_DE\",\n    \"es_ES\",\n    \"it_IT\",\n    \"pt_BR\",", "metadata": {"fpath_tuple": ["tornado", "locale.py"], "line_no": 0, "prediction": "from typing import List, Tuple, Optional\n\n# Predefined list of available locales for demonstration purposes.\nAVAILABLE_LOCALES = [\n    \"en_US\",\n    \"en_GB\",\n    \"fr_FR\",\n    \"de_DE\",\n    \"es_ES\",\n    \"it_IT\",\n    \"pt_BR\",\n    \"zh_CN\",\n    \"ja_JP\",\n    \"ko_KR\",\n    # ... more locales can be added here\n]\n\nDEFAULT_LOCALE = \"en_US\"\n\ndef ge(locale_codes: List[str]) -> str:\n    \"\"\"Returns the closest match for the given locale codes.\n\n    We iterate over all given locale codes in order. If we have a tight\n    or a loose match for the code (e.g., \"en\" for \"en_US\"), we return\n    the locale. Otherwise we move to the next code in the list.\n\n    By default we return ``en_US`` if no translations are found for any of\n    the specified locales. You can change the default locale with\n    `set_default_locale()`.\n    \"\"\"\n    for code in locale_codes:\n        # Check for exact match\n        if code in AVAILABLE_LOCALES:\n            return code\n        \n        # Check for loose match (e.g., \"en\" for \"en_US\")\n        # This works by matching the language part before the underscore\n        language_code = code.split('_')[0]\n        loose_matches = [locale for locale in AVAILABLE_LOCALES if locale.startswith(language_code)]\n        if loose_matches:\n            return loose_matches[0]  # Return the first loose match\n\n    # If no matches found, return the default locale\n    return DEFAULT_LOCALE\n\n# Example usage:\nprint(ge([\"fr_CA\", \"de\", \"es\"]))  # Outputs: \"fr_FR\"\nprint(ge([\"it\", \"zh\", \"ja\"]))      # Outputs: \"it_IT\"\nprint(ge([\"nl\", \"ru\"]))             # Outputs: \"en_US\" (default)", "task_id": "tornado/id49", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "import unittest\n\nimport tornado.escape\nfrom tornado.escape import (\n    utf8,\n    xhtml_escape,\n    xhtml_unescape,\n    url_escape,\n    url_unescape,\n    to_unicode,\n    json_decode,\n    json_encode,\n    squeeze,\n    recursive_unicode,\n)\nfrom tornado.util import unicode_type\n\nfrom typing import List, Tuple, Union, Dict, Any  # noqa: F401\n\nlinkify_tests = [", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16470588235294117}, {"context": "    ReversibleRuleRouter,\n    URLSpec,\n    _RuleList,\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\n\nurl = URLSpec\n\nfrom typing import (\n    Dict,\n    Any,\n    Union,\n    Optional,\n    Awaitable,\n    Tuple,\n    List,\n    Callable,\n    Iterable,\n    Generator,\n    Type,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16455696202531644}, {"context": "    Any,\n    Union,\n    Optional,\n    Awaitable,\n    Tuple,\n    List,\n    Callable,\n    Iterable,\n    Generator,\n    Type,\n    cast,\n    overload,\n)\nfrom types import TracebackType\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Set  # noqa: F401\n\n", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15789473684210525}, {"context": "from tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\n    Union,\n    Optional,\n    Awaitable,\n    Callable,\n    Pattern,\n    Any,\n    Dict,\n    TypeVar,\n    Tuple,\n)\nfrom types import TracebackType\n\nif typing.TYPE_CHECKING:\n    from typing import Deque, List, Type  # noqa: F401\n\n_IOStreamType = TypeVar(\"_IOStreamType\", bound=\"IOStream\")", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15730337078651685}, {"context": "# responses is unused in this file, but we re-export it to other files.\n# Reference it so pyflakes doesn't complain.\nresponses\n\nimport typing\nfrom typing import (\n    Tuple,\n    Iterable,\n    List,\n    Mapping,\n    Iterator,\n    Dict,\n    Union,\n    Optional,\n    Awaitable,\n    Generator,\n    AnyStr,\n)\n\nif typing.TYPE_CHECKING:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15555555555555556}, {"context": "import textwrap\n\nfrom tornado.escape import _unicode, native_str\nfrom tornado.log import define_logging_options\nfrom tornado.util import basestring_type, exec_in\n\nfrom typing import (\n    Any,\n    Iterator,\n    Iterable,\n    Tuple,\n    Set,\n    Dict,\n    Callable,\n    List,\n    TextIO,\n    Optional,\n)\n\n", "metadata": [{"fpath_tuple": ["tornado", "options.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1518987341772152}, {"context": "\nimport html.entities\nimport json\nimport re\nimport urllib.parse\n\nfrom tornado.util import unicode_type\n\nimport typing\nfrom typing import Union, Any, Optional, Dict, List, Callable\n\n\n_XHTML_ESCAPE_RE = re.compile(\"[&<>\\\"']\")\n_XHTML_ESCAPE_DICT = {\n    \"&\": \"&amp;\",\n    \"<\": \"&lt;\",\n    \">\": \"&gt;\",\n    '\"': \"&quot;\",\n    \"'\": \"&#39;\",\n}", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.15151515151515152}, {"context": "import linecache\nimport os.path\nimport posixpath\nimport re\nimport threading\n\nfrom tornado import escape\nfrom tornado.log import app_log\nfrom tornado.util import ObjectDict, exec_in, unicode_type\n\nfrom typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Tuple, ContextManager  # noqa: F401\n\n_DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n\n\nclass _UnsetMarker:", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1509433962264151}, {"context": "\"\"\"\n\nimport array\nimport atexit\nfrom inspect import getfullargspec\nimport os\nimport re\nimport typing\nimport zlib\n\nfrom typing import (\n    Any,\n    Optional,\n    Dict,\n    Mapping,\n    List,\n    Tuple,\n    Match,\n    Callable,\n    Type,", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.14492753623188406}, {"context": "from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Tuple, ContextManager  # noqa: F401\n\n_DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n\n\nclass _UnsetMarker:\n    pass\n\n\n_UNSET = _UnsetMarker()\n\n\ndef filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.14285714285714285}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n# \n#     def embedded_javascript(self) -> Optional[str]:\n#         \"\"\"Override to return a JavaScript string\n#         to be embedded in the page.\"\"\"\n#         return None\n# \n#     def javascript_files(self) -> Optional[Iterable[str]]:\n#         \"\"\"Override to return a list of JavaScript files needed by this module.\n# \n#         If the return values are relative paths, they will be passed to\n#         `RequestHandler.static_url`; otherwise they will be used as-is.\n#         \"\"\"\n#         return None\n# \n#     def embedded_css(self) -> Optional[str]:\n#         \"\"\"Override to return a CSS string\n#         that will be embedded in the page.\"\"\"\n#         return None\n# \n#     def css_files(self) -> Optional[Iterable[str]]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# process.py\n# --------------------------------------------------\n#     future_set_result_unless_cancelled,\n#     future_set_exception_unless_cancelled,\n# )\n# from tornado import ioloop\n# from tornado.iostream import PipeIOStream\n# from tornado.log import gen_log\n# \n# import typing\n# from typing import Optional, Any, Callable\n# \n# if typing.TYPE_CHECKING:\n#     from typing import List  # noqa: F401\n# \n# # Re-export this exception for convenience.\n# CalledProcessError = subprocess.CalledProcessError\n# \n# \n# def cpu_count() -> int:\n#     \"\"\"Returns the number of processors on this machine.\"\"\"\n#     if multiprocessing is None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/locks_test.py\n# --------------------------------------------------\n# # under the License.\n# \n# import asyncio\n# from datetime import timedelta\n# import typing  # noqa: F401\n# import unittest\n# \n# from tornado import gen, locks\n# from tornado.gen import TimeoutError\n# from tornado.testing import gen_test, AsyncTestCase\n# \n# \n# class ConditionTest(AsyncTestCase):\n#     def setUp(self):\n#         super().setUp()\n#         self.history = []  # type: typing.List[typing.Union[int, str]]\n# \n#     def record_done(self, future, key):\n#         \"\"\"Record the resolution of a Future returned by Condition.wait.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# gen.py\n# --------------------------------------------------\n#         self._running_future = None  # type: Optional[Future]\n# \n#         for future in futures:\n#             future_add_done_callback(future, self._done_callback)\n# \n#     def done(self) -> bool:\n#         \"\"\"Returns True if this iterator has no more results.\"\"\"\n#         if self._finished or self._unfinished:\n#             return False\n#         # Clear the 'current' values when iteration is done.\n#         self.current_index = self.current_future = None\n#         return True\n# \n#     def next(self) -> Future:\n#         \"\"\"Returns a `.Future` that will yield the next available result.\n# \n#         Note that this `.Future` will not be the same object as any of\n#         the inputs.\n#         \"\"\"\n#         self._running_future = Future()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n#     def get_all(self) -> Iterable[Tuple[str, str]]:\n#         \"\"\"Returns an iterable of all (name, value) pairs.\n# \n#         If a header has multiple values, multiple pairs will be\n#         returned with the same name.\n#         \"\"\"\n#         for name, values in self._as_list.items():\n#             for value in values:\n#                 yield (name, value)\n# \n#     def parse_line(self, line: str) -> None:\n#         \"\"\"Updates the dictionary with a single header line.\n# \n#         >>> h = HTTPHeaders()\n#         >>> h.parse_line(\"Content-Type: text/html\")\n#         >>> h.get('content-type')\n#         'text/html'\n#         \"\"\"\n#         if line[0].isspace():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#             self.update(*args, **kwargs)\n# \n#     # new public methods\n# \n#     def add(self, name: str, value: str) -> None:\n#         \"\"\"Adds a new value for the given key.\"\"\"\n#         norm_name = _normalize_header(name)\n#         self._last_key = norm_name\n#         if norm_name in self:\n#             self._dict[norm_name] = (\n#                 native_str(self[norm_name]) + \",\" + native_str(value)\n#             )\n#             self._as_list[norm_name].append(value)\n#         else:\n#             self[norm_name] = value\n# \n#     def get_list(self, name: str) -> List[str]:\n#         \"\"\"Returns all values for the given header as a list.\"\"\"\n#         norm_name = _normalize_header(name)\n#         return self._as_list.get(norm_name, [])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#                 native_str(self[norm_name]) + \",\" + native_str(value)\n#             )\n#             self._as_list[norm_name].append(value)\n#         else:\n#             self[norm_name] = value\n# \n#     def get_list(self, name: str) -> List[str]:\n#         \"\"\"Returns all values for the given header as a list.\"\"\"\n#         norm_name = _normalize_header(name)\n#         return self._as_list.get(norm_name, [])\n# \n#     def get_all(self) -> Iterable[Tuple[str, str]]:\n#         \"\"\"Returns an iterable of all (name, value) pairs.\n# \n#         If a header has multiple values, multiple pairs will be\n#         returned with the same name.\n#         \"\"\"\n#         for name, values in self._as_list.items():\n#             for value in values:\n#                 yield (name, value)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         self.ui = handler.ui\n#         self.locale = handler.locale\n# \n#     @property\n#     def current_user(self) -> Any:\n#         return self.handler.current_user\n# \n#     def render(self, *args: Any, **kwargs: Any) -> str:\n#         \"\"\"Override in subclasses to return this module's output.\"\"\"\n#         raise NotImplementedError()\n# \n#     def embedded_javascript(self) -> Optional[str]:\n#         \"\"\"Override to return a JavaScript string\n#         to be embedded in the page.\"\"\"\n#         return None\n# \n#     def javascript_files(self) -> Optional[Iterable[str]]:\n#         \"\"\"Override to return a list of JavaScript files needed by this module.\n# \n#         If the return values are relative paths, they will be passed to\n# --------------------------------------------------\n\ndef get_supported_locales() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n", "metadata": {"task_id": "tornado/id50", "ground_truth": "def get_supported_locales() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n    return _supported_locales", "fpath_tuple": ["tornado", "locale.py"], "function_name": "get_supported_locales", "lineno": 0, "context_start_lineno": 0, "_id": 50, "query_window": {"context": "import locale\nimport os\nfrom typing import Iterable\ndef get() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n    # Get a list of all locale names\n    locale_codes = set()\n    # Retrieve the available locales using the locale module\n    try:\n        # The 'locale -a' command lists all available locales", "metadata": {"fpath_tuple": ["tornado", "locale.py"], "line_no": 0, "prediction": "import locale\nimport os\nfrom typing import Iterable\n\ndef get() -> Iterable[str]:\n    \"\"\"Returns a list of all the supported locale codes.\"\"\"\n    # Get a list of all locale names\n    locale_codes = set()\n\n    # Retrieve the available locales using the locale module\n    try:\n        # The 'locale -a' command lists all available locales\n        locales_output = os.popen('locale -a').read()\n        # Split the output into individual locale codes\n        locale_codes = {line.strip() for line in locales_output.splitlines() if line.strip()}\n    except Exception as e:\n        print(f\"An error occurred while retrieving locale codes: {e}\")\n\n    return sorted(locale_codes)\n\n# Example usage:\nif __name__ == \"__main__\":\n    print(get())", "task_id": "tornado/id50", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "        self.ui = handler.ui\n        self.locale = handler.locale\n\n    @property\n    def current_user(self) -> Any:\n        return self.handler.current_user\n\n    def render(self, *args: Any, **kwargs: Any) -> str:\n        \"\"\"Override in subclasses to return this module's output.\"\"\"\n        raise NotImplementedError()\n\n    def embedded_javascript(self) -> Optional[str]:\n        \"\"\"Override to return a JavaScript string\n        to be embedded in the page.\"\"\"\n        return None\n\n    def javascript_files(self) -> Optional[Iterable[str]]:\n        \"\"\"Override to return a list of JavaScript files needed by this module.\n\n        If the return values are relative paths, they will be passed to", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3200, "start_line_no": 3190, "end_line_no": 3210, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19130434782608696}, {"context": "                native_str(self[norm_name]) + \",\" + native_str(value)\n            )\n            self._as_list[norm_name].append(value)\n        else:\n            self[norm_name] = value\n\n    def get_list(self, name: str) -> List[str]:\n        \"\"\"Returns all values for the given header as a list.\"\"\"\n        norm_name = _normalize_header(name)\n        return self._as_list.get(norm_name, [])\n\n    def get_all(self) -> Iterable[Tuple[str, str]]:\n        \"\"\"Returns an iterable of all (name, value) pairs.\n\n        If a header has multiple values, multiple pairs will be\n        returned with the same name.\n        \"\"\"\n        for name, values in self._as_list.items():\n            for value in values:\n                yield (name, value)", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1896551724137931}, {"context": "            self.update(*args, **kwargs)\n\n    # new public methods\n\n    def add(self, name: str, value: str) -> None:\n        \"\"\"Adds a new value for the given key.\"\"\"\n        norm_name = _normalize_header(name)\n        self._last_key = norm_name\n        if norm_name in self:\n            self._dict[norm_name] = (\n                native_str(self[norm_name]) + \",\" + native_str(value)\n            )\n            self._as_list[norm_name].append(value)\n        else:\n            self[norm_name] = value\n\n    def get_list(self, name: str) -> List[str]:\n        \"\"\"Returns all values for the given header as a list.\"\"\"\n        norm_name = _normalize_header(name)\n        return self._as_list.get(norm_name, [])", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17391304347826086}, {"context": "\n    def get_all(self) -> Iterable[Tuple[str, str]]:\n        \"\"\"Returns an iterable of all (name, value) pairs.\n\n        If a header has multiple values, multiple pairs will be\n        returned with the same name.\n        \"\"\"\n        for name, values in self._as_list.items():\n            for value in values:\n                yield (name, value)\n\n    def parse_line(self, line: str) -> None:\n        \"\"\"Updates the dictionary with a single header line.\n\n        >>> h = HTTPHeaders()\n        >>> h.parse_line(\"Content-Type: text/html\")\n        >>> h.get('content-type')\n        'text/html'\n        \"\"\"\n        if line[0].isspace():", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1732283464566929}, {"context": "        self._running_future = None  # type: Optional[Future]\n\n        for future in futures:\n            future_add_done_callback(future, self._done_callback)\n\n    def done(self) -> bool:\n        \"\"\"Returns True if this iterator has no more results.\"\"\"\n        if self._finished or self._unfinished:\n            return False\n        # Clear the 'current' values when iteration is done.\n        self.current_index = self.current_future = None\n        return True\n\n    def next(self) -> Future:\n        \"\"\"Returns a `.Future` that will yield the next available result.\n\n        Note that this `.Future` will not be the same object as any of\n        the inputs.\n        \"\"\"\n        self._running_future = Future()", "metadata": [{"fpath_tuple": ["tornado", "gen.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.17094017094017094}, {"context": "# under the License.\n\nimport asyncio\nfrom datetime import timedelta\nimport typing  # noqa: F401\nimport unittest\n\nfrom tornado import gen, locks\nfrom tornado.gen import TimeoutError\nfrom tornado.testing import gen_test, AsyncTestCase\n\n\nclass ConditionTest(AsyncTestCase):\n    def setUp(self):\n        super().setUp()\n        self.history = []  # type: typing.List[typing.Union[int, str]]\n\n    def record_done(self, future, key):\n        \"\"\"Record the resolution of a Future returned by Condition.wait.\"\"\"\n", "metadata": [{"fpath_tuple": ["tornado", "test", "locks_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16806722689075632}, {"context": "    future_set_result_unless_cancelled,\n    future_set_exception_unless_cancelled,\n)\nfrom tornado import ioloop\nfrom tornado.iostream import PipeIOStream\nfrom tornado.log import gen_log\n\nimport typing\nfrom typing import Optional, Any, Callable\n\nif typing.TYPE_CHECKING:\n    from typing import List  # noqa: F401\n\n# Re-export this exception for convenience.\nCalledProcessError = subprocess.CalledProcessError\n\n\ndef cpu_count() -> int:\n    \"\"\"Returns the number of processors on this machine.\"\"\"\n    if multiprocessing is None:", "metadata": [{"fpath_tuple": ["tornado", "process.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.1652892561983471}, {"context": "\n    def embedded_javascript(self) -> Optional[str]:\n        \"\"\"Override to return a JavaScript string\n        to be embedded in the page.\"\"\"\n        return None\n\n    def javascript_files(self) -> Optional[Iterable[str]]:\n        \"\"\"Override to return a list of JavaScript files needed by this module.\n\n        If the return values are relative paths, they will be passed to\n        `RequestHandler.static_url`; otherwise they will be used as-is.\n        \"\"\"\n        return None\n\n    def embedded_css(self) -> Optional[str]:\n        \"\"\"Override to return a CSS string\n        that will be embedded in the page.\"\"\"\n        return None\n\n    def css_files(self) -> Optional[Iterable[str]]:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3210, "start_line_no": 3200, "end_line_no": 3220, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.16037735849056603}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# concurrent.py\n# --------------------------------------------------\n# import sys\n# import types\n# \n# from tornado.log import app_log\n# \n# import typing\n# from typing import Any, Callable, Optional, Tuple, Union\n# \n# _T = typing.TypeVar(\"_T\")\n# \n# \n# class ReturnValueIgnoredError(Exception):\n#     # No longer used; was previously used by @return_future\n#     pass\n# \n# \n# Future = asyncio.Future\n# \n# FUTURES = (futures.Future, Future)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#     http://tools.ietf.org/html/rfc6555\n# \n#     \"\"\"\n# \n#     def __init__(\n#         self,\n#         addrinfo: List[Tuple],\n#         connect: Callable[\n#             [socket.AddressFamily, Tuple], Tuple[IOStream, \"Future[IOStream]\"]\n#         ],\n#     ) -> None:\n#         self.io_loop = IOLoop.current()\n#         self.connect = connect\n# \n#         self.future = (\n#             Future()\n#         )  # type: Future[Tuple[socket.AddressFamily, Any, IOStream]]\n#         self.timeout = None  # type: Optional[object]\n#         self.connect_timeout = None  # type: Optional[object]\n#         self.last_error = None  # type: Optional[Exception]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/caresresolver.py\n# --------------------------------------------------\n# import pycares  # type: ignore\n# import socket\n# \n# from tornado.concurrent import Future\n# from tornado import gen\n# from tornado.ioloop import IOLoop\n# from tornado.netutil import Resolver, is_valid_ip\n# \n# import typing\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# )\n# from tornado.log import app_log\n# from tornado.util import Configurable, TimeoutError, import_object\n# \n# import typing\n# from typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Dict, List  # noqa: F401\n# \n#     from typing_extensions import Protocol\n# else:\n#     Protocol = object\n# \n# \n# class _Selectable(Protocol):\n#     def fileno(self) -> int:\n#         pass\n# \n#     def close(self) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ioloop.py\n# --------------------------------------------------\n# import time\n# import math\n# import random\n# \n# from tornado.concurrent import (\n#     Future,\n#     is_future,\n#     chain_future,\n#     future_set_exc_info,\n#     future_add_done_callback,\n# )\n# from tornado.log import app_log\n# from tornado.util import Configurable, TimeoutError, import_object\n# \n# import typing\n# from typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Dict, List  # noqa: F401\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#     HTTPFile,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado.log import gen_log\n# from tornado.testing import ExpectLog\n# \n# import copy\n# import datetime\n# import logging\n# import pickle\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tcpclient.py\n# --------------------------------------------------\n#     ) -> None:\n#         self.io_loop = IOLoop.current()\n#         self.connect = connect\n# \n#         self.future = (\n#             Future()\n#         )  # type: Future[Tuple[socket.AddressFamily, Any, IOStream]]\n#         self.timeout = None  # type: Optional[object]\n#         self.connect_timeout = None  # type: Optional[object]\n#         self.last_error = None  # type: Optional[Exception]\n#         self.remaining = len(addrinfo)\n#         self.primary_addrs, self.secondary_addrs = self.split(addrinfo)\n#         self.streams = set()  # type: Set[IOStream]\n# \n#     @staticmethod\n#     def split(\n#         addrinfo: List[Tuple],\n#     ) -> Tuple[\n#         List[Tuple[socket.AddressFamily, Tuple]],\n#         List[Tuple[socket.AddressFamily, Tuple]],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/escape_test.py\n# --------------------------------------------------\n# import unittest\n# \n# import tornado.escape\n# from tornado.escape import (\n#     utf8,\n#     xhtml_escape,\n#     xhtml_unescape,\n#     url_escape,\n#     url_unescape,\n#     to_unicode,\n#     json_decode,\n#     json_encode,\n#     squeeze,\n#     recursive_unicode,\n# )\n# from tornado.util import unicode_type\n# \n# from typing import List, Tuple, Union, Dict, Any  # noqa: F401\n# \n# linkify_tests = [\n# --------------------------------------------------\n# the below code fragment can be found in:\n# platform/asyncio.py\n# --------------------------------------------------\n# import socket\n# import sys\n# import threading\n# import typing\n# from tornado.gen import convert_yielded\n# from tornado.ioloop import IOLoop, _Selectable\n# \n# from typing import Any, TypeVar, Awaitable, Callable, Union, Optional, List, Tuple, Dict\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Set  # noqa: F401\n#     from typing_extensions import Protocol\n# \n#     class _HasFileno(Protocol):\n#         def fileno(self) -> int:\n#             pass\n# \n#     _FileDescriptorLike = Union[int, _HasFileno]\n# \n# _T = TypeVar(\"_T\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# from tornado.util import errno_from_exception\n# \n# import typing\n# from typing import (\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Callable,\n#     Pattern,\n#     Any,\n#     Dict,\n#     TypeVar,\n#     Tuple,\n# )\n# from types import TracebackType\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Deque, List, Type  # noqa: F401\n# \n# _IOStreamType = TypeVar(\"_IOStreamType\", bound=\"IOStream\")\n# --------------------------------------------------\n\ndef multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n    If multiple ``Futures`` fail, any exceptions after the first (which is\n    raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n    Use `multi` instead.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id3", "ground_truth": "def multi_future(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n       If multiple ``Futures`` fail, any exceptions after the first (which is\n       raised) will be logged. Added the ``quiet_exceptions``\n       argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n       Use `multi` instead.\n    \"\"\"\n    if isinstance(children, dict):\n        keys = list(children.keys())  # type: Optional[List]\n        children_seq = children.values()  # type: Iterable\n    else:\n        keys = None\n        children_seq = children\n    children_futs = list(map(convert_yielded, children_seq))\n    assert all(is_future(i) or isinstance(i, _NullFuture) for i in children_futs)\n    unfinished_children = set(children_futs)\n\n    future = _create_future()\n    if not children_futs:\n        future_set_result_unless_cancelled(future, {} if keys is not None else [])\n\n    def callback(fut: Future) -> None:\n        unfinished_children.remove(fut)\n        if not unfinished_children:\n            result_list = []\n            for f in children_futs:\n                try:\n                    result_list.append(f.result())\n                except Exception as e:\n                    if future.done():\n                        if not isinstance(e, quiet_exceptions):\n                            app_log.error(\n                                \"Multiple exceptions in yield list\", exc_info=True\n                            )\n                    else:\n                        future_set_exc_info(future, sys.exc_info())\n            if not future.done():\n                if keys is not None:\n                    future_set_result_unless_cancelled(\n                        future, dict(zip(keys, result_list))\n                    )\n                else:\n                    future_set_result_unless_cancelled(future, result_list)\n\n    listening = set()  # type: Set[Future]\n    for f in children_futs:\n        if f not in listening:\n            listening.add(f)\n            future_add_done_callback(f, callback)\n    return future", "fpath_tuple": ["tornado", "gen.py"], "function_name": "multi_future", "lineno": 0, "context_start_lineno": 0, "_id": 3, "query_window": {"context": "from typing import Any, Dict, List, Tuple, Union\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.queues import Queue\nfrom future import Future  # Assuming it refers to a compatible Future object\nimport logging\ndef multi_future(\n    children: Union[List[Any], Dict[Any, Any]],\n    quiet_exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]] = (),\n) -> Union[Future[List[Any]], Future[Dict[Any, Any]]]:", "metadata": {"fpath_tuple": ["tornado", "gen.py"], "line_no": 0, "prediction": "from typing import Any, Dict, List, Tuple, Union\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.queues import Queue\nfrom future import Future  # Assuming it refers to a compatible Future object\nimport logging\n\ndef multi_future(\n    children: Union[List[Any], Dict[Any, Any]],\n    quiet_exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]] = (),\n) -> Union[Future[List[Any]], Future[Dict[Any, Any]]]:\n    \"\"\"Wait for multiple asynchronous futures in parallel.\n\n    Since Tornado 6.0, this function is exactly the same as `multi`.\n\n    .. versionadded:: 4.0\n\n    .. versionchanged:: 4.2\n    If multiple ``Futures`` fail, any exceptions after the first (which is\n    raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. deprecated:: 4.3\n    Use `multi` instead.\n    \"\"\"\n    # Create a Future to return when all tasks are complete\n    result_future = Future()\n    results = {}\n    errors = []\n    \n    if isinstance(children, dict):\n        keys = list(children.keys())\n        futures = list(children.values())\n    else:\n        keys = list(range(len(children)))\n        futures = children\n\n    def handle_failure(failure: Any) -> None:\n        errors.append(failure)\n        if not result_future.done():\n            result_future.set_exception(failure)\n\n    def handle_success(index: int, value: Any) -> None:\n        results[keys[index]] = value\n        if len(results) == len(futures) and not result_future.done():\n            result_future.set_result(results)\n\n    for i, future in enumerate(futures):\n        if not isinstance(future, Future):\n            logging.error(f\"Item {i} is not a Future.\")\n            continue\n        \n        future.add_done_callback(lambda f, idx=i: (\n            handle_failure(f.exception()) if f.exception() else handle_success(idx, f.result())\n        ))\n\n    return result_future", "task_id": "tornado/id3", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "from tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\n    Union,\n    Optional,\n    Awaitable,\n    Callable,\n    Pattern,\n    Any,\n    Dict,\n    TypeVar,\n    Tuple,\n)\nfrom types import TracebackType\n\nif typing.TYPE_CHECKING:\n    from typing import Deque, List, Type  # noqa: F401\n\n_IOStreamType = TypeVar(\"_IOStreamType\", bound=\"IOStream\")", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2604166666666667}, {"context": "import socket\nimport sys\nimport threading\nimport typing\nfrom tornado.gen import convert_yielded\nfrom tornado.ioloop import IOLoop, _Selectable\n\nfrom typing import Any, TypeVar, Awaitable, Callable, Union, Optional, List, Tuple, Dict\n\nif typing.TYPE_CHECKING:\n    from typing import Set  # noqa: F401\n    from typing_extensions import Protocol\n\n    class _HasFileno(Protocol):\n        def fileno(self) -> int:\n            pass\n\n    _FileDescriptorLike = Union[int, _HasFileno]\n\n_T = TypeVar(\"_T\")", "metadata": [{"fpath_tuple": ["tornado", "platform", "asyncio.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2542372881355932}, {"context": "import unittest\n\nimport tornado.escape\nfrom tornado.escape import (\n    utf8,\n    xhtml_escape,\n    xhtml_unescape,\n    url_escape,\n    url_unescape,\n    to_unicode,\n    json_decode,\n    json_encode,\n    squeeze,\n    recursive_unicode,\n)\nfrom tornado.util import unicode_type\n\nfrom typing import List, Tuple, Union, Dict, Any  # noqa: F401\n\nlinkify_tests = [", "metadata": [{"fpath_tuple": ["tornado", "test", "escape_test.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24468085106382978}, {"context": "    ) -> None:\n        self.io_loop = IOLoop.current()\n        self.connect = connect\n\n        self.future = (\n            Future()\n        )  # type: Future[Tuple[socket.AddressFamily, Any, IOStream]]\n        self.timeout = None  # type: Optional[object]\n        self.connect_timeout = None  # type: Optional[object]\n        self.last_error = None  # type: Optional[Exception]\n        self.remaining = len(addrinfo)\n        self.primary_addrs, self.secondary_addrs = self.split(addrinfo)\n        self.streams = set()  # type: Set[IOStream]\n\n    @staticmethod\n    def split(\n        addrinfo: List[Tuple],\n    ) -> Tuple[\n        List[Tuple[socket.AddressFamily, Tuple]],\n        List[Tuple[socket.AddressFamily, Tuple]],", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23853211009174313}, {"context": "    HTTPFile,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado.log import gen_log\nfrom tornado.testing import ExpectLog\n\nimport copy\nimport datetime\nimport logging\nimport pickle\nimport time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23636363636363636}, {"context": "import time\nimport math\nimport random\n\nfrom tornado.concurrent import (\n    Future,\n    is_future,\n    chain_future,\n    future_set_exc_info,\n    future_add_done_callback,\n)\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n\nif typing.TYPE_CHECKING:\n    from typing import Dict, List  # noqa: F401\n", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23529411764705882}, {"context": ")\nfrom tornado.log import app_log\nfrom tornado.util import Configurable, TimeoutError, import_object\n\nimport typing\nfrom typing import Union, Any, Type, Optional, Callable, TypeVar, Tuple, Awaitable\n\nif typing.TYPE_CHECKING:\n    from typing import Dict, List  # noqa: F401\n\n    from typing_extensions import Protocol\nelse:\n    Protocol = object\n\n\nclass _Selectable(Protocol):\n    def fileno(self) -> int:\n        pass\n\n    def close(self) -> None:", "metadata": [{"fpath_tuple": ["tornado", "ioloop.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23148148148148148}, {"context": "import pycares  # type: ignore\nimport socket\n\nfrom tornado.concurrent import Future\nfrom tornado import gen\nfrom tornado.ioloop import IOLoop\nfrom tornado.netutil import Resolver, is_valid_ip\n\nimport typing\n", "metadata": [{"fpath_tuple": ["tornado", "platform", "caresresolver.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.23076923076923078}, {"context": "    http://tools.ietf.org/html/rfc6555\n\n    \"\"\"\n\n    def __init__(\n        self,\n        addrinfo: List[Tuple],\n        connect: Callable[\n            [socket.AddressFamily, Tuple], Tuple[IOStream, \"Future[IOStream]\"]\n        ],\n    ) -> None:\n        self.io_loop = IOLoop.current()\n        self.connect = connect\n\n        self.future = (\n            Future()\n        )  # type: Future[Tuple[socket.AddressFamily, Any, IOStream]]\n        self.timeout = None  # type: Optional[object]\n        self.connect_timeout = None  # type: Optional[object]\n        self.last_error = None  # type: Optional[Exception]", "metadata": [{"fpath_tuple": ["tornado", "tcpclient.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22807017543859648}, {"context": "import sys\nimport types\n\nfrom tornado.log import app_log\n\nimport typing\nfrom typing import Any, Callable, Optional, Tuple, Union\n\n_T = typing.TypeVar(\"_T\")\n\n\nclass ReturnValueIgnoredError(Exception):\n    # No longer used; was previously used by @return_future\n    pass\n\n\nFuture = asyncio.Future\n\nFUTURES = (futures.Future, Future)\n", "metadata": [{"fpath_tuple": ["tornado", "concurrent.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22772277227722773}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/httputil_test.py\n# --------------------------------------------------\n#     HTTPFile,\n# )\n# from tornado.escape import utf8, native_str\n# from tornado.log import gen_log\n# from tornado.testing import ExpectLog\n# \n# import copy\n# import datetime\n# import logging\n# import pickle\n# import time\n# import urllib.parse\n# import unittest\n# \n# from typing import Tuple, Dict, List\n# \n# \n# def form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n#     \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     url: str,\n#     args: Union[\n#         None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n#     ],\n# ) -> str:\n#     \"\"\"Concatenate url and arguments regardless of whether\n#     url has existing query parameters.\n# \n#     ``args`` may be either a dictionary or a list of key-value pairs\n#     (the latter allows for multiple values with the same key.\n# \n#     >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n#     'http://example.com/foo?c=d'\n#     >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n#     'http://example.com/foo?a=b&c=d'\n#     >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n#     'http://example.com/foo?a=b&c=d&c=d2'\n#     \"\"\"\n#     if args is None:\n#         return url\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#     ReversibleRuleRouter,\n#     URLSpec,\n#     _RuleList,\n# )\n# from tornado.util import ObjectDict, unicode_type, _websocket_mask\n# \n# url = URLSpec\n# \n# from typing import (\n#     Dict,\n#     Any,\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Tuple,\n#     List,\n#     Callable,\n#     Iterable,\n#     Generator,\n#     Type,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     Returned ``port`` will be ``None`` if not present.\n# \n#     .. versionadded:: 4.1\n#     \"\"\"\n#     match = _netloc_re.match(netloc)\n#     if match:\n#         host = match.group(1)\n#         port = int(match.group(2))  # type: Optional[int]\n#     else:\n#         host = netloc\n#         port = None\n#     return (host, port)\n# \n# \n# def qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n#     \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n# \n#     .. versionadded:: 5.0\n#     \"\"\"\n#     for k, vs in qs.items():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# template.py\n# --------------------------------------------------\n# from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\n# import typing\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Tuple, ContextManager  # noqa: F401\n# \n# _DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n# \n# \n# class _UnsetMarker:\n#     pass\n# \n# \n# _UNSET = _UnsetMarker()\n# \n# \n# def filter_whitespace(mode: str, text: str) -> str:\n#     \"\"\"Transform whitespace in ``text`` according to ``mode``.\n# \n#     Available modes are:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#         \"\"\"\n#         raise NotImplementedError()\n# \n#     def finish(self) -> None:\n#         \"\"\"Indicates that the last body data has been written.\n#         \"\"\"\n#         raise NotImplementedError()\n# \n# \n# def url_concat(\n#     url: str,\n#     args: Union[\n#         None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n#     ],\n# ) -> str:\n#     \"\"\"Concatenate url and arguments regardless of whether\n#     url has existing query parameters.\n# \n#     ``args`` may be either a dictionary or a list of key-value pairs\n#     (the latter allows for multiple values with the same key.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n# from tornado.util import errno_from_exception\n# \n# import typing\n# from typing import (\n#     Union,\n#     Optional,\n#     Awaitable,\n#     Callable,\n#     Pattern,\n#     Any,\n#     Dict,\n#     TypeVar,\n#     Tuple,\n# )\n# from types import TracebackType\n# \n# if typing.TYPE_CHECKING:\n#     from typing import Deque, List, Type  # noqa: F401\n# \n# _IOStreamType = TypeVar(\"_IOStreamType\", bound=\"IOStream\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# util.py\n# --------------------------------------------------\n#     def replace(\n#         self, new_value: Any, args: Sequence[Any], kwargs: Dict[str, Any]\n#     ) -> Tuple[Any, Sequence[Any], Dict[str, Any]]:\n#         \"\"\"Replace the named argument in ``args, kwargs`` with ``new_value``.\n# \n#         Returns ``(old_value, args, kwargs)``.  The returned ``args`` and\n#         ``kwargs`` objects may not be the same as the input objects, or\n#         the input objects may be mutated.\n# \n#         If the named argument was not found, ``new_value`` will be added\n#         to ``kwargs`` and None will be returned as ``old_value``.\n#         \"\"\"\n#         if self.arg_pos is not None and len(args) > self.arg_pos:\n#             # The arg to replace is passed positionally\n#             old_value = args[self.arg_pos]\n#             args = list(args)  # *args is normally a tuple\n#             args[self.arg_pos] = new_value\n#         else:\n#             # The arg to replace is either omitted or passed by keyword.\n#             old_value = kwargs.get(self.name)\n# --------------------------------------------------\n\ndef multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n    results = []\n    for future in list_of_futures:\n    results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n    If multiple yieldables fail, any exceptions after the first\n    (which is raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n    Replaced the class ``Multi`` and the function ``multi_future``\n    with a unified function ``multi``. Added support for yieldables\n    other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n", "metadata": {"task_id": "tornado/id2", "ground_truth": "def multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: \"Union[Type[Exception], Tuple[Type[Exception], ...]]\" = (),\n) -> \"Union[Future[List], Future[Dict]]\":\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    That is, ``results = yield multi(list_of_futures)`` is equivalent\n    to::\n\n        results = []\n        for future in list_of_futures:\n            results.append(yield future)\n\n    If any children raise exceptions, ``multi()`` will raise the first\n    one. All others will be logged, unless they are of types\n    contained in the ``quiet_exceptions`` argument.\n\n    In a ``yield``-based coroutine, it is not normally necessary to\n    call this function directly, since the coroutine runner will\n    do it automatically when a list or dict is yielded. However,\n    it is necessary in ``await``-based coroutines, or to pass\n    the ``quiet_exceptions`` argument.\n\n    This function is available under the names ``multi()`` and ``Multi()``\n    for historical reasons.\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n       If multiple yieldables fail, any exceptions after the first\n       (which is raised) will be logged. Added the ``quiet_exceptions``\n       argument to suppress this logging for selected exception types.\n\n    .. versionchanged:: 4.3\n       Replaced the class ``Multi`` and the function ``multi_future``\n       with a unified function ``multi``. Added support for yieldables\n       other than ``YieldPoint`` and `.Future`.\n\n    \"\"\"\n    return multi_future(children, quiet_exceptions=quiet_exceptions)", "fpath_tuple": ["tornado", "gen.py"], "function_name": "multi", "lineno": 0, "context_start_lineno": 0, "_id": 2, "query_window": {"context": "from typing import Any, Dict, Future, List, Type, Tuple, Union\nfrom tornado import gen\nfrom tornado.queues import Queue\n_Yieldable = Any  # Assuming _Yieldable is defined somewhere in your codebase\ndef multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]] = ()\n) -> Union[Future[List], Future[Dict]]:\n    \"\"\"Runs multiple asynchronous operations in parallel.\n    ``children`` may either be a list or a dict whose values are", "metadata": {"fpath_tuple": ["tornado", "gen.py"], "line_no": 0, "prediction": "from typing import Any, Dict, Future, List, Type, Tuple, Union\nfrom tornado import gen\nfrom tornado.queues import Queue\n\n_Yieldable = Any  # Assuming _Yieldable is defined somewhere in your codebase\n\ndef multi(\n    children: Union[List[_Yieldable], Dict[Any, _Yieldable]],\n    quiet_exceptions: Union[Type[Exception], Tuple[Type[Exception], ...]] = ()\n) -> Union[Future[List], Future[Dict]]:\n    \"\"\"Runs multiple asynchronous operations in parallel.\n\n    ``children`` may either be a list or a dict whose values are\n    yieldable objects. ``multi()`` returns a new yieldable\n    object that resolves to a parallel structure containing their\n    results. If ``children`` is a list, the result is a list of\n    results in the same order; if it is a dict, the result is a dict\n    with the same keys.\n\n    ...\n\n    Cancelling a `.Future` returned by ``multi()`` does not cancel its\n    children. `asyncio.gather` is similar to ``multi()``, but it does\n    cancel its children.\n\n    .. versionchanged:: 4.2\n    If multiple yieldables fail, any exceptions after the first\n    (which is raised) will be logged. Added the ``quiet_exceptions``\n    argument to suppress this logging for selected exception types.\n    \"\"\"\n    if isinstance(children, dict):\n        keys = list(children.keys())\n        futures = list(children.values())\n    else:\n        keys = range(len(children))\n        futures = children\n\n    queue = Queue()\n    errors = []\n    \n    @gen.coroutine\n    def run_future(index, future):\n        try:\n            result = yield future\n            yield queue.put((index, result))\n        except Exception as e:\n            if not isinstance(e, quiet_exceptions):\n                errors.append(e)\n            yield queue.put((index, e))\n\n    @gen.coroutine\n    def gather_results():\n        yield [run_future(i, future) for i, future in zip(keys, futures)]\n        results = {}\n        for _ in range(len(futures)):\n            index, result = yield queue.get()\n            results[index] = result\n        \n        if errors:\n            raise errors[0]  # Raise first exception\n        return results\n\n    return gather_results()", "task_id": "tornado/id2", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    def replace(\n        self, new_value: Any, args: Sequence[Any], kwargs: Dict[str, Any]\n    ) -> Tuple[Any, Sequence[Any], Dict[str, Any]]:\n        \"\"\"Replace the named argument in ``args, kwargs`` with ``new_value``.\n\n        Returns ``(old_value, args, kwargs)``.  The returned ``args`` and\n        ``kwargs`` objects may not be the same as the input objects, or\n        the input objects may be mutated.\n\n        If the named argument was not found, ``new_value`` will be added\n        to ``kwargs`` and None will be returned as ``old_value``.\n        \"\"\"\n        if self.arg_pos is not None and len(args) > self.arg_pos:\n            # The arg to replace is passed positionally\n            old_value = args[self.arg_pos]\n            args = list(args)  # *args is normally a tuple\n            args[self.arg_pos] = new_value\n        else:\n            # The arg to replace is either omitted or passed by keyword.\n            old_value = kwargs.get(self.name)", "metadata": [{"fpath_tuple": ["tornado", "util.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22916666666666666}, {"context": "from tornado.util import errno_from_exception\n\nimport typing\nfrom typing import (\n    Union,\n    Optional,\n    Awaitable,\n    Callable,\n    Pattern,\n    Any,\n    Dict,\n    TypeVar,\n    Tuple,\n)\nfrom types import TracebackType\n\nif typing.TYPE_CHECKING:\n    from typing import Deque, List, Type  # noqa: F401\n\n_IOStreamType = TypeVar(\"_IOStreamType\", bound=\"IOStream\")", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22807017543859648}, {"context": "        \"\"\"\n        raise NotImplementedError()\n\n    def finish(self) -> None:\n        \"\"\"Indicates that the last body data has been written.\n        \"\"\"\n        raise NotImplementedError()\n\n\ndef url_concat(\n    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22627737226277372}, {"context": "from typing import Any, Union, Callable, List, Dict, Iterable, Optional, TextIO\nimport typing\n\nif typing.TYPE_CHECKING:\n    from typing import Tuple, ContextManager  # noqa: F401\n\n_DEFAULT_AUTOESCAPE = \"xhtml_escape\"\n\n\nclass _UnsetMarker:\n    pass\n\n\n_UNSET = _UnsetMarker()\n\n\ndef filter_whitespace(mode: str, text: str) -> str:\n    \"\"\"Transform whitespace in ``text`` according to ``mode``.\n\n    Available modes are:", "metadata": [{"fpath_tuple": ["tornado", "template.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2222222222222222}, {"context": "    Returned ``port`` will be ``None`` if not present.\n\n    .. versionadded:: 4.1\n    \"\"\"\n    match = _netloc_re.match(netloc)\n    if match:\n        host = match.group(1)\n        port = int(match.group(2))  # type: Optional[int]\n    else:\n        host = netloc\n        port = None\n    return (host, port)\n\n\ndef qs_to_qsl(qs: Dict[str, List[AnyStr]]) -> Iterable[Tuple[str, AnyStr]]:\n    \"\"\"Generator converting a result of ``parse_qs`` back to name-value pairs.\n\n    .. versionadded:: 5.0\n    \"\"\"\n    for k, vs in qs.items():", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 1040, "start_line_no": 1030, "end_line_no": 1050, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2191780821917808}, {"context": "    ReversibleRuleRouter,\n    URLSpec,\n    _RuleList,\n)\nfrom tornado.util import ObjectDict, unicode_type, _websocket_mask\n\nurl = URLSpec\n\nfrom typing import (\n    Dict,\n    Any,\n    Union,\n    Optional,\n    Awaitable,\n    Tuple,\n    List,\n    Callable,\n    Iterable,\n    Generator,\n    Type,", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2169811320754717}, {"context": "    url: str,\n    args: Union[\n        None, Dict[str, str], List[Tuple[str, str]], Tuple[Tuple[str, str], ...]\n    ],\n) -> str:\n    \"\"\"Concatenate url and arguments regardless of whether\n    url has existing query parameters.\n\n    ``args`` may be either a dictionary or a list of key-value pairs\n    (the latter allows for multiple values with the same key.\n\n    >>> url_concat(\"http://example.com/foo\", dict(c=\"d\"))\n    'http://example.com/foo?c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", dict(c=\"d\"))\n    'http://example.com/foo?a=b&c=d'\n    >>> url_concat(\"http://example.com/foo?a=b\", [(\"c\", \"d\"), (\"c\", \"d2\")])\n    'http://example.com/foo?a=b&c=d&c=d2'\n    \"\"\"\n    if args is None:\n        return url", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 620, "start_line_no": 610, "end_line_no": 630, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21621621621621623}, {"context": "    HTTPFile,\n)\nfrom tornado.escape import utf8, native_str\nfrom tornado.log import gen_log\nfrom tornado.testing import ExpectLog\n\nimport copy\nimport datetime\nimport logging\nimport pickle\nimport time\nimport urllib.parse\nimport unittest\n\nfrom typing import Tuple, Dict, List\n\n\ndef form_data_args() -> Tuple[Dict[str, List[bytes]], Dict[str, List[HTTPFile]]]:\n    \"\"\"Return two empty dicts suitable for use with parse_multipart_form_data.\n", "metadata": [{"fpath_tuple": ["tornado", "test", "httputil_test.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2109375}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# web.py\n# --------------------------------------------------\n#         \"\"\"Override to returns a list of CSS files required by this module.\n# \n#         If the return values are relative paths, they will be passed to\n#         `RequestHandler.static_url`; otherwise they will be used as-is.\n#         \"\"\"\n#         return None\n# \n#     def html_head(self) -> Optional[str]:\n#         \"\"\"Override to return an HTML string that will be put in the <head/>\n#         element.\n#         \"\"\"\n#         return None\n# \n#     def html_body(self) -> Optional[str]:\n#         \"\"\"Override to return an HTML string that will be put at the end of\n#         the <body/> element.\n#         \"\"\"\n#         return None\n# \n#     def render_string(self, path: str, **kwargs: Any) -> bytes:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n# def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n#     \"\"\"Returns a URL-encoded version of the given value.\n# \n#     If ``plus`` is true (the default), spaces will be represented\n#     as \"+\" instead of \"%20\".  This is appropriate for query strings\n#     but not for the path component of a URL.  Note that this default\n#     is the reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#         The ``plus`` argument\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# iostream.py\n# --------------------------------------------------\n#         as returned by _find_read_pos.\n#         \"\"\"\n#         self._read_bytes = self._read_delimiter = self._read_regex = None\n#         self._read_partial = False\n#         self._finish_read(pos, False)\n# \n#     def _find_read_pos(self) -> Optional[int]:\n#         \"\"\"Attempts to find a position in the read buffer that satisfies\n#         the currently-pending read.\n# \n#         Returns a position in the buffer if the current read can be satisfied,\n#         or None if it cannot.\n#         \"\"\"\n#         if self._read_bytes is not None and (\n#             self._read_buffer_size >= self._read_bytes\n#             or (self._read_partial and self._read_buffer_size > 0)\n#         ):\n#             num_bytes = min(self._read_bytes, self._read_buffer_size)\n#             return num_bytes\n#         elif self._read_delimiter is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# websocket.py\n# --------------------------------------------------\n#         is given it will be called with the future when it is\n#         ready.\n#         \"\"\"\n# \n#         awaitable = self.read_queue.get()\n#         if callback is not None:\n#             self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n#         return awaitable\n# \n#     def on_message(self, message: Union[str, bytes]) -> Optional[Awaitable[None]]:\n#         return self._on_message(message)\n# \n#     def _on_message(\n#         self, message: Union[None, str, bytes]\n#     ) -> Optional[Awaitable[None]]:\n#         if self._on_message_callback:\n#             self._on_message_callback(message)\n#             return None\n#         else:\n#             return self.read_queue.put(message)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n# \n# def _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n#     \"\"\"Returns a suitable Content-Range header:\n# \n#     >>> print(_get_content_range(None, 1, 4))\n#     bytes 0-0/4\n#     >>> print(_get_content_range(1, 3, 4))\n#     bytes 1-2/4\n#     >>> print(_get_content_range(None, None, 4))\n#     bytes 0-3/4\n#     \"\"\"\n#     start = start or 0\n#     end = (end or total) - 1\n#     return \"bytes %s-%s/%s\" % (start, end, total)\n# \n# \n# def _int_or_none(val: str) -> Optional[int]:\n#     val = val.strip()\n#     if val == \"\":\n#         return None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# httputil.py\n# --------------------------------------------------\n#     \"\"\"\n#     start = start or 0\n#     end = (end or total) - 1\n#     return \"bytes %s-%s/%s\" % (start, end, total)\n# \n# \n# def _int_or_none(val: str) -> Optional[int]:\n#     val = val.strip()\n#     if val == \"\":\n#         return None\n#     return int(val)\n# \n# \n# def parse_body_arguments(\n#     content_type: str,\n#     body: bytes,\n#     arguments: Dict[str, List[bytes]],\n#     files: Dict[str, List[HTTPFile]],\n#     headers: Optional[HTTPHeaders] = None,\n# ) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     for the path component of a URL.  Note that this default is the\n#     reverse of Python's urllib module.\n# \n#     .. versionadded:: 3.1\n#        The ``plus`` argument\n#     \"\"\"\n#     if encoding is None:\n#         if plus:\n#             # unquote_to_bytes doesn't have a _plus variant\n#             value = to_basestring(value).replace(\"+\", \" \")\n#         return urllib.parse.unquote_to_bytes(value)\n#     else:\n#         unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n#         return unquote(to_basestring(value), encoding=encoding)\n# \n# \n# def parse_qs_bytes(\n#     qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n# ) -> Dict[str, List[bytes]]:\n#     \"\"\"Parses a query string like urlparse.parse_qs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# escape.py\n# --------------------------------------------------\n#     \"\"\"\n#     quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n#     return quote(utf8(value))\n# \n# \n# @typing.overload\n# def url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n#     pass\n# \n# \n# @typing.overload  # noqa: F811\n# def url_unescape(\n#     value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n# ) -> str:\n#     pass\n# \n# \n# def url_unescape(  # noqa: F811\n#     value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n# ) -> Union[str, bytes]:\n# --------------------------------------------------\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n", "metadata": {"task_id": "tornado/id0", "ground_truth": "def _unquote_or_none(s: Optional[str]) -> Optional[bytes]:  # noqa: F811\n    \"\"\"None-safe wrapper around url_unescape to handle unmatched optional\n    groups correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    encoding to use.\n    \"\"\"\n    if s is None:\n        return s\n    return url_unescape(s, encoding=None, plus=False)", "fpath_tuple": ["tornado", "routing.py"], "function_name": "_unquote_or_none", "lineno": 0, "context_start_lineno": 0, "_id": 0, "query_window": {"context": "from typing import Optional\nfrom urllib.parse import unquote\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:\n    \"\"\"None-safe wrapper around to handle unmatched optional\n    group correctly.\n    Note that args are passed as bytes so the handler can decide what\n    to do with them.\n    \"\"\"\n    if s is None:\n        return None", "metadata": {"fpath_tuple": ["tornado", "routing.py"], "line_no": 0, "prediction": "from typing import Optional\nfrom urllib.parse import unquote\n\ndef _unquote_or_none(s: Optional[str]) -> Optional[bytes]:\n    \"\"\"None-safe wrapper around to handle unmatched optional\n    group correctly.\n\n    Note that args are passed as bytes so the handler can decide what\n    to do with them.\n    \"\"\"\n    if s is None:\n        return None\n    return unquote(s).encode('utf-8')", "task_id": "tornado/id0", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "tornado"}}, "top_k_context": [{"context": "    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n\n@typing.overload  # noqa: F811\ndef url_unescape(\n    value: Union[str, bytes], encoding: str = \"utf-8\", plus: bool = True\n) -> str:\n    pass\n\n\ndef url_unescape(  # noqa: F811\n    value: Union[str, bytes], encoding: Optional[str] = \"utf-8\", plus: bool = True\n) -> Union[str, bytes]:", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.24489795918367346}, {"context": "    for the path component of a URL.  Note that this default is the\n    reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n       The ``plus`` argument\n    \"\"\"\n    if encoding is None:\n        if plus:\n            # unquote_to_bytes doesn't have a _plus variant\n            value = to_basestring(value).replace(\"+\", \" \")\n        return urllib.parse.unquote_to_bytes(value)\n    else:\n        unquote = urllib.parse.unquote_plus if plus else urllib.parse.unquote\n        return unquote(to_basestring(value), encoding=encoding)\n\n\ndef parse_qs_bytes(\n    qs: Union[str, bytes], keep_blank_values: bool = False, strict_parsing: bool = False\n) -> Dict[str, List[bytes]]:\n    \"\"\"Parses a query string like urlparse.parse_qs,", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22857142857142856}, {"context": "    \"\"\"\n    start = start or 0\n    end = (end or total) - 1\n    return \"bytes %s-%s/%s\" % (start, end, total)\n\n\ndef _int_or_none(val: str) -> Optional[int]:\n    val = val.strip()\n    if val == \"\":\n        return None\n    return int(val)\n\n\ndef parse_body_arguments(\n    content_type: str,\n    body: bytes,\n    arguments: Dict[str, List[bytes]],\n    files: Dict[str, List[HTTPFile]],\n    headers: Optional[HTTPHeaders] = None,\n) -> None:", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.22018348623853212}, {"context": "\ndef _get_content_range(start: Optional[int], end: Optional[int], total: int) -> str:\n    \"\"\"Returns a suitable Content-Range header:\n\n    >>> print(_get_content_range(None, 1, 4))\n    bytes 0-0/4\n    >>> print(_get_content_range(1, 3, 4))\n    bytes 1-2/4\n    >>> print(_get_content_range(None, None, 4))\n    bytes 0-3/4\n    \"\"\"\n    start = start or 0\n    end = (end or total) - 1\n    return \"bytes %s-%s/%s\" % (start, end, total)\n\n\ndef _int_or_none(val: str) -> Optional[int]:\n    val = val.strip()\n    if val == \"\":\n        return None", "metadata": [{"fpath_tuple": ["tornado", "httputil.py"], "line_no": 730, "start_line_no": 720, "end_line_no": 740, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.21621621621621623}, {"context": "        is given it will be called with the future when it is\n        ready.\n        \"\"\"\n\n        awaitable = self.read_queue.get()\n        if callback is not None:\n            self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n        return awaitable\n\n    def on_message(self, message: Union[str, bytes]) -> Optional[Awaitable[None]]:\n        return self._on_message(message)\n\n    def _on_message(\n        self, message: Union[None, str, bytes]\n    ) -> Optional[Awaitable[None]]:\n        if self._on_message_callback:\n            self._on_message_callback(message)\n            return None\n        else:\n            return self.read_queue.put(message)", "metadata": [{"fpath_tuple": ["tornado", "websocket.py"], "line_no": 1530, "start_line_no": 1520, "end_line_no": 1540, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.2072072072072072}, {"context": "        as returned by _find_read_pos.\n        \"\"\"\n        self._read_bytes = self._read_delimiter = self._read_regex = None\n        self._read_partial = False\n        self._finish_read(pos, False)\n\n    def _find_read_pos(self) -> Optional[int]:\n        \"\"\"Attempts to find a position in the read buffer that satisfies\n        the currently-pending read.\n\n        Returns a position in the buffer if the current read can be satisfied,\n        or None if it cannot.\n        \"\"\"\n        if self._read_bytes is not None and (\n            self._read_buffer_size >= self._read_bytes\n            or (self._read_partial and self._read_buffer_size > 0)\n        ):\n            num_bytes = min(self._read_bytes, self._read_buffer_size)\n            return num_bytes\n        elif self._read_delimiter is not None:", "metadata": [{"fpath_tuple": ["tornado", "iostream.py"], "line_no": 910, "start_line_no": 900, "end_line_no": 920, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20512820512820512}, {"context": "def url_escape(value: Union[str, bytes], plus: bool = True) -> str:\n    \"\"\"Returns a URL-encoded version of the given value.\n\n    If ``plus`` is true (the default), spaces will be represented\n    as \"+\" instead of \"%20\".  This is appropriate for query strings\n    but not for the path component of a URL.  Note that this default\n    is the reverse of Python's urllib module.\n\n    .. versionadded:: 3.1\n        The ``plus`` argument\n    \"\"\"\n    quote = urllib.parse.quote_plus if plus else urllib.parse.quote\n    return quote(utf8(value))\n\n\n@typing.overload\ndef url_unescape(value: Union[str, bytes], encoding: None, plus: bool = True) -> bytes:\n    pass\n\n", "metadata": [{"fpath_tuple": ["tornado", "escape.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.20437956204379562}, {"context": "        \"\"\"Override to returns a list of CSS files required by this module.\n\n        If the return values are relative paths, they will be passed to\n        `RequestHandler.static_url`; otherwise they will be used as-is.\n        \"\"\"\n        return None\n\n    def html_head(self) -> Optional[str]:\n        \"\"\"Override to return an HTML string that will be put in the <head/>\n        element.\n        \"\"\"\n        return None\n\n    def html_body(self) -> Optional[str]:\n        \"\"\"Override to return an HTML string that will be put at the end of\n        the <body/> element.\n        \"\"\"\n        return None\n\n    def render_string(self, path: str, **kwargs: Any) -> bytes:", "metadata": [{"fpath_tuple": ["tornado", "web.py"], "line_no": 3230, "start_line_no": 3220, "end_line_no": 3240, "window_size": 20, "repo": "tornado", "slice_size": 2}], "sim_score": 0.19827586206896552}], "window_size": 20, "slice_size": 2}}
